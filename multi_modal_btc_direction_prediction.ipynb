{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1unsFH5ojsU"
   },
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sentiment = pd.read_csv(\"/content/btc_sentiment_ohlcv (1).csv\")\n",
    "market = pd.read_csv(\"market_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletting unececssary columns and set date column as an index\n",
    "sentiment.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "sentiment[\"date\"] = pd.to_datetime(sentiment[\"date\"])\n",
    "sentiment.set_index(\"date\", inplace=True)\n",
    "\n",
    "market.rename(columns={\"Unnamed: 0\" : \"date\"}, inplace=True)\n",
    "market[\"date\"] = pd.to_datetime(market[\"date\"])\n",
    "market.set_index(\"date\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7p7FwYYpMsO"
   },
   "source": [
    "Technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ta.trend import EMAIndicator, MACD, ADXIndicator, PSARIndicator\n",
    "from ta.volatility import BollingerBands, AverageTrueRange, KeltnerChannel\n",
    "from ta.volume import OnBalanceVolumeIndicator, ChaikinMoneyFlowIndicator, AccDistIndexIndicator\n",
    "\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    # Trend Indicators\n",
    "    df['ema_5'] = EMAIndicator(close=df['close'], window=5).ema_indicator()\n",
    "    df['ema_20'] = EMAIndicator(close=df['close'], window=20).ema_indicator()\n",
    "    df['ema_50'] = EMAIndicator(close=df['close'], window=50).ema_indicator()\n",
    "\n",
    "    macd = MACD(close=df['close'])\n",
    "    df['macd'] = macd.macd()\n",
    "    df['signal'] = macd.macd_signal()\n",
    "    df['histogram'] = macd.macd_diff()\n",
    "\n",
    "    # Volatility Indicators\n",
    "    bb = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
    "    df['bb_upper'] = bb.bollinger_hband()\n",
    "    df['bb_lower'] = bb.bollinger_lband()\n",
    "    df['bb_middle'] = bb.bollinger_mavg()\n",
    "\n",
    "    atr = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
    "    df['ATR'] = atr.average_true_range()\n",
    "\n",
    "    # Donchian Channels (manual)\n",
    "    df['donchian_upper'] = df['high'].rolling(window=20).max()\n",
    "    df['donchian_lower'] = df['low'].rolling(window=20).min()\n",
    "    df['donchian_middle'] = (df['donchian_upper'] + df['donchian_lower']) / 2\n",
    "\n",
    "    # Volume Indicators\n",
    "    df['obv'] = OnBalanceVolumeIndicator(close=df['close'], volume=df['volume']).on_balance_volume()\n",
    "\n",
    "    df['vwap'] = (df['close'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_technical_indicators(sentiment)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding days of the week as number\n",
    "df['day_number'] = df.index.weekday\n",
    "df[\"month\"] = df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(market, how=\"left\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding target variable\n",
    "df['target'] = df['close'].diff().apply(lambda x: 1 if x > 0 else 0)\n",
    "df[\"target\"] = df[\"target\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuEhT3XZtREZ"
   },
   "source": [
    "Profiling report for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df, title=\"Mulitmodal dataset for bitcoin direction prediciton\", explorative=True)\n",
    "\n",
    "# Save the report to an HTML file\n",
    "profile.to_file(\"multimodal_report.html\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"multimodal_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKcYV2zHviL_"
   },
   "source": [
    "### Scaling and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVZlxOaIxKbb"
   },
   "source": [
    "**Creating different version of datasets**\n",
    "- Scaled dataset\n",
    "- Normalized dataset\n",
    "- Log transformation dataset\n",
    "- Log and Normalized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "target_feature = 'target'  # Replace 'target' with the actual target column name\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=[target_feature])\n",
    "y = df[target_feature]\n",
    "\n",
    "# Initialize StandardScaler and MinMaXScaler\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "features_log = X.copy()\n",
    "for column in features_log.columns:\n",
    "    # Applying log transformation. Adjust the shift if necessary.\n",
    "    features_log[column] = np.log(features_log[column] + 1)\n",
    "\n",
    "# Log transformed dataset\n",
    "df_log_transformed = features_log.copy()\n",
    "df_log_transformed[target_feature] = y\n",
    "\n",
    "# Log normalized dataset\n",
    "log_normalized_features = minmax_scaler.fit_transform(features_log)\n",
    "log_norm_features_df = pd.DataFrame(log_normalized_features, index=features_log.index, columns=features_log.columns)\n",
    "df_log_norm = log_norm_features_df.copy()\n",
    "df_log_norm[target_feature] = y\n",
    "\n",
    "# Fit the scaler to the features and transform them\n",
    "scaled_features = standard_scaler.fit_transform(X)\n",
    "normalized_features = minmax_scaler.fit_transform(X)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "scaled_features_df = pd.DataFrame(scaled_features, index=X.index, columns=X.columns)\n",
    "norm_features_df = pd.DataFrame(normalized_features, index=X.index, columns=X.columns)\n",
    "\n",
    "\n",
    "# Reattach the target feature back to the DataFrame\n",
    "df_scaled = scaled_features_df.copy()\n",
    "df_scaled[target_feature] = y\n",
    "\n",
    "df_norm = norm_features_df.copy()\n",
    "df_norm[target_feature] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2h6HDBT0VJD"
   },
   "source": [
    "Datasets version collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"scaled\": df_scaled,\n",
    "    \"normalized\": df_norm,\n",
    "    \"log_transformed\": df_log_transformed,\n",
    "    \"log_normalized\": df_log_norm\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TUAN2n9IOD78"
   },
   "source": [
    "Saving transformed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dfs.items():\n",
    "    df.to_csv(f\"{df_name}_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNlmasID0cyA"
   },
   "source": [
    "### LSTM training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAL26BQq0ix3"
   },
   "source": [
    "Function to create sequence according to the window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequences(data, feature_cols, target_col, window_size=60):\n",
    "    X, y = [], []\n",
    "\n",
    "    for i in range(len(data) - window_size):\n",
    "        # Range of data for this window\n",
    "        seq_x = data[feature_cols].iloc[i:i+window_size].values\n",
    "        # Target is the \"day after the window\"\n",
    "        seq_y = data[target_col].iloc[i+window_size]\n",
    "\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSHD7ixc085B"
   },
   "source": [
    "Function to split data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "  train_size = int(len(df) * 0.8)\n",
    "  train_data = df[:train_size]\n",
    "  test_data = df[train_size:]\n",
    "\n",
    "  return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaAtnCaw1jM3"
   },
   "source": [
    "Function to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "def create_model(X_train):\n",
    "  model = Sequential()\n",
    "\n",
    "  # Model layers\n",
    "  model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "  model.add(LSTM(units=64, return_sequences=True))\n",
    "  model.add(LSTM(units=32, return_sequences=False))\n",
    "  model.add(Dense(units=50, activation=\"relu\"))\n",
    "  model.add(Dense(units=30, activation=\"relu\"))\n",
    "  model.add(Dense(units=30, activation=\"relu\"))\n",
    "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "  model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model to see visual architecture\n",
    "from tensorflow.keras.utils import plot_model\n",
    "feature_cols = [col for col in dfs[\"log_normalized\"].columns if col != \"target\"]\n",
    "target_col = \"target\"\n",
    "X_train = create_sequences(dfs[\"log_normalized\"], feature_cols, target_col, window_size=60)[0]\n",
    "model = create_model(X_train)\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZYIn3OF1p7M"
   },
   "source": [
    "Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def training_loop(df, window_sizes, batch_sizes):\n",
    "\n",
    "  # Extracting features and target column\n",
    "  feature_cols = [col for col in df.columns if col != \"target\"]\n",
    "  target_col = \"target\"\n",
    "\n",
    "  # Creating df to store results for each dataset\n",
    "  result = pd.DataFrame(columns=[\"model\", \"window_size\", \"batch_size\", \"train_accuracy\", \"val_accuracy\", \"X_test\", \"y_test\"])\n",
    "\n",
    "  # Split dataframe into train and test\n",
    "  train_data, test_data = split(df)\n",
    "\n",
    "  for window_size in window_sizes:\n",
    "    for batch_size in batch_sizes:\n",
    "\n",
    "      # Creation of the sequences according to window size\n",
    "      X_train, y_train = create_sequences(\n",
    "          data=train_data,\n",
    "          feature_cols=feature_cols,\n",
    "          target_col=target_col,\n",
    "          window_size=window_size\n",
    "      )\n",
    "      X_test, y_test = create_sequences(\n",
    "          data=test_data,\n",
    "          feature_cols=feature_cols,\n",
    "          target_col=target_col,\n",
    "          window_size=window_size\n",
    "      )\n",
    "\n",
    "      # Early stopping in case if validation loss doesn't change in 15 epochs\n",
    "      early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True  # Restore model weights from the best epoch\n",
    "      )\n",
    "\n",
    "\n",
    "      # Model creation with different split data\n",
    "      model = create_model(X_train)\n",
    "\n",
    "      # Training configuration with different batch sizes\n",
    "      history = model.fit(\n",
    "          X_train, y_train,\n",
    "          epochs=30,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=False,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[early_stop]\n",
    "      )\n",
    "\n",
    "      # Saving results\n",
    "      train_acc = max(history.history[\"accuracy\"])\n",
    "      val_acc   = max(history.history[\"val_accuracy\"])\n",
    "\n",
    "      row_dict = {\n",
    "              \"model\": model,\n",
    "              \"window_size\": window_size,\n",
    "              \"batch_size\": batch_size,\n",
    "              \"train_accuracy\": train_acc,\n",
    "              \"val_accuracy\": val_acc,\n",
    "              \"X_test\" : X_test,\n",
    "              \"y_test\" : y_test\n",
    "          }\n",
    "\n",
    "      # Creating row dataframe\n",
    "      temp_df = pd.DataFrame([row_dict])\n",
    "\n",
    "      # Concatenate with the main results DataFrame\n",
    "      result = pd.concat([result, temp_df], ignore_index=True)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intial set up\n",
    "window_sizes = list(range(10, 101, 10))\n",
    "batch_sizes = [64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"macd\", \"signal\", \"histogram\"]\n",
    "dfs_to_drop = [\"log_transformed\", \"log_normalized\"]\n",
    "\n",
    "for df in dfs_to_drop:\n",
    "  dfs[df].drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"log_normalized\"].dropna(inplace=True)\n",
    "dfs[\"log_transformed\"].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srfWtrAoTk9q"
   },
   "source": [
    "Evalutaion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_accuracy(model, X_test, y_test):\n",
    "\n",
    "    # Predicts probability\n",
    "    y_prob = model.predict(X_test)  # shape: (num_samples, 1)\n",
    "\n",
    "    # If you need actual class labels (0 or 1):\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    # Calculate accuracy\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "def compute_best_results(results):\n",
    "\n",
    "  results[\"final_accuracy\"] = None\n",
    "  for idx, row in results.iterrows():\n",
    "      # Grab the trained model from the row\n",
    "      model = row['model']\n",
    "\n",
    "      X_test = results[\"X_test\"][idx]\n",
    "      y_test = results[\"y_test\"][idx]\n",
    "      # Compute accuracy\n",
    "      acc = compute_accuracy(model, X_test, y_test)\n",
    "\n",
    "      # Save to 'final_accuracy' column\n",
    "      results.at[idx, 'final_accuracy'] = acc\n",
    "\n",
    "  results_highest = results.sort_values(by=\"final_accuracy\", ascending=False)\n",
    "  return results_highest.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8IZPh8RN26Y"
   },
   "source": [
    "#### Log transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log = training_loop(dfs[\"log_transformed\"], window_sizes, batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log_test = compute_best_results(result_log)\n",
    "result_log_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdHI3eqbWGmV"
   },
   "source": [
    "###Log transform with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log_normalized = training_loop(dfs[\"log_normalized\"], window_sizes, batch_sizes)\n",
    "result_log_normalized_test = compute_best_results(result_log_normalized)\n",
    "result_log_normalized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LymcQ677YNAk"
   },
   "source": [
    "### Min max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_normalized = training_loop(dfs[\"normalized\"], window_sizes, batch_sizes)\n",
    "result_normalized_test = compute_best_results(result_normalized)\n",
    "result_normalized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhXR0yXraS5A"
   },
   "source": [
    "### Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scaled = training_loop(dfs[\"scaled\"], window_sizes, batch_sizes)\n",
    "result_scaled_test = compute_best_results(result_scaled)\n",
    "result_scaled_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA1CK9w9bNBV"
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BnsjB8_-cFPV"
   },
   "source": [
    "Model creation and training functiion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "def xgboost_model_training(df):\n",
    "\n",
    "  X = df.drop(columns=[\"target\"])\n",
    "  y = df[\"target\"]\n",
    "\n",
    "  # Split the data:\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "  model = xgb.XGBClassifier(\n",
    "      objective='binary:logistic',   # Use this objective if you have binary classes (e.g., up/down).\n",
    "      eval_metric='logloss',         # Evaluation metric can be logloss, error, etc.\n",
    "      use_label_encoder=False,       # Prevents deprecation warnings in newer versions of XGBoost.\n",
    "      random_state=42\n",
    "  )\n",
    "\n",
    "  # Parameter grid for the grid search\n",
    "  param_grid = {\n",
    "      'max_depth': [3, 5, 7],\n",
    "      'learning_rate': [0.01, 0.1, 0.2],\n",
    "      'n_estimators': [100, 200, 300],\n",
    "      'subsample': [0.8, 1.0]\n",
    "  }\n",
    "\n",
    "  grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  # Retrieve the best model after grid search\n",
    "  best_model = grid_search.best_estimator_\n",
    "  return best_model, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpJdV3TfcCZD"
   },
   "source": [
    "Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgboost_model(best_model, X_test, y_test):\n",
    "  # Make predictions on the test set\n",
    "  y_pred = best_model.predict(X_test)\n",
    "\n",
    "  # Evaluate using accuracy and other metrics.\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  print(\"Test Accuracy:\", acc)\n",
    "\n",
    "  # Detailed classification report\n",
    "  print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "  # Confusion matrix to see the distribution of predictions.\n",
    "  conf_mat = confusion_matrix(y_test, y_pred)\n",
    "  print(\"Confusion Matrix:\\n\", conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEz5VGe4cz0U"
   },
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in dfs.items():\n",
    "  print(f\"{df_name}\")\n",
    "  print(50*\"-\")\n",
    "  df[\"month\"] = df.index.month\n",
    "  best_model, X_test, y_test = xgboost_model_training(df)\n",
    "  evaluate_xgboost_model(best_model, X_test, y_test)\n",
    "  print(50*\"-\")\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
