{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6rRiDBVwPhAq1RgOfvNly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4f057e1841743bcb6c1a033450f37c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3166eada9b974ce8ae4266f4b783f831",
              "IPY_MODEL_55cfda073b6a4f3a871a56fefa2cd0fb",
              "IPY_MODEL_708dee3383774ae39a1ee40d228e284d"
            ],
            "layout": "IPY_MODEL_08148c152ea647ecb496cc31cc02e57e"
          }
        },
        "3166eada9b974ce8ae4266f4b783f831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b994196d866a46778dc64d0bc3813ef6",
            "placeholder": "​",
            "style": "IPY_MODEL_5594103c4e5a47c58380f1a94933921b",
            "value": "Summarize dataset:  27%"
          }
        },
        "55cfda073b6a4f3a871a56fefa2cd0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c903471edd544ae58d51c250db4ef811",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e00f6d210e0f4b33933bd5143ed2259f",
            "value": 5
          }
        },
        "708dee3383774ae39a1ee40d228e284d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0468174536d04af7925728529218d685",
            "placeholder": "​",
            "style": "IPY_MODEL_cc2fe1433b894bb79d77335f81a0e677",
            "value": " 273/1000 [00:25&lt;01:04, 11.30it/s, scatter obv, volume]"
          }
        },
        "08148c152ea647ecb496cc31cc02e57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b994196d866a46778dc64d0bc3813ef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5594103c4e5a47c58380f1a94933921b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c903471edd544ae58d51c250db4ef811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00f6d210e0f4b33933bd5143ed2259f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0468174536d04af7925728529218d685": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc2fe1433b894bb79d77335f81a0e677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Altemir1/BTC-ML-Based-Trading-System/blob/main/multi_modal_lstm_btc_direction_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset preparation"
      ],
      "metadata": {
        "id": "K1unsFH5ojsU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z9HBdtCoobbW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sentiment = pd.read_csv(\"/content/btc_sentiment_ohlcv (1).csv\")\n",
        "market = pd.read_csv(\"market_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "t24dL2VBpZNt",
        "outputId": "d8077271-1c9c-4c11-873f-64ac5d94dcf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0        date  negative  neutral  positive          open  \\\n",
              "0           1155  2017-11-12         4        1         2   6295.450195   \n",
              "1           1156  2017-11-13        13       20        12   5938.250000   \n",
              "2           1157  2017-11-14         0        5         3   6561.479980   \n",
              "3           1158  2017-11-15         6       17         5   6634.759766   \n",
              "4           1159  2017-11-16         5       14         4   7323.240234   \n",
              "...          ...         ...       ...      ...       ...           ...   \n",
              "2102        3257  2023-08-15         6       11         3  29408.048590   \n",
              "2103        3258  2023-08-16         7       10         5  29169.074020   \n",
              "2104        3259  2023-08-17         8        7         5  28699.802840   \n",
              "2105        3260  2023-08-18        19        8         2  26636.078402   \n",
              "2106        3261  2023-08-19         2        0         1  26047.832979   \n",
              "\n",
              "              high           low         close        volume  \n",
              "0      6625.049805   5519.009766   5950.069824  8.957350e+09  \n",
              "1      6811.189941   5844.290039   6559.490234  6.263250e+09  \n",
              "2      6764.979980   6461.750000   6635.750000  3.197110e+09  \n",
              "3      7342.250000   6634.759766   7315.540039  4.200880e+09  \n",
              "4      7967.379883   7176.580078   7871.689941  5.123810e+09  \n",
              "...            ...           ...           ...           ...  \n",
              "2102  29439.120422  29088.853277  29170.347206  1.264020e+10  \n",
              "2103  29221.975743  28701.779525  28701.779525  1.494927e+10  \n",
              "2104  28745.946525  25409.111603  26664.549993  3.112085e+10  \n",
              "2105  26808.195785  25668.922817  26049.556901  2.402624e+10  \n",
              "2106  26249.448384  25802.407889  26096.204551  1.063144e+10  \n",
              "\n",
              "[2107 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca640b9c-3ffa-4a46-a60e-d5176f45707e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1155</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6295.450195</td>\n",
              "      <td>6625.049805</td>\n",
              "      <td>5519.009766</td>\n",
              "      <td>5950.069824</td>\n",
              "      <td>8.957350e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1156</td>\n",
              "      <td>2017-11-13</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>5938.250000</td>\n",
              "      <td>6811.189941</td>\n",
              "      <td>5844.290039</td>\n",
              "      <td>6559.490234</td>\n",
              "      <td>6.263250e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1157</td>\n",
              "      <td>2017-11-14</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6561.479980</td>\n",
              "      <td>6764.979980</td>\n",
              "      <td>6461.750000</td>\n",
              "      <td>6635.750000</td>\n",
              "      <td>3.197110e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1158</td>\n",
              "      <td>2017-11-15</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>6634.759766</td>\n",
              "      <td>7342.250000</td>\n",
              "      <td>6634.759766</td>\n",
              "      <td>7315.540039</td>\n",
              "      <td>4.200880e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1159</td>\n",
              "      <td>2017-11-16</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>7323.240234</td>\n",
              "      <td>7967.379883</td>\n",
              "      <td>7176.580078</td>\n",
              "      <td>7871.689941</td>\n",
              "      <td>5.123810e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2102</th>\n",
              "      <td>3257</td>\n",
              "      <td>2023-08-15</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>29408.048590</td>\n",
              "      <td>29439.120422</td>\n",
              "      <td>29088.853277</td>\n",
              "      <td>29170.347206</td>\n",
              "      <td>1.264020e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2103</th>\n",
              "      <td>3258</td>\n",
              "      <td>2023-08-16</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>29169.074020</td>\n",
              "      <td>29221.975743</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>1.494927e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104</th>\n",
              "      <td>3259</td>\n",
              "      <td>2023-08-17</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>28699.802840</td>\n",
              "      <td>28745.946525</td>\n",
              "      <td>25409.111603</td>\n",
              "      <td>26664.549993</td>\n",
              "      <td>3.112085e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2105</th>\n",
              "      <td>3260</td>\n",
              "      <td>2023-08-18</td>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>26636.078402</td>\n",
              "      <td>26808.195785</td>\n",
              "      <td>25668.922817</td>\n",
              "      <td>26049.556901</td>\n",
              "      <td>2.402624e+10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>3261</td>\n",
              "      <td>2023-08-19</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26047.832979</td>\n",
              "      <td>26249.448384</td>\n",
              "      <td>25802.407889</td>\n",
              "      <td>26096.204551</td>\n",
              "      <td>1.063144e+10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2107 rows × 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca640b9c-3ffa-4a46-a60e-d5176f45707e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca640b9c-3ffa-4a46-a60e-d5176f45707e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca640b9c-3ffa-4a46-a60e-d5176f45707e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8e3b50df-6b12-43f4-935c-3f94168cc5cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e3b50df-6b12-43f4-935c-3f94168cc5cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8e3b50df-6b12-43f4-935c-3f94168cc5cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c28ca294-ac49-4425-b715-050da8961e00\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sentiment')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c28ca294-ac49-4425-b715-050da8961e00 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sentiment');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sentiment",
              "summary": "{\n  \"name\": \"sentiment\",\n  \"rows\": 2107,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 608,\n        \"min\": 1155,\n        \"max\": 3261,\n        \"num_unique_values\": 2107,\n        \"samples\": [\n          1901,\n          2790,\n          1409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2107,\n        \"samples\": [\n          \"2019-11-28\",\n          \"2022-05-05\",\n          \"2018-07-24\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 94,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          12,\n          25,\n          24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 0,\n        \"max\": 104,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          48,\n          1,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 71,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          23,\n          50,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16037.063537851274,\n        \"min\": 3236.2747733,\n        \"max\": 67549.7355807849,\n        \"num_unique_values\": 2106,\n        \"samples\": [\n          61609.5271462034,\n          6490.09,\n          9585.51480236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16441.178178098504,\n        \"min\": 3275.37782696,\n        \"max\": 68789.6259389221,\n        \"num_unique_values\": 2106,\n        \"samples\": [\n          62274.477085765,\n          6497.72,\n          9623.33703153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15569.198339738023,\n        \"min\": 3191.30356157,\n        \"max\": 66382.0610082114,\n        \"num_unique_values\": 2107,\n        \"samples\": [\n          7454.12179377,\n          35856.5161061082,\n          7705.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16030.3438071988,\n        \"min\": 3236.76164502,\n        \"max\": 67566.8300878775,\n        \"num_unique_values\": 2106,\n        \"samples\": [\n          60892.1806927008,\n          6482.35,\n          9536.89268563\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18997677370.772446,\n        \"min\": 2923670016.0,\n        \"max\": 350967941479.06,\n        \"num_unique_values\": 2107,\n        \"samples\": [\n          19050116751.27,\n          43106256317.32,\n          7277689856.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "market"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "N8kOyT8GpdbU",
        "outputId": "428fbb21-0790-46ae-e8cc-cb42b44a3193"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  treasury_yield_10y         gold       sp_500        nasdaq  \\\n",
              "0     2014-01-02               2.985  1225.000000  1831.979980   4143.069824   \n",
              "1     2014-01-03               2.995  1238.400024  1831.369995   4131.910156   \n",
              "2     2014-01-04               2.995  1238.400024  1831.369995   4131.910156   \n",
              "3     2014-01-05               2.995  1238.400024  1831.369995   4131.910156   \n",
              "4     2014-01-06               2.961  1237.800049  1826.770020   4113.680176   \n",
              "...          ...                 ...          ...          ...           ...   \n",
              "4012  2024-12-27               4.619  2617.199951  5970.839844  19722.029297   \n",
              "4013  2024-12-28               4.619  2617.199951  5970.839844  19722.029297   \n",
              "4014  2024-12-29               4.619  2617.199951  5970.839844  19722.029297   \n",
              "4015  2024-12-30               4.545  2606.100098  5906.939941  19486.789062   \n",
              "4016  2024-12-31               4.573  2629.199951  5881.629883  19310.789062   \n",
              "\n",
              "      volatility_index  dollar_index        wti  \n",
              "0                14.23     80.629997  95.440002  \n",
              "1                13.76     80.790001  93.959999  \n",
              "2                13.76     80.790001  93.959999  \n",
              "3                13.76     80.790001  93.959999  \n",
              "4                13.55     80.650002  93.430000  \n",
              "...                ...           ...        ...  \n",
              "4012             15.95    108.000000  70.599998  \n",
              "4013             15.95    108.000000  70.599998  \n",
              "4014             15.95    108.000000  70.599998  \n",
              "4015             17.40    108.129997  70.989998  \n",
              "4016             17.35    108.489998  71.720001  \n",
              "\n",
              "[4017 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d8626fe-5ace-4b42-bd1e-22ed06673e51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>treasury_yield_10y</th>\n",
              "      <th>gold</th>\n",
              "      <th>sp_500</th>\n",
              "      <th>nasdaq</th>\n",
              "      <th>volatility_index</th>\n",
              "      <th>dollar_index</th>\n",
              "      <th>wti</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>2.985</td>\n",
              "      <td>1225.000000</td>\n",
              "      <td>1831.979980</td>\n",
              "      <td>4143.069824</td>\n",
              "      <td>14.23</td>\n",
              "      <td>80.629997</td>\n",
              "      <td>95.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>2.995</td>\n",
              "      <td>1238.400024</td>\n",
              "      <td>1831.369995</td>\n",
              "      <td>4131.910156</td>\n",
              "      <td>13.76</td>\n",
              "      <td>80.790001</td>\n",
              "      <td>93.959999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>2.995</td>\n",
              "      <td>1238.400024</td>\n",
              "      <td>1831.369995</td>\n",
              "      <td>4131.910156</td>\n",
              "      <td>13.76</td>\n",
              "      <td>80.790001</td>\n",
              "      <td>93.959999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>2.995</td>\n",
              "      <td>1238.400024</td>\n",
              "      <td>1831.369995</td>\n",
              "      <td>4131.910156</td>\n",
              "      <td>13.76</td>\n",
              "      <td>80.790001</td>\n",
              "      <td>93.959999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>2.961</td>\n",
              "      <td>1237.800049</td>\n",
              "      <td>1826.770020</td>\n",
              "      <td>4113.680176</td>\n",
              "      <td>13.55</td>\n",
              "      <td>80.650002</td>\n",
              "      <td>93.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4012</th>\n",
              "      <td>2024-12-27</td>\n",
              "      <td>4.619</td>\n",
              "      <td>2617.199951</td>\n",
              "      <td>5970.839844</td>\n",
              "      <td>19722.029297</td>\n",
              "      <td>15.95</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>70.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4013</th>\n",
              "      <td>2024-12-28</td>\n",
              "      <td>4.619</td>\n",
              "      <td>2617.199951</td>\n",
              "      <td>5970.839844</td>\n",
              "      <td>19722.029297</td>\n",
              "      <td>15.95</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>70.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4014</th>\n",
              "      <td>2024-12-29</td>\n",
              "      <td>4.619</td>\n",
              "      <td>2617.199951</td>\n",
              "      <td>5970.839844</td>\n",
              "      <td>19722.029297</td>\n",
              "      <td>15.95</td>\n",
              "      <td>108.000000</td>\n",
              "      <td>70.599998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>2024-12-30</td>\n",
              "      <td>4.545</td>\n",
              "      <td>2606.100098</td>\n",
              "      <td>5906.939941</td>\n",
              "      <td>19486.789062</td>\n",
              "      <td>17.40</td>\n",
              "      <td>108.129997</td>\n",
              "      <td>70.989998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4016</th>\n",
              "      <td>2024-12-31</td>\n",
              "      <td>4.573</td>\n",
              "      <td>2629.199951</td>\n",
              "      <td>5881.629883</td>\n",
              "      <td>19310.789062</td>\n",
              "      <td>17.35</td>\n",
              "      <td>108.489998</td>\n",
              "      <td>71.720001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4017 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8626fe-5ace-4b42-bd1e-22ed06673e51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d8626fe-5ace-4b42-bd1e-22ed06673e51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d8626fe-5ace-4b42-bd1e-22ed06673e51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f2e18267-9bfc-47f2-ab22-c13cbd136325\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2e18267-9bfc-47f2-ab22-c13cbd136325')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f2e18267-9bfc-47f2-ab22-c13cbd136325 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3d951fd1-776d-495c-968e-215dd16af081\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('market')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3d951fd1-776d-495c-968e-215dd16af081 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('market');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "market",
              "summary": "{\n  \"name\": \"market\",\n  \"rows\": 4017,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 4017,\n        \"samples\": [\n          \"2016-12-08\",\n          \"2017-04-16\",\n          \"2021-06-12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"treasury_yield_10y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.006380636965841,\n        \"min\": 0.4990000128746032,\n        \"max\": 4.98799991607666,\n        \"num_unique_values\": 1832,\n        \"samples\": [\n          2.108999967575073,\n          4.624000072479248,\n          1.256999969482422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 387.2728188204558,\n        \"min\": 1050.800048828125,\n        \"max\": 2788.5,\n        \"num_unique_values\": 2275,\n        \"samples\": [\n          2011.5,\n          1894.300048828125,\n          1347.199951171875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sp_500\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1112.2986433738129,\n        \"min\": 1741.8900146484375,\n        \"max\": 6090.27001953125,\n        \"num_unique_values\": 2755,\n        \"samples\": [\n          6084.18994140625,\n          4486.22998046875,\n          2642.330078125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nasdaq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4232.055107808334,\n        \"min\": 3996.9599609375,\n        \"max\": 20173.890625,\n        \"num_unique_values\": 2759,\n        \"samples\": [\n          5160.08984375,\n          7577.56982421875,\n          13139.8701171875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.001960173690208,\n        \"min\": 9.140000343322754,\n        \"max\": 82.69000244140625,\n        \"num_unique_values\": 1433,\n        \"samples\": [\n          18.940000534057617,\n          10.109999656677246,\n          26.3799991607666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dollar_index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.520023206843813,\n        \"min\": 79.13999938964844,\n        \"max\": 114.11000061035156,\n        \"num_unique_values\": 1522,\n        \"samples\": [\n          102.6999969482422,\n          99.87999725341795,\n          104.4000015258789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wti\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19.810203490330668,\n        \"min\": -37.630001068115234,\n        \"max\": 123.6999969482422,\n        \"num_unique_values\": 2264,\n        \"samples\": [\n          112.20999908447266,\n          63.27000045776367,\n          60.45000076293945\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deletting unececssary columns and set date column as an index\n",
        "sentiment.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "sentiment[\"date\"] = pd.to_datetime(sentiment[\"date\"])\n",
        "sentiment.set_index(\"date\", inplace=True)\n",
        "\n",
        "market.rename(columns={\"Unnamed: 0\" : \"date\"}, inplace=True)\n",
        "market[\"date\"] = pd.to_datetime(market[\"date\"])\n",
        "market.set_index(\"date\", inplace=True)"
      ],
      "metadata": {
        "id": "JMTXgMGHp_vH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "market.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaXc9mxNqa4n",
        "outputId": "26def93c-d9b9-4a76-810e-c93911139886"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 4017 entries, 2014-01-02 to 2024-12-31\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   treasury_yield_10y  4017 non-null   float64\n",
            " 1   gold                4017 non-null   float64\n",
            " 2   sp_500              4017 non-null   float64\n",
            " 3   nasdaq              4017 non-null   float64\n",
            " 4   volatility_index    4017 non-null   float64\n",
            " 5   dollar_index        4017 non-null   float64\n",
            " 6   wti                 4017 non-null   float64\n",
            "dtypes: float64(7)\n",
            "memory usage: 251.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NtNLbS2qdwQ",
        "outputId": "5d9dd8d7-7bec-4c6f-b65b-8915cc3b9957"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2107 entries, 2017-11-12 to 2023-08-19\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   negative  2107 non-null   int64  \n",
            " 1   neutral   2107 non-null   int64  \n",
            " 2   positive  2107 non-null   int64  \n",
            " 3   open      2107 non-null   float64\n",
            " 4   high      2107 non-null   float64\n",
            " 5   low       2107 non-null   float64\n",
            " 6   close     2107 non-null   float64\n",
            " 7   volume    2107 non-null   float64\n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 148.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Technical indicators"
      ],
      "metadata": {
        "id": "q7p7FwYYpMsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3sEBwHFq1fe",
        "outputId": "f1faf67f-5046-4223-8192-d7af154970ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=5a7661192a52dbdfbe3b3377e971441b2c99c5667a3ce2a987567314cbb9b756\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ta.trend import EMAIndicator, MACD, ADXIndicator, PSARIndicator\n",
        "from ta.volatility import BollingerBands, AverageTrueRange, KeltnerChannel\n",
        "from ta.volume import OnBalanceVolumeIndicator, ChaikinMoneyFlowIndicator, AccDistIndexIndicator\n",
        "\n",
        "\n",
        "def add_technical_indicators(df):\n",
        "    # Trend Indicators\n",
        "    df['ema_5'] = EMAIndicator(close=df['close'], window=5).ema_indicator()\n",
        "    df['ema_20'] = EMAIndicator(close=df['close'], window=20).ema_indicator()\n",
        "    df['ema_50'] = EMAIndicator(close=df['close'], window=50).ema_indicator()\n",
        "\n",
        "    macd = MACD(close=df['close'])\n",
        "    df['macd'] = macd.macd()\n",
        "    df['signal'] = macd.macd_signal()\n",
        "    df['histogram'] = macd.macd_diff()\n",
        "\n",
        "    # Volatility Indicators\n",
        "    bb = BollingerBands(close=df['close'], window=20, window_dev=2)\n",
        "    df['bb_upper'] = bb.bollinger_hband()\n",
        "    df['bb_lower'] = bb.bollinger_lband()\n",
        "    df['bb_middle'] = bb.bollinger_mavg()\n",
        "\n",
        "    atr = AverageTrueRange(high=df['high'], low=df['low'], close=df['close'], window=14)\n",
        "    df['ATR'] = atr.average_true_range()\n",
        "\n",
        "    # Donchian Channels (manual)\n",
        "    df['donchian_upper'] = df['high'].rolling(window=20).max()\n",
        "    df['donchian_lower'] = df['low'].rolling(window=20).min()\n",
        "    df['donchian_middle'] = (df['donchian_upper'] + df['donchian_lower']) / 2\n",
        "\n",
        "    # Volume Indicators\n",
        "    df['obv'] = OnBalanceVolumeIndicator(close=df['close'], volume=df['volume']).on_balance_volume()\n",
        "\n",
        "    df['vwap'] = (df['close'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "HOjYteuMpN1c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = add_technical_indicators(sentiment)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "rzCdbbA0rF27",
        "outputId": "f78ad4e0-f49a-431d-ad93-f497dfcaf36e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            negative  neutral  positive         open         high  \\\n",
              "date                                                                \n",
              "2017-11-12         4        1         2  6295.450195  6625.049805   \n",
              "2017-11-13        13       20        12  5938.250000  6811.189941   \n",
              "2017-11-14         0        5         3  6561.479980  6764.979980   \n",
              "2017-11-15         6       17         5  6634.759766  7342.250000   \n",
              "2017-11-16         5       14         4  7323.240234  7967.379883   \n",
              "\n",
              "                    low        close        volume        ema_5  ema_20  ...  \\\n",
              "date                                                                     ...   \n",
              "2017-11-12  5519.009766  5950.069824  8.957350e+09          NaN     NaN  ...   \n",
              "2017-11-13  5844.290039  6559.490234  6.263250e+09          NaN     NaN  ...   \n",
              "2017-11-14  6461.750000  6635.750000  3.197110e+09          NaN     NaN  ...   \n",
              "2017-11-15  6634.759766  7315.540039  4.200880e+09          NaN     NaN  ...   \n",
              "2017-11-16  7176.580078  7871.689941  5.123810e+09  7055.819607     NaN  ...   \n",
              "\n",
              "            histogram  bb_upper  bb_lower  bb_middle  ATR  donchian_upper  \\\n",
              "date                                                                        \n",
              "2017-11-12        NaN       NaN       NaN        NaN  0.0             NaN   \n",
              "2017-11-13        NaN       NaN       NaN        NaN  0.0             NaN   \n",
              "2017-11-14        NaN       NaN       NaN        NaN  0.0             NaN   \n",
              "2017-11-15        NaN       NaN       NaN        NaN  0.0             NaN   \n",
              "2017-11-16        NaN       NaN       NaN        NaN  0.0             NaN   \n",
              "\n",
              "            donchian_lower  donchian_middle           obv         vwap  \n",
              "date                                                                    \n",
              "2017-11-12             NaN              NaN  8.957350e+09  5950.069824  \n",
              "2017-11-13             NaN              NaN  1.522060e+10  6200.845246  \n",
              "2017-11-14             NaN              NaN  1.841771e+10  6276.339884  \n",
              "2017-11-15             NaN              NaN  2.261859e+10  6469.347286  \n",
              "2017-11-16             NaN              NaN  2.774240e+10  6728.349287  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c418627a-520f-49c0-9be1-07d78112390b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_20</th>\n",
              "      <th>...</th>\n",
              "      <th>histogram</th>\n",
              "      <th>bb_upper</th>\n",
              "      <th>bb_lower</th>\n",
              "      <th>bb_middle</th>\n",
              "      <th>ATR</th>\n",
              "      <th>donchian_upper</th>\n",
              "      <th>donchian_lower</th>\n",
              "      <th>donchian_middle</th>\n",
              "      <th>obv</th>\n",
              "      <th>vwap</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-11-12</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>6295.450195</td>\n",
              "      <td>6625.049805</td>\n",
              "      <td>5519.009766</td>\n",
              "      <td>5950.069824</td>\n",
              "      <td>8.957350e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.957350e+09</td>\n",
              "      <td>5950.069824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-13</th>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>5938.250000</td>\n",
              "      <td>6811.189941</td>\n",
              "      <td>5844.290039</td>\n",
              "      <td>6559.490234</td>\n",
              "      <td>6.263250e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.522060e+10</td>\n",
              "      <td>6200.845246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-14</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>6561.479980</td>\n",
              "      <td>6764.979980</td>\n",
              "      <td>6461.750000</td>\n",
              "      <td>6635.750000</td>\n",
              "      <td>3.197110e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.841771e+10</td>\n",
              "      <td>6276.339884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-15</th>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>6634.759766</td>\n",
              "      <td>7342.250000</td>\n",
              "      <td>6634.759766</td>\n",
              "      <td>7315.540039</td>\n",
              "      <td>4.200880e+09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.261859e+10</td>\n",
              "      <td>6469.347286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-11-16</th>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>7323.240234</td>\n",
              "      <td>7967.379883</td>\n",
              "      <td>7176.580078</td>\n",
              "      <td>7871.689941</td>\n",
              "      <td>5.123810e+09</td>\n",
              "      <td>7055.819607</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.774240e+10</td>\n",
              "      <td>6728.349287</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c418627a-520f-49c0-9be1-07d78112390b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c418627a-520f-49c0-9be1-07d78112390b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c418627a-520f-49c0-9be1-07d78112390b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7963d4eb-f913-44a0-86ea-20a539ded167\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7963d4eb-f913-44a0-86ea-20a539ded167')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7963d4eb-f913-44a0-86ea-20a539ded167 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "NmDtCwDarQM-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EopHtRgxrTDZ",
        "outputId": "db3c5774-545a-4e7c-9cdf-34542ccc75b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2058 entries, 2017-12-31 to 2023-08-19\n",
            "Data columns (total 23 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   negative         2058 non-null   int64  \n",
            " 1   neutral          2058 non-null   int64  \n",
            " 2   positive         2058 non-null   int64  \n",
            " 3   open             2058 non-null   float64\n",
            " 4   high             2058 non-null   float64\n",
            " 5   low              2058 non-null   float64\n",
            " 6   close            2058 non-null   float64\n",
            " 7   volume           2058 non-null   float64\n",
            " 8   ema_5            2058 non-null   float64\n",
            " 9   ema_20           2058 non-null   float64\n",
            " 10  ema_50           2058 non-null   float64\n",
            " 11  macd             2058 non-null   float64\n",
            " 12  signal           2058 non-null   float64\n",
            " 13  histogram        2058 non-null   float64\n",
            " 14  bb_upper         2058 non-null   float64\n",
            " 15  bb_lower         2058 non-null   float64\n",
            " 16  bb_middle        2058 non-null   float64\n",
            " 17  ATR              2058 non-null   float64\n",
            " 18  donchian_upper   2058 non-null   float64\n",
            " 19  donchian_lower   2058 non-null   float64\n",
            " 20  donchian_middle  2058 non-null   float64\n",
            " 21  obv              2058 non-null   float64\n",
            " 22  vwap             2058 non-null   float64\n",
            "dtypes: float64(20), int64(3)\n",
            "memory usage: 385.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding days of the week as number\n",
        "df['day_number'] = df.index.weekday\n",
        "df[\"month\"] = df.index.month"
      ],
      "metadata": {
        "id": "kKkHWSuOrYG3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.join(market, how=\"left\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "zdjfJR5FrsTP",
        "outputId": "ec62681f-ee8d-4763-a296-bd570bd57327"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            negative  neutral  positive          open          high  \\\n",
              "date                                                                  \n",
              "2017-12-31         3       22         6  12897.700195  14377.400391   \n",
              "2018-01-01         4       15         1  14112.200195  14112.200195   \n",
              "2018-01-02        17       48         9  13625.000000  15444.599609   \n",
              "2018-01-03         5       38        13  14978.200195  15572.799805   \n",
              "2018-01-04        23       49        11  15270.700195  15739.700195   \n",
              "...              ...      ...       ...           ...           ...   \n",
              "2023-08-15         6       11         3  29408.048590  29439.120422   \n",
              "2023-08-16         7       10         5  29169.074020  29221.975743   \n",
              "2023-08-17         8        7         5  28699.802840  28745.946525   \n",
              "2023-08-18        19        8         2  26636.078402  26808.195785   \n",
              "2023-08-19         2        0         1  26047.832979  26249.448384   \n",
              "\n",
              "                     low         close        volume         ema_5  \\\n",
              "date                                                                 \n",
              "2017-12-31  12755.599609  14156.400391  1.213630e+10  14249.986749   \n",
              "2018-01-01  13154.700195  13657.200195  1.029120e+10  14052.391231   \n",
              "2018-01-02  13163.599609  14982.099609  1.684660e+10  14362.294024   \n",
              "2018-01-03  14844.500000  15201.000000  1.687190e+10  14641.862683   \n",
              "2018-01-04  14522.200195  15599.200195  2.178320e+10  14960.975187   \n",
              "...                  ...           ...           ...           ...   \n",
              "2023-08-15  29088.853277  29170.347206  1.264020e+10  29312.368589   \n",
              "2023-08-16  28701.779525  28701.779525  1.494927e+10  29108.838901   \n",
              "2023-08-17  25409.111603  26664.549993  3.112085e+10  28294.075932   \n",
              "2023-08-18  25668.922817  26049.556901  2.402624e+10  27545.902921   \n",
              "2023-08-19  25802.407889  26096.204551  1.063144e+10  27062.670131   \n",
              "\n",
              "                  ema_20  ...           obv          vwap  day_number  \\\n",
              "date                      ...                                           \n",
              "2017-12-31  14906.561549  ...  5.291101e+10  14279.542564           6   \n",
              "2018-01-01  14787.574753  ...  4.261981e+10  14267.278311           0   \n",
              "2018-01-02  14806.100930  ...  5.946641e+10  14289.617457           1   \n",
              "2018-01-03  14843.710365  ...  7.633831e+10  14317.276505           2   \n",
              "2018-01-04  14915.661778  ...  9.812151e+10  14365.611811           3   \n",
              "...                  ...  ...           ...           ...         ...   \n",
              "2023-08-15  29395.377865  ...  1.027359e+12  27085.362047           1   \n",
              "2023-08-16  29329.320880  ...  1.012409e+12  27085.814654           2   \n",
              "2023-08-17  29075.533177  ...  9.812885e+11  27085.569239           3   \n",
              "2023-08-18  28787.344960  ...  9.572623e+11  27085.103493           4   \n",
              "2023-08-19  28531.045874  ...  9.678937e+11  27084.906815           5   \n",
              "\n",
              "            treasury_yield_10y         gold       sp_500        nasdaq  \\\n",
              "date                                                                     \n",
              "2017-12-31               2.405  1306.300049  2673.610107   6903.390137   \n",
              "2018-01-01               2.405  1306.300049  2673.610107   6903.390137   \n",
              "2018-01-02               2.465  1313.699951  2695.810059   7006.899902   \n",
              "2018-01-03               2.447  1316.199951  2713.060059   7065.529785   \n",
              "2018-01-04               2.453  1319.400024  2723.989990   7077.910156   \n",
              "...                        ...          ...          ...           ...   \n",
              "2023-08-15               4.221  1902.500000  4437.859863  13631.049805   \n",
              "2023-08-16               4.258  1896.099976  4404.330078  13474.629883   \n",
              "2023-08-17               4.308  1884.099976  4370.359863  13316.929688   \n",
              "2023-08-18               4.251  1886.099976  4369.709961  13290.780273   \n",
              "2023-08-19               4.251  1886.099976  4369.709961  13290.780273   \n",
              "\n",
              "            volatility_index  dollar_index        wti  \n",
              "date                                                   \n",
              "2017-12-31         11.040000     92.120003  60.419998  \n",
              "2018-01-01         11.040000     92.120003  60.419998  \n",
              "2018-01-02          9.770000     91.849998  60.369999  \n",
              "2018-01-03          9.150000     92.160004  61.630001  \n",
              "2018-01-04          9.220000     91.849998  62.009998  \n",
              "...                      ...           ...        ...  \n",
              "2023-08-15         16.459999    103.209999  80.989998  \n",
              "2023-08-16         16.780001    103.419998  79.379997  \n",
              "2023-08-17         17.889999    103.440002  80.389999  \n",
              "2023-08-18         17.299999    103.379997  81.250000  \n",
              "2023-08-19         17.299999    103.379997  81.250000  \n",
              "\n",
              "[2058 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f4fba19-17c6-498c-b6a4-7c860d8c8623\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_20</th>\n",
              "      <th>...</th>\n",
              "      <th>obv</th>\n",
              "      <th>vwap</th>\n",
              "      <th>day_number</th>\n",
              "      <th>treasury_yield_10y</th>\n",
              "      <th>gold</th>\n",
              "      <th>sp_500</th>\n",
              "      <th>nasdaq</th>\n",
              "      <th>volatility_index</th>\n",
              "      <th>dollar_index</th>\n",
              "      <th>wti</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31</th>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>12897.700195</td>\n",
              "      <td>14377.400391</td>\n",
              "      <td>12755.599609</td>\n",
              "      <td>14156.400391</td>\n",
              "      <td>1.213630e+10</td>\n",
              "      <td>14249.986749</td>\n",
              "      <td>14906.561549</td>\n",
              "      <td>...</td>\n",
              "      <td>5.291101e+10</td>\n",
              "      <td>14279.542564</td>\n",
              "      <td>6</td>\n",
              "      <td>2.405</td>\n",
              "      <td>1306.300049</td>\n",
              "      <td>2673.610107</td>\n",
              "      <td>6903.390137</td>\n",
              "      <td>11.040000</td>\n",
              "      <td>92.120003</td>\n",
              "      <td>60.419998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>14112.200195</td>\n",
              "      <td>14112.200195</td>\n",
              "      <td>13154.700195</td>\n",
              "      <td>13657.200195</td>\n",
              "      <td>1.029120e+10</td>\n",
              "      <td>14052.391231</td>\n",
              "      <td>14787.574753</td>\n",
              "      <td>...</td>\n",
              "      <td>4.261981e+10</td>\n",
              "      <td>14267.278311</td>\n",
              "      <td>0</td>\n",
              "      <td>2.405</td>\n",
              "      <td>1306.300049</td>\n",
              "      <td>2673.610107</td>\n",
              "      <td>6903.390137</td>\n",
              "      <td>11.040000</td>\n",
              "      <td>92.120003</td>\n",
              "      <td>60.419998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-02</th>\n",
              "      <td>17</td>\n",
              "      <td>48</td>\n",
              "      <td>9</td>\n",
              "      <td>13625.000000</td>\n",
              "      <td>15444.599609</td>\n",
              "      <td>13163.599609</td>\n",
              "      <td>14982.099609</td>\n",
              "      <td>1.684660e+10</td>\n",
              "      <td>14362.294024</td>\n",
              "      <td>14806.100930</td>\n",
              "      <td>...</td>\n",
              "      <td>5.946641e+10</td>\n",
              "      <td>14289.617457</td>\n",
              "      <td>1</td>\n",
              "      <td>2.465</td>\n",
              "      <td>1313.699951</td>\n",
              "      <td>2695.810059</td>\n",
              "      <td>7006.899902</td>\n",
              "      <td>9.770000</td>\n",
              "      <td>91.849998</td>\n",
              "      <td>60.369999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-03</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>13</td>\n",
              "      <td>14978.200195</td>\n",
              "      <td>15572.799805</td>\n",
              "      <td>14844.500000</td>\n",
              "      <td>15201.000000</td>\n",
              "      <td>1.687190e+10</td>\n",
              "      <td>14641.862683</td>\n",
              "      <td>14843.710365</td>\n",
              "      <td>...</td>\n",
              "      <td>7.633831e+10</td>\n",
              "      <td>14317.276505</td>\n",
              "      <td>2</td>\n",
              "      <td>2.447</td>\n",
              "      <td>1316.199951</td>\n",
              "      <td>2713.060059</td>\n",
              "      <td>7065.529785</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>92.160004</td>\n",
              "      <td>61.630001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-04</th>\n",
              "      <td>23</td>\n",
              "      <td>49</td>\n",
              "      <td>11</td>\n",
              "      <td>15270.700195</td>\n",
              "      <td>15739.700195</td>\n",
              "      <td>14522.200195</td>\n",
              "      <td>15599.200195</td>\n",
              "      <td>2.178320e+10</td>\n",
              "      <td>14960.975187</td>\n",
              "      <td>14915.661778</td>\n",
              "      <td>...</td>\n",
              "      <td>9.812151e+10</td>\n",
              "      <td>14365.611811</td>\n",
              "      <td>3</td>\n",
              "      <td>2.453</td>\n",
              "      <td>1319.400024</td>\n",
              "      <td>2723.989990</td>\n",
              "      <td>7077.910156</td>\n",
              "      <td>9.220000</td>\n",
              "      <td>91.849998</td>\n",
              "      <td>62.009998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-15</th>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>29408.048590</td>\n",
              "      <td>29439.120422</td>\n",
              "      <td>29088.853277</td>\n",
              "      <td>29170.347206</td>\n",
              "      <td>1.264020e+10</td>\n",
              "      <td>29312.368589</td>\n",
              "      <td>29395.377865</td>\n",
              "      <td>...</td>\n",
              "      <td>1.027359e+12</td>\n",
              "      <td>27085.362047</td>\n",
              "      <td>1</td>\n",
              "      <td>4.221</td>\n",
              "      <td>1902.500000</td>\n",
              "      <td>4437.859863</td>\n",
              "      <td>13631.049805</td>\n",
              "      <td>16.459999</td>\n",
              "      <td>103.209999</td>\n",
              "      <td>80.989998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-16</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>29169.074020</td>\n",
              "      <td>29221.975743</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>1.494927e+10</td>\n",
              "      <td>29108.838901</td>\n",
              "      <td>29329.320880</td>\n",
              "      <td>...</td>\n",
              "      <td>1.012409e+12</td>\n",
              "      <td>27085.814654</td>\n",
              "      <td>2</td>\n",
              "      <td>4.258</td>\n",
              "      <td>1896.099976</td>\n",
              "      <td>4404.330078</td>\n",
              "      <td>13474.629883</td>\n",
              "      <td>16.780001</td>\n",
              "      <td>103.419998</td>\n",
              "      <td>79.379997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-17</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>28699.802840</td>\n",
              "      <td>28745.946525</td>\n",
              "      <td>25409.111603</td>\n",
              "      <td>26664.549993</td>\n",
              "      <td>3.112085e+10</td>\n",
              "      <td>28294.075932</td>\n",
              "      <td>29075.533177</td>\n",
              "      <td>...</td>\n",
              "      <td>9.812885e+11</td>\n",
              "      <td>27085.569239</td>\n",
              "      <td>3</td>\n",
              "      <td>4.308</td>\n",
              "      <td>1884.099976</td>\n",
              "      <td>4370.359863</td>\n",
              "      <td>13316.929688</td>\n",
              "      <td>17.889999</td>\n",
              "      <td>103.440002</td>\n",
              "      <td>80.389999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-18</th>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>26636.078402</td>\n",
              "      <td>26808.195785</td>\n",
              "      <td>25668.922817</td>\n",
              "      <td>26049.556901</td>\n",
              "      <td>2.402624e+10</td>\n",
              "      <td>27545.902921</td>\n",
              "      <td>28787.344960</td>\n",
              "      <td>...</td>\n",
              "      <td>9.572623e+11</td>\n",
              "      <td>27085.103493</td>\n",
              "      <td>4</td>\n",
              "      <td>4.251</td>\n",
              "      <td>1886.099976</td>\n",
              "      <td>4369.709961</td>\n",
              "      <td>13290.780273</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>103.379997</td>\n",
              "      <td>81.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-19</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>26047.832979</td>\n",
              "      <td>26249.448384</td>\n",
              "      <td>25802.407889</td>\n",
              "      <td>26096.204551</td>\n",
              "      <td>1.063144e+10</td>\n",
              "      <td>27062.670131</td>\n",
              "      <td>28531.045874</td>\n",
              "      <td>...</td>\n",
              "      <td>9.678937e+11</td>\n",
              "      <td>27084.906815</td>\n",
              "      <td>5</td>\n",
              "      <td>4.251</td>\n",
              "      <td>1886.099976</td>\n",
              "      <td>4369.709961</td>\n",
              "      <td>13290.780273</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>103.379997</td>\n",
              "      <td>81.250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2058 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f4fba19-17c6-498c-b6a4-7c860d8c8623')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f4fba19-17c6-498c-b6a4-7c860d8c8623 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f4fba19-17c6-498c-b6a4-7c860d8c8623');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f084e355-02a9-4d6d-a732-0f00174d61b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f084e355-02a9-4d6d-a732-0f00174d61b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f084e355-02a9-4d6d-a732-0f00174d61b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9d605937-ac07-4d0b-be87-09a075322a8d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d605937-ac07-4d0b-be87-09a075322a8d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding target variable\n",
        "df['target'] = df['close'].diff().apply(lambda x: 1 if x > 0 else 0)\n",
        "df[\"target\"] = df[\"target\"].shift(-1)"
      ],
      "metadata": {
        "id": "xDdnOcA4r4mx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "3grt02hPsZiw",
        "outputId": "e8990717-9b98-4e28-8336-cece7776adf4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            negative  neutral  positive          open          high  \\\n",
              "date                                                                  \n",
              "2017-12-31         3       22         6  12897.700195  14377.400391   \n",
              "2018-01-01         4       15         1  14112.200195  14112.200195   \n",
              "2018-01-02        17       48         9  13625.000000  15444.599609   \n",
              "2018-01-03         5       38        13  14978.200195  15572.799805   \n",
              "2018-01-04        23       49        11  15270.700195  15739.700195   \n",
              "...              ...      ...       ...           ...           ...   \n",
              "2023-08-14         5       14         6  29283.262943  29660.254339   \n",
              "2023-08-15         6       11         3  29408.048590  29439.120422   \n",
              "2023-08-16         7       10         5  29169.074020  29221.975743   \n",
              "2023-08-17         8        7         5  28699.802840  28745.946525   \n",
              "2023-08-18        19        8         2  26636.078402  26808.195785   \n",
              "\n",
              "                     low         close        volume         ema_5  \\\n",
              "date                                                                 \n",
              "2017-12-31  12755.599609  14156.400391  1.213630e+10  14249.986749   \n",
              "2018-01-01  13154.700195  13657.200195  1.029120e+10  14052.391231   \n",
              "2018-01-02  13163.599609  14982.099609  1.684660e+10  14362.294024   \n",
              "2018-01-03  14844.500000  15201.000000  1.687190e+10  14641.862683   \n",
              "2018-01-04  14522.200195  15599.200195  2.178320e+10  14960.975187   \n",
              "...                  ...           ...           ...           ...   \n",
              "2023-08-14  29124.105547  29408.442550  1.401370e+10  29383.379280   \n",
              "2023-08-15  29088.853277  29170.347206  1.264020e+10  29312.368589   \n",
              "2023-08-16  28701.779525  28701.779525  1.494927e+10  29108.838901   \n",
              "2023-08-17  25409.111603  26664.549993  3.112085e+10  28294.075932   \n",
              "2023-08-18  25668.922817  26049.556901  2.402624e+10  27545.902921   \n",
              "\n",
              "                  ema_20  ...          vwap  day_number  treasury_yield_10y  \\\n",
              "date                      ...                                                 \n",
              "2017-12-31  14906.561549  ...  14279.542564           6               2.405   \n",
              "2018-01-01  14787.574753  ...  14267.278311           0               2.405   \n",
              "2018-01-02  14806.100930  ...  14289.617457           1               2.465   \n",
              "2018-01-03  14843.710365  ...  14317.276505           2               2.447   \n",
              "2018-01-04  14915.661778  ...  14365.611811           3               2.453   \n",
              "...                  ...  ...           ...         ...                 ...   \n",
              "2023-08-14  29419.065303  ...  27084.868160           0               4.184   \n",
              "2023-08-15  29395.377865  ...  27085.362047           1               4.221   \n",
              "2023-08-16  29329.320880  ...  27085.814654           2               4.258   \n",
              "2023-08-17  29075.533177  ...  27085.569239           3               4.308   \n",
              "2023-08-18  28787.344960  ...  27085.103493           4               4.251   \n",
              "\n",
              "                   gold       sp_500        nasdaq  volatility_index  \\\n",
              "date                                                                   \n",
              "2017-12-31  1306.300049  2673.610107   6903.390137         11.040000   \n",
              "2018-01-01  1306.300049  2673.610107   6903.390137         11.040000   \n",
              "2018-01-02  1313.699951  2695.810059   7006.899902          9.770000   \n",
              "2018-01-03  1316.199951  2713.060059   7065.529785          9.150000   \n",
              "2018-01-04  1319.400024  2723.989990   7077.910156          9.220000   \n",
              "...                 ...          ...           ...               ...   \n",
              "2023-08-14  1910.599976  4489.720215  13788.330078         14.820000   \n",
              "2023-08-15  1902.500000  4437.859863  13631.049805         16.459999   \n",
              "2023-08-16  1896.099976  4404.330078  13474.629883         16.780001   \n",
              "2023-08-17  1884.099976  4370.359863  13316.929688         17.889999   \n",
              "2023-08-18  1886.099976  4369.709961  13290.780273         17.299999   \n",
              "\n",
              "            dollar_index        wti  target  \n",
              "date                                         \n",
              "2017-12-31     92.120003  60.419998     0.0  \n",
              "2018-01-01     92.120003  60.419998     1.0  \n",
              "2018-01-02     91.849998  60.369999     1.0  \n",
              "2018-01-03     92.160004  61.630001     1.0  \n",
              "2018-01-04     91.849998  62.009998     1.0  \n",
              "...                  ...        ...     ...  \n",
              "2023-08-14    103.190002  82.510002     0.0  \n",
              "2023-08-15    103.209999  80.989998     0.0  \n",
              "2023-08-16    103.419998  79.379997     0.0  \n",
              "2023-08-17    103.440002  80.389999     0.0  \n",
              "2023-08-18    103.379997  81.250000     1.0  \n",
              "\n",
              "[2057 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6c9113d-5019-44c3-a244-73138de7c16c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_20</th>\n",
              "      <th>...</th>\n",
              "      <th>vwap</th>\n",
              "      <th>day_number</th>\n",
              "      <th>treasury_yield_10y</th>\n",
              "      <th>gold</th>\n",
              "      <th>sp_500</th>\n",
              "      <th>nasdaq</th>\n",
              "      <th>volatility_index</th>\n",
              "      <th>dollar_index</th>\n",
              "      <th>wti</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-12-31</th>\n",
              "      <td>3</td>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>12897.700195</td>\n",
              "      <td>14377.400391</td>\n",
              "      <td>12755.599609</td>\n",
              "      <td>14156.400391</td>\n",
              "      <td>1.213630e+10</td>\n",
              "      <td>14249.986749</td>\n",
              "      <td>14906.561549</td>\n",
              "      <td>...</td>\n",
              "      <td>14279.542564</td>\n",
              "      <td>6</td>\n",
              "      <td>2.405</td>\n",
              "      <td>1306.300049</td>\n",
              "      <td>2673.610107</td>\n",
              "      <td>6903.390137</td>\n",
              "      <td>11.040000</td>\n",
              "      <td>92.120003</td>\n",
              "      <td>60.419998</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01</th>\n",
              "      <td>4</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>14112.200195</td>\n",
              "      <td>14112.200195</td>\n",
              "      <td>13154.700195</td>\n",
              "      <td>13657.200195</td>\n",
              "      <td>1.029120e+10</td>\n",
              "      <td>14052.391231</td>\n",
              "      <td>14787.574753</td>\n",
              "      <td>...</td>\n",
              "      <td>14267.278311</td>\n",
              "      <td>0</td>\n",
              "      <td>2.405</td>\n",
              "      <td>1306.300049</td>\n",
              "      <td>2673.610107</td>\n",
              "      <td>6903.390137</td>\n",
              "      <td>11.040000</td>\n",
              "      <td>92.120003</td>\n",
              "      <td>60.419998</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-02</th>\n",
              "      <td>17</td>\n",
              "      <td>48</td>\n",
              "      <td>9</td>\n",
              "      <td>13625.000000</td>\n",
              "      <td>15444.599609</td>\n",
              "      <td>13163.599609</td>\n",
              "      <td>14982.099609</td>\n",
              "      <td>1.684660e+10</td>\n",
              "      <td>14362.294024</td>\n",
              "      <td>14806.100930</td>\n",
              "      <td>...</td>\n",
              "      <td>14289.617457</td>\n",
              "      <td>1</td>\n",
              "      <td>2.465</td>\n",
              "      <td>1313.699951</td>\n",
              "      <td>2695.810059</td>\n",
              "      <td>7006.899902</td>\n",
              "      <td>9.770000</td>\n",
              "      <td>91.849998</td>\n",
              "      <td>60.369999</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-03</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>13</td>\n",
              "      <td>14978.200195</td>\n",
              "      <td>15572.799805</td>\n",
              "      <td>14844.500000</td>\n",
              "      <td>15201.000000</td>\n",
              "      <td>1.687190e+10</td>\n",
              "      <td>14641.862683</td>\n",
              "      <td>14843.710365</td>\n",
              "      <td>...</td>\n",
              "      <td>14317.276505</td>\n",
              "      <td>2</td>\n",
              "      <td>2.447</td>\n",
              "      <td>1316.199951</td>\n",
              "      <td>2713.060059</td>\n",
              "      <td>7065.529785</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>92.160004</td>\n",
              "      <td>61.630001</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-04</th>\n",
              "      <td>23</td>\n",
              "      <td>49</td>\n",
              "      <td>11</td>\n",
              "      <td>15270.700195</td>\n",
              "      <td>15739.700195</td>\n",
              "      <td>14522.200195</td>\n",
              "      <td>15599.200195</td>\n",
              "      <td>2.178320e+10</td>\n",
              "      <td>14960.975187</td>\n",
              "      <td>14915.661778</td>\n",
              "      <td>...</td>\n",
              "      <td>14365.611811</td>\n",
              "      <td>3</td>\n",
              "      <td>2.453</td>\n",
              "      <td>1319.400024</td>\n",
              "      <td>2723.989990</td>\n",
              "      <td>7077.910156</td>\n",
              "      <td>9.220000</td>\n",
              "      <td>91.849998</td>\n",
              "      <td>62.009998</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-14</th>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>29283.262943</td>\n",
              "      <td>29660.254339</td>\n",
              "      <td>29124.105547</td>\n",
              "      <td>29408.442550</td>\n",
              "      <td>1.401370e+10</td>\n",
              "      <td>29383.379280</td>\n",
              "      <td>29419.065303</td>\n",
              "      <td>...</td>\n",
              "      <td>27084.868160</td>\n",
              "      <td>0</td>\n",
              "      <td>4.184</td>\n",
              "      <td>1910.599976</td>\n",
              "      <td>4489.720215</td>\n",
              "      <td>13788.330078</td>\n",
              "      <td>14.820000</td>\n",
              "      <td>103.190002</td>\n",
              "      <td>82.510002</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-15</th>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>29408.048590</td>\n",
              "      <td>29439.120422</td>\n",
              "      <td>29088.853277</td>\n",
              "      <td>29170.347206</td>\n",
              "      <td>1.264020e+10</td>\n",
              "      <td>29312.368589</td>\n",
              "      <td>29395.377865</td>\n",
              "      <td>...</td>\n",
              "      <td>27085.362047</td>\n",
              "      <td>1</td>\n",
              "      <td>4.221</td>\n",
              "      <td>1902.500000</td>\n",
              "      <td>4437.859863</td>\n",
              "      <td>13631.049805</td>\n",
              "      <td>16.459999</td>\n",
              "      <td>103.209999</td>\n",
              "      <td>80.989998</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-16</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>29169.074020</td>\n",
              "      <td>29221.975743</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>28701.779525</td>\n",
              "      <td>1.494927e+10</td>\n",
              "      <td>29108.838901</td>\n",
              "      <td>29329.320880</td>\n",
              "      <td>...</td>\n",
              "      <td>27085.814654</td>\n",
              "      <td>2</td>\n",
              "      <td>4.258</td>\n",
              "      <td>1896.099976</td>\n",
              "      <td>4404.330078</td>\n",
              "      <td>13474.629883</td>\n",
              "      <td>16.780001</td>\n",
              "      <td>103.419998</td>\n",
              "      <td>79.379997</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-17</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>28699.802840</td>\n",
              "      <td>28745.946525</td>\n",
              "      <td>25409.111603</td>\n",
              "      <td>26664.549993</td>\n",
              "      <td>3.112085e+10</td>\n",
              "      <td>28294.075932</td>\n",
              "      <td>29075.533177</td>\n",
              "      <td>...</td>\n",
              "      <td>27085.569239</td>\n",
              "      <td>3</td>\n",
              "      <td>4.308</td>\n",
              "      <td>1884.099976</td>\n",
              "      <td>4370.359863</td>\n",
              "      <td>13316.929688</td>\n",
              "      <td>17.889999</td>\n",
              "      <td>103.440002</td>\n",
              "      <td>80.389999</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-08-18</th>\n",
              "      <td>19</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>26636.078402</td>\n",
              "      <td>26808.195785</td>\n",
              "      <td>25668.922817</td>\n",
              "      <td>26049.556901</td>\n",
              "      <td>2.402624e+10</td>\n",
              "      <td>27545.902921</td>\n",
              "      <td>28787.344960</td>\n",
              "      <td>...</td>\n",
              "      <td>27085.103493</td>\n",
              "      <td>4</td>\n",
              "      <td>4.251</td>\n",
              "      <td>1886.099976</td>\n",
              "      <td>4369.709961</td>\n",
              "      <td>13290.780273</td>\n",
              "      <td>17.299999</td>\n",
              "      <td>103.379997</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2057 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6c9113d-5019-44c3-a244-73138de7c16c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6c9113d-5019-44c3-a244-73138de7c16c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6c9113d-5019-44c3-a244-73138de7c16c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-45f60105-6522-4b6e-bbbc-e15c2d8e6caa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-45f60105-6522-4b6e-bbbc-e15c2d8e6caa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-45f60105-6522-4b6e-bbbc-e15c2d8e6caa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_16f166cd-3314-41f6-b20c-835715f9000e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16f166cd-3314-41f6-b20c-835715f9000e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "sMH2FAJXsaGZ",
        "outputId": "96c8f5f1-c4d6-4bfe-bd6d-9c2b2873e765"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          negative      neutral     positive          open          high  \\\n",
              "count  2057.000000  2057.000000  2057.000000   2057.000000   2057.000000   \n",
              "mean      7.817696    19.488576     7.002431  21004.635122  21497.563306   \n",
              "std       8.084267    14.870419     7.286954  16165.690135  16577.767872   \n",
              "min       0.000000     0.000000     0.000000   3236.274773   3275.377827   \n",
              "25%       2.000000     8.000000     2.000000   8162.191138   8285.959961   \n",
              "50%       5.000000    15.000000     4.000000  13952.400391  14511.799805   \n",
              "75%      11.000000    28.000000    10.000000  30409.561691  30959.965559   \n",
              "max      94.000000   104.000000    71.000000  67549.735581  68789.625939   \n",
              "\n",
              "                low         close        volume         ema_5        ema_20  \\\n",
              "count   2057.000000   2057.000000  2.057000e+03   2057.000000   2057.000000   \n",
              "mean   20458.472959  21009.051385  2.573870e+10  20996.169398  20945.309391   \n",
              "std    15690.610557  16160.980735  1.906061e+10  16126.069471  16002.161812   \n",
              "min     3191.303562   3236.761645  2.923670e+09   3304.842540   3525.493275   \n",
              "25%     7925.729980   8165.009766  1.272690e+10   8172.917944   8148.371866   \n",
              "50%    13580.472071  14133.707153  2.313231e+10  14362.294024  14139.440603   \n",
              "75%    29892.226032  30399.066385  3.448336e+10  30388.362742  30515.112803   \n",
              "max    66382.061008  67566.830088  3.509679e+11  64988.454794  63208.295961   \n",
              "\n",
              "       ...          vwap   day_number  treasury_yield_10y         gold  \\\n",
              "count  ...   2057.000000  2057.000000         2057.000000  2057.000000   \n",
              "mean   ...  16849.600796     2.999028            2.246991  1642.772094   \n",
              "std    ...   8305.398139     2.000486            1.003388   255.127906   \n",
              "min    ...   7965.222049     0.000000            0.499000  1176.199951   \n",
              "25%    ...   8760.565102     1.000000            1.489000  1346.599976   \n",
              "50%    ...  12391.796198     3.000000            2.296000  1737.400024   \n",
              "75%    ...  27045.933985     5.000000            2.971000  1847.300049   \n",
              "max    ...  28257.923065     6.000000            4.308000  2051.500000   \n",
              "\n",
              "            sp_500        nasdaq  volatility_index  dollar_index          wti  \\\n",
              "count  2057.000000   2057.000000       2057.000000   2057.000000  2057.000000   \n",
              "mean   3530.906943  10655.247877         20.789106     97.336743    65.942193   \n",
              "std     675.544216   2737.470600          8.000672      5.190883    19.169961   \n",
              "min    2237.399902   6192.919922          9.150000     88.589996   -37.630001   \n",
              "25%    2876.320068   7924.160156         15.440000     93.379997    54.700001   \n",
              "50%    3483.810059  10890.849609         19.100000     96.790001    65.550003   \n",
              "75%    4137.290039  13119.429688         24.350000    100.040001    76.099998   \n",
              "max    4796.560059  16057.440430         82.690002    114.110001   123.699997   \n",
              "\n",
              "            target  \n",
              "count  2057.000000  \n",
              "mean      0.510938  \n",
              "std       0.500002  \n",
              "min       0.000000  \n",
              "25%       0.000000  \n",
              "50%       1.000000  \n",
              "75%       1.000000  \n",
              "max       1.000000  \n",
              "\n",
              "[8 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11216af8-1f22-4e38-8cf8-a3cf0f0c4f0d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>ema_5</th>\n",
              "      <th>ema_20</th>\n",
              "      <th>...</th>\n",
              "      <th>vwap</th>\n",
              "      <th>day_number</th>\n",
              "      <th>treasury_yield_10y</th>\n",
              "      <th>gold</th>\n",
              "      <th>sp_500</th>\n",
              "      <th>nasdaq</th>\n",
              "      <th>volatility_index</th>\n",
              "      <th>dollar_index</th>\n",
              "      <th>wti</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2.057000e+03</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "      <td>2057.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.817696</td>\n",
              "      <td>19.488576</td>\n",
              "      <td>7.002431</td>\n",
              "      <td>21004.635122</td>\n",
              "      <td>21497.563306</td>\n",
              "      <td>20458.472959</td>\n",
              "      <td>21009.051385</td>\n",
              "      <td>2.573870e+10</td>\n",
              "      <td>20996.169398</td>\n",
              "      <td>20945.309391</td>\n",
              "      <td>...</td>\n",
              "      <td>16849.600796</td>\n",
              "      <td>2.999028</td>\n",
              "      <td>2.246991</td>\n",
              "      <td>1642.772094</td>\n",
              "      <td>3530.906943</td>\n",
              "      <td>10655.247877</td>\n",
              "      <td>20.789106</td>\n",
              "      <td>97.336743</td>\n",
              "      <td>65.942193</td>\n",
              "      <td>0.510938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.084267</td>\n",
              "      <td>14.870419</td>\n",
              "      <td>7.286954</td>\n",
              "      <td>16165.690135</td>\n",
              "      <td>16577.767872</td>\n",
              "      <td>15690.610557</td>\n",
              "      <td>16160.980735</td>\n",
              "      <td>1.906061e+10</td>\n",
              "      <td>16126.069471</td>\n",
              "      <td>16002.161812</td>\n",
              "      <td>...</td>\n",
              "      <td>8305.398139</td>\n",
              "      <td>2.000486</td>\n",
              "      <td>1.003388</td>\n",
              "      <td>255.127906</td>\n",
              "      <td>675.544216</td>\n",
              "      <td>2737.470600</td>\n",
              "      <td>8.000672</td>\n",
              "      <td>5.190883</td>\n",
              "      <td>19.169961</td>\n",
              "      <td>0.500002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3236.274773</td>\n",
              "      <td>3275.377827</td>\n",
              "      <td>3191.303562</td>\n",
              "      <td>3236.761645</td>\n",
              "      <td>2.923670e+09</td>\n",
              "      <td>3304.842540</td>\n",
              "      <td>3525.493275</td>\n",
              "      <td>...</td>\n",
              "      <td>7965.222049</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499000</td>\n",
              "      <td>1176.199951</td>\n",
              "      <td>2237.399902</td>\n",
              "      <td>6192.919922</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>88.589996</td>\n",
              "      <td>-37.630001</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8162.191138</td>\n",
              "      <td>8285.959961</td>\n",
              "      <td>7925.729980</td>\n",
              "      <td>8165.009766</td>\n",
              "      <td>1.272690e+10</td>\n",
              "      <td>8172.917944</td>\n",
              "      <td>8148.371866</td>\n",
              "      <td>...</td>\n",
              "      <td>8760.565102</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.489000</td>\n",
              "      <td>1346.599976</td>\n",
              "      <td>2876.320068</td>\n",
              "      <td>7924.160156</td>\n",
              "      <td>15.440000</td>\n",
              "      <td>93.379997</td>\n",
              "      <td>54.700001</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>13952.400391</td>\n",
              "      <td>14511.799805</td>\n",
              "      <td>13580.472071</td>\n",
              "      <td>14133.707153</td>\n",
              "      <td>2.313231e+10</td>\n",
              "      <td>14362.294024</td>\n",
              "      <td>14139.440603</td>\n",
              "      <td>...</td>\n",
              "      <td>12391.796198</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.296000</td>\n",
              "      <td>1737.400024</td>\n",
              "      <td>3483.810059</td>\n",
              "      <td>10890.849609</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>96.790001</td>\n",
              "      <td>65.550003</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>11.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>30409.561691</td>\n",
              "      <td>30959.965559</td>\n",
              "      <td>29892.226032</td>\n",
              "      <td>30399.066385</td>\n",
              "      <td>3.448336e+10</td>\n",
              "      <td>30388.362742</td>\n",
              "      <td>30515.112803</td>\n",
              "      <td>...</td>\n",
              "      <td>27045.933985</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.971000</td>\n",
              "      <td>1847.300049</td>\n",
              "      <td>4137.290039</td>\n",
              "      <td>13119.429688</td>\n",
              "      <td>24.350000</td>\n",
              "      <td>100.040001</td>\n",
              "      <td>76.099998</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>94.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>67549.735581</td>\n",
              "      <td>68789.625939</td>\n",
              "      <td>66382.061008</td>\n",
              "      <td>67566.830088</td>\n",
              "      <td>3.509679e+11</td>\n",
              "      <td>64988.454794</td>\n",
              "      <td>63208.295961</td>\n",
              "      <td>...</td>\n",
              "      <td>28257.923065</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.308000</td>\n",
              "      <td>2051.500000</td>\n",
              "      <td>4796.560059</td>\n",
              "      <td>16057.440430</td>\n",
              "      <td>82.690002</td>\n",
              "      <td>114.110001</td>\n",
              "      <td>123.699997</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11216af8-1f22-4e38-8cf8-a3cf0f0c4f0d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11216af8-1f22-4e38-8cf8-a3cf0f0c4f0d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11216af8-1f22-4e38-8cf8-a3cf0f0c4f0d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7eb9e93-d291-40c5-a096-59429cdd55a7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7eb9e93-d291-40c5-a096-59429cdd55a7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7eb9e93-d291-40c5-a096-59429cdd55a7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling report for EDA"
      ],
      "metadata": {
        "id": "kuEhT3XZtREZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata-profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t73_ZJBrs7UT",
        "outputId": "ff4c4a41-7fff-49bc-dc36-3dfdecbf315a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ydata-profiling\n",
            "  Downloading ydata_profiling-4.16.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: scipy<1.16,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (1.14.1)\n",
            "Requirement already satisfied: pandas!=1.4.0,<3.0,>1.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (2.2.2)\n",
            "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (3.10.0)\n",
            "Requirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (2.11.3)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (6.0.2)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (3.1.6)\n",
            "Collecting visions<0.8.2,>=0.7.5 (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
            "  Downloading visions-0.8.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.2,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (2.0.2)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
            "  Downloading phik-0.12.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (2.32.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (4.67.1)\n",
            "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (0.13.2)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
            "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (0.14.4)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (4.4.2)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (1.9.4)\n",
            "Collecting dacite>=1.8 (from ydata-profiling)\n",
            "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba<=0.61,>=0.56.0 in /usr/local/lib/python3.11/dist-packages (from ydata-profiling) (0.60.0)\n",
            "Collecting PyWavelets (from imagehash==4.3.1->ydata-profiling)\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from imagehash==4.3.1->ydata-profiling) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<=0.61,>=0.56.0->ydata-profiling) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.2)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ydata-profiling) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ydata-profiling) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ydata-profiling) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2025.1.31)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.11/dist-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (25.3.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling) (3.4.2)\n",
            "Collecting puremagic (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling)\n",
            "  Downloading puremagic-1.28-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<=3.10,>=3.5->ydata-profiling) (1.17.0)\n",
            "Downloading ydata_profiling-4.16.1-py2.py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.1/400.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
            "Downloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
            "Downloading phik-0.12.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (687 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m687.8/687.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading visions-0.8.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading puremagic-1.28-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=a9dd02d47eaf6366b2cdad4a95a901e32ac4a88aa4483b9e48be4635b9d725c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/55/1a/19cd535375ed1ede0c996405ebffe34b196d78e2d9545723a2\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: puremagic, htmlmin, PyWavelets, multimethod, dacite, imagehash, visions, phik, ydata-profiling\n",
            "Successfully installed PyWavelets-1.8.0 dacite-1.9.2 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.12 phik-0.12.4 puremagic-1.28 visions-0.8.1 ydata-profiling-4.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"from ydata_profiling import ProfileReport\n",
        "\n",
        "profile = ProfileReport(df, title=\"Mulitmodal dataset for bitcoin direction prediciton\", explorative=True)\n",
        "\n",
        "# Save the report to an HTML file\n",
        "profile.to_file(\"multimodal_report.html\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e4f057e1841743bcb6c1a033450f37c0",
            "3166eada9b974ce8ae4266f4b783f831",
            "55cfda073b6a4f3a871a56fefa2cd0fb",
            "708dee3383774ae39a1ee40d228e284d",
            "08148c152ea647ecb496cc31cc02e57e",
            "b994196d866a46778dc64d0bc3813ef6",
            "5594103c4e5a47c58380f1a94933921b",
            "c903471edd544ae58d51c250db4ef811",
            "e00f6d210e0f4b33933bd5143ed2259f",
            "0468174536d04af7925728529218d685",
            "cc2fe1433b894bb79d77335f81a0e677"
          ]
        },
        "id": "B_w1IEg2tYkB",
        "outputId": "0ee68023-23e5-4b88-b979-ca7f6d3c4c62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
              "                <p>\n",
              "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
              "                </p>\n",
              "            </div>\n",
              "            "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4f057e1841743bcb6c1a033450f37c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/32 [00:00<?, ?it/s]\u001b[A\n",
            " 25%|██▌       | 8/32 [00:00<00:00, 62.86it/s]\u001b[A\n",
            " 47%|████▋     | 15/32 [00:00<00:00, 56.71it/s]\u001b[A\n",
            "100%|██████████| 32/32 [00:00<00:00, 67.01it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/ydata_profiling/model/pandas/discretize_pandas.py:52: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[9 0 1 ... 3 4 6]' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
            "  discretized_df.loc[:, column] = self._discretize_column(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9b8f7caa045c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Save the report to an HTML file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multimodal_report.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, output_file, silent)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mcreate_html_assets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\".html\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36mto_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36mhtml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_html\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36m_render_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mydata_profiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflavours\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTMLReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         with tqdm(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36mreport\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRoot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_report_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/profile_report.py\u001b[0m in \u001b[0;36mdescription_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdescription_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBaseDescription\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_description_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             self._description_set = describe_df(\n\u001b[0m\u001b[1;32m    271\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/model/describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(config, df, summarizer, typeset, sample)\u001b[0m\n\u001b[1;32m    143\u001b[0m         }\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscatter_tasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             scatter_matrix[x][y] = progress(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mget_scatter_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"scatter {x}, {y}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )(config, df, x, y, interval_columns)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/utils/progress_bar.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/model/pairwise.py\u001b[0m in \u001b[0;36mget_scatter_plot\u001b[0;34m(config, df, x, y, continuous_variables)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recreate_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/visualisation/plot.py\u001b[0m in \u001b[0;36mscatter_pairwise\u001b[0;34m(config, series1, series2, x_label, y_label)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_360_n0sc0pe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ydata_profiling/visualisation/utils.py\u001b[0m in \u001b[0;36mplot_360_n0sc0pe\u001b[0;34m(config, image_format, bbox_extra_artists, bbox_inches)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mimage_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             plt.savefig(\n\u001b[0m\u001b[1;32m     74\u001b[0m                 \u001b[0mimage_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;31m# savefig default implementation has no return, so mypy is unhappy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m     \u001b[0;31m# presumably this is here because subclasses can return?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[func-returns-value]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Need this if 'transparent=True', to reset colors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3488\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3489\u001b[0m                     \u001b[0m_recursively_make_axes_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3490\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3492\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2182\u001b[0m                 \u001b[0;31m# force the figure dpi to 72), so we need to set it again here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m                     result = print_method(\n\u001b[0m\u001b[1;32m   2185\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                         \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                 \"bbox_inches_restore\"}\n\u001b[1;32m   2039\u001b[0m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptional_kws\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m             print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n\u001b[0m\u001b[1;32m   2041\u001b[0m                 *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n\u001b[1;32m   2042\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Let third-parties do as they see fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/backends/backend_svg.py\u001b[0m in \u001b[0;36mprint_svg\u001b[0;34m(self, filename, bbox_inches_restore, metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mRendererSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_dpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m                 bbox_inches_restore=bbox_inches_restore)\n\u001b[0;32m-> 1351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rasterizing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3258\u001b[0m                     renderer, self, artists, self.suppressComposite)\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3179\u001b[0m             \u001b[0m_draw_rasterized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists_rasterized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3181\u001b[0;31m         mimage._draw_list_compositing_images(\n\u001b[0m\u001b[1;32m   3182\u001b[0m             renderer, self, artists, self.get_figure(root=True).suppressComposite)\n\u001b[1;32m   3183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1416\u001b[0m         \u001b[0mtlb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ticklabel_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_ticks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m             \u001b[0;31m# Update the new tick label properties from the old.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m             \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_tick_props\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \"_tick_class or reimplement _get_tick()\")\n\u001b[1;32m   1602\u001b[0m         \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_major_tick_kw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmajor\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tick_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_tick_label_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the y loc is 3 points below the min of y axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text1_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         self.label1.set(\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mverticalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArtist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{cls.__qualname__}.set\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;31m# Artist._update_set_signature_and_docstring() at the end of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;31m# module.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_internal_update\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mlack\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprenormalization\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaintain\u001b[0m \u001b[0mbackcompatibility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \"\"\"\n\u001b[0;32m-> 1233\u001b[0;31m         return self._update_props(\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{cls.__name__}.set() got an unexpected keyword argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \"{prop_name!r}\")\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36m_update_props\u001b[0;34m(self, props, errfmt)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"set_{k}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                         raise AttributeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x550 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"multimodal_dataset.csv\")"
      ],
      "metadata": {
        "id": "tqMjJQ6cvkYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling and Normalization"
      ],
      "metadata": {
        "id": "FKcYV2zHviL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating different version of datasets**\n",
        "- Scaled dataset\n",
        "- Normalized dataset\n",
        "- Log transformation dataset\n",
        "- Log and Normalized dataset"
      ],
      "metadata": {
        "id": "FVZlxOaIxKbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "target_feature = 'target'  # Replace 'target' with the actual target column name\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[target_feature])\n",
        "y = df[target_feature]\n",
        "\n",
        "# Initialize StandardScaler and MinMaXScaler\n",
        "standard_scaler = StandardScaler()\n",
        "minmax_scaler = MinMaxScaler()\n",
        "\n",
        "features_log = X.copy()\n",
        "for column in features_log.columns:\n",
        "    # Applying log transformation. Adjust the shift if necessary.\n",
        "    features_log[column] = np.log(features_log[column] + 1)\n",
        "\n",
        "# Log transformed dataset\n",
        "df_log_transformed = features_log.copy()\n",
        "df_log_transformed[target_feature] = y\n",
        "\n",
        "# Log normalized dataset\n",
        "log_normalized_features = minmax_scaler.fit_transform(features_log)\n",
        "log_norm_features_df = pd.DataFrame(log_normalized_features, index=features_log.index, columns=features_log.columns)\n",
        "df_log_norm = log_norm_features_df.copy()\n",
        "df_log_norm[target_feature] = y\n",
        "\n",
        "# Fit the scaler to the features and transform them\n",
        "scaled_features = standard_scaler.fit_transform(X)\n",
        "normalized_features = minmax_scaler.fit_transform(X)\n",
        "\n",
        "# Convert the scaled features back to a DataFrame\n",
        "scaled_features_df = pd.DataFrame(scaled_features, index=X.index, columns=X.columns)\n",
        "norm_features_df = pd.DataFrame(normalized_features, index=X.index, columns=X.columns)\n",
        "\n",
        "\n",
        "# Reattach the target feature back to the DataFrame\n",
        "df_scaled = scaled_features_df.copy()\n",
        "df_scaled[target_feature] = y\n",
        "\n",
        "df_norm = norm_features_df.copy()\n",
        "df_norm[target_feature] = y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX9XdKavt0SK",
        "outputId": "dfbc89b3-b226-4f2e-827f-5eb02dbe5ff6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets version collection"
      ],
      "metadata": {
        "id": "w2h6HDBT0VJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = {\n",
        "    \"scaled\": df_scaled,\n",
        "    \"normalized\": df_norm,\n",
        "    \"log_transformed\": df_log_transformed,\n",
        "    \"log_normalized\": df_log_norm\n",
        "}"
      ],
      "metadata": {
        "id": "hNq1MXy4yr3N"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving transformed datasets"
      ],
      "metadata": {
        "id": "TUAN2n9IOD78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df_name, df in dfs.items():\n",
        "    df.to_csv(f\"{df_name}_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "b0YheknDOGc8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sHu-63YEcYkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM training and evaluation"
      ],
      "metadata": {
        "id": "KNlmasID0cyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to create sequence according to the window size"
      ],
      "metadata": {
        "id": "PAL26BQq0ix3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_sequences(data, feature_cols, target_col, window_size=60):\n",
        "    X, y = [], []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        # Range of data for this window\n",
        "        seq_x = data[feature_cols].iloc[i:i+window_size].values\n",
        "        # Target is the \"day after the window\"\n",
        "        seq_y = data[target_col].iloc[i+window_size]\n",
        "\n",
        "        X.append(seq_x)\n",
        "        y.append(seq_y)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "A3J-7mNK0Y4z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to split data to train and test"
      ],
      "metadata": {
        "id": "CSHD7ixc085B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split(df):\n",
        "  train_size = int(len(df) * 0.8)\n",
        "  train_data = df[:train_size]\n",
        "  test_data = df[train_size:]\n",
        "\n",
        "  return train_data, test_data"
      ],
      "metadata": {
        "id": "5W0Ijacn08bt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to create a model"
      ],
      "metadata": {
        "id": "AaAtnCaw1jM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "def create_model(X_train):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Model layers\n",
        "  model.add(LSTM(units=128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "  model.add(LSTM(units=64, return_sequences=True))\n",
        "  model.add(LSTM(units=32, return_sequences=False))\n",
        "  model.add(Dense(units=50, activation=\"relu\"))\n",
        "  model.add(Dense(units=30, activation=\"relu\"))\n",
        "  model.add(Dense(units=30, activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "pa1K8zzr1fEd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot model to see visual architecture\n",
        "from tensorflow.keras.utils import plot_model\n",
        "feature_cols = [col for col in dfs[\"log_normalized\"].columns if col != \"target\"]\n",
        "target_col = \"target\"\n",
        "X_train = create_sequences(dfs[\"log_normalized\"], feature_cols, target_col, window_size=60)[0]\n",
        "model = create_model(X_train)\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_yr4b9WSZm9F",
        "outputId": "847deda1-6ee5-440f-9d39-a24dc1967657"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABHYAAAjQCAYAAABR1KgHAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdd3xO5/8/8NedHRkSQYwUNVujRm2laIj5RW2xW0XVKGqrVTNKtCoUjRVEaakRqtSMvWLUiBkxQjbZcv3+8Mv9yck590ruO8ktr+fjcR6PnHOuc53rvs+57/vK+1xDJYQQICIiIiIiIiIic/O7RV6XgIiIiIiIiIiIsoeBHSIiIiIiIiIiM8XADhERERERERGRmWJgh4iIiIiIiIjITDGwQ0RERERERERkphjYISIiIiIiIiIyUwzsEBERERERERGZKQZ2iIiIiIiIiIjMFAM7RERERERERERmioEdIiIiIiIiIiIzZaVPoiNHjqBv376mLgsRERERERERUYHn5OSE//77T6+0egV2kpKSEB4enqNCERERERERERGRbk5OTnqnZVcsIiIiIiIiIiIzxcAOEREREREREZGZYmCHiIiIiIiIiMhMMbBDRERERERERGSmGNghIiIiIiIiIjJTDOwQEREREREREZkpBnaIiIiIiIiIiMwUAztERERERERERGaKgR0iIiIiIiIiIjPFwA4RERERERERkZliYIeIiIiIiIiIyEwxsENEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiIiIiIiIiIzBQDO0REREREREREZoqBHSIiIiIiIiIiM8XADhERERERERGRmWJgh4iIiIiIiIjITDGwQ0RERERERERkphjYISIiIiIiIiIyUwzsEBERERERERGZKQZ2iIiIiIiIiIjMFAM7RERERERERERmioEdIiIiIiIiIiIzxcAOEREREREREZGZYmCHiIiIiIiIiMhMMbBDRERERERERGSmGNghIiIiIiIiIjJTDOwQEREREREREZkpBnaIiIiIiIiIiMwUAztERERERERERGaKgR0iIiIiIiIiIjPFwA4RERERERERkZliYIeIiIiIiIiIyEwxsENEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiISG8vX76EEEK2eHh45HXRiMyStbU1/v33X/Vn6dGjR3B3d8/rYpEJdevWDenp6epr/s033+R1kYiIyMwxsENERESUR1auXInmzZsDABISEtC5c2c8f/48bwtFJrV9+3bMnj1bve7r64s2bdrkYYmIiMjcMbBDREREao0aNcK8efNw4sQJPHr0CK9evUJycjKeP3+Oq1evYv369RgyZAgKFy6sd55HjhxRbOll6DJt2jS9zmdjY4OuXbtixYoVOHPmDJ48eYLXr18jJSUFL1++xJ07d/Dnn39i6tSpqFKlSnbfqhwbNWoUBg8erF4fNmwYLl68KEv35ZdfSt6H/fv350r5HB0d0blzZ/z00084ePAg7t+/j+joaKSkpCA5ORlRUVF4+PAhDh8+DD8/P3Tv3h3Ozs5a87SysjLKvaBtefDggey8Wd/DjKV27dpGea+GDx+umL+jo6Ni+lmzZmHv3r0AAEtLSwQGBqJ8+fJGKQsRERVAQg9BQUECABcuXLhwKeDLy5cvFX8nPDw88rxsAMTcuXMl5Ro/fnyel8lcljp16ogTJ07oUy0QQgiRkJAgfHx8hL29vc68L1++rHe+2kybNk3reSwsLMTIkSM13qeaHDp0SHz44Ye5+n5Xr15dJCUlqcuwY8cOjWm//PJLSXn3799v0rK5u7uLpUuXioSEBIOv0evXr4WPj49wcXFRzNvKysrgPA314MEDne9hhuXLlxvlPTt79qxi/o6OjhqPKVGihOReDQ4OFpaWlrl6H3LhwoULl/y7ODk56fvTt40tdoiI6J1gYWGBfv365XUxzFLfvn0RHByMJk2a6H2Mvb09xo8fj3PnzqFYsWJa07q4uOS0iDrZ2dlh9+7d+Omnn+Dm5mbQsS1btsSlS5fQoUMHE5VOytraGgEBAbC1tQXwduyqoUOH5sq5dfn0009x5coVjBkzBvb29gYfX6hQIfV98cEHH5ighMbl7e0NOzu7HOVRrVo11KtXz+Djnj17Jhlfp1GjRpg0aVKOykJERAUTAztERPRO8PT0xHvvvZfXxTA7np6e8Pf3VwcZDFWtWjXs27cPlpaWGtPkRmBn5cqVaNeuXbaPt7W1xfbt21G1alUjlkrZiBEj8NFHH6nXZ86ciZcvX5r8vLrUqFED+/btkwzenJSUhI0bN6Jnz56oWrUqihQpAmtra9jb26NEiRJo2rQppkyZghs3bkjyqlixIvbu3QtXV1fJ9rS0NKhUKr2WtWvXSo6dPHmyXseVK1dO52tNTU0F8Pbe/Pzzz7P5jr2VuTtdWlqaQcdu3boVJ0+eVK9PnTqV32NERGQ4fdr1sCsWFy5cuHAB8ndXrC1btsjKxa5Y2hdbW1vx4MEDfZv5avXVV18pnkOlUok3b97I0h88eNBor6NBgwYay3XixAnRsmVL4eTkJGxsbESlSpXEnDlzRFpammL63bt3m/Q9d3NzE1FRUerz3bx5U1hZWWk9Jre6Yl28eFFynlOnTokyZcrodayFhYUYPXq07H1dsWJFtsuzZs0aSV6TJk3Kdl5Z38OjR4+q/z58+HC287W2thbPnz9X55W1S5a2rlia7t/Nmzeb9B7kwoULFy7msbArFhERFSguLi7o3LlzXhfD7AwcOBBly5ZV3Hf+/Hm0bdsWJUuWhJOTEz766CMsW7ZM3dIhqy+++EJxu7OzMyws5NWNmJiY7Bc8C01d8B48eIDPPvsMhw8fRnx8PFJSUnDnzh1Mnz4d48ePVzymTZs2slYmxvTtt99K8p87d67BrTxMoX79+pKBhCMiItC2bVs8evRIr+PT09OxbNkyTJw4UbL9yy+/RKlSpYxaVmPIPAB18+bNsz1wcfv27VG8eHEAQGJiIs6fP29wHmfOnJGUp3fv3rnScoyIiN4dDOwQEVGusbGxQadOneDn54fg4GA8efIEr169QlpaGmJiYnDr1i3s3LkTo0eP1tkdYdKkSeqZZ6KjoxXHyfDx8ZHMUBMaGirZ7+LiojiTzZ49eyTp6tevjw0bNuDBgwdITk5GfHw8QkJCsGjRInh4eCiWz9XVFdOmTcPp06cRExODlJQUPH78GHv37kX37t0NfOdMo1evXorbr1y5gsaNG2P//v149uwZXr16hatXr2LMmDEYO3as4jH16tVTnClLUzcsYwZ2NI1vsmLFCiQnJyvuW7NmDYQQsu1WVlaoVauW0cqWmb29PYYNG6Zef/78OQIDA01yLkM1atRIsr5ly5ZsXSNfX1/cvn1bvW5tbY3evXvnuHzGdvToUSQlJQEAVCqVpDuVITIfd+DAAcUgpj5+/vlnyfqYMWOylQ8RERVQ+rTrYVcsLly4cOECZL8rloWFhRg+fLh48eKFvk1KRUpKivj1119F4cKFFfOcNGmS3nllCA0NleShaYaekydPCuBtN6IFCxaI9PR0jXnGxcWJDh06SPJt0qSJiIiI0FqWffv2CQcHhzy7ljY2NiI5OVmxbF5eXhqPs7e3F6mpqYrHVa1aVZa+Zs2aiml9fHyM9lru3buneI7OnTtrPe7JkyeKx3Xv3t0k73nW7kCzZ8/O1nGm6Iq1aNEiyTlGjx6d7bx69eol5syZI3r27CmqVq2qs6uZpsWUXbEaNGggdu3apV5//PixwTNSubu7Sz4L/fr1E+vXr5ecR5+uWMDb75q7d++qj0tMTNQ4sxgXLly4cCkYC7tiERFRvmFtbY3NmzdjxYoVKFq0qEHHDRkyBBcvXtTYXSin0tLSFLsWZXSVmT59OiZOnAiVSqUxDycnJ2zfvl09GO6HH36Iffv26Zwpqm3btggICMhB6XOmWLFi+Pvvv3Hs2DFcuXIF9+/fR1RUFOLi4nDkyBGNxyUmJmpsyaE0i5JSKx7AuC12oqOjFbdrG9AZgMbrGhsbm+MyKenZs6dkfdu2bSY5T3Zk7Q6mqSWaPrZu3Yrp06cjMDAQN27cyBddzbKytbXF77//rl4vXbo0vLy8DMqjf//+sLKyAvB2kOldu3bB2to6W+URQmD79u3qdTs7O3Tq1ClbeRERUcHDwA4REZnU9OnTZf/QGqJ8+fLYt29ftmdt0iWjO0ZmTk5OqFmzJr7//nu98rC1tcXChQuhUqmwbt06ODs763Vcp06dcjSTU06Eh4ejY8eO+PTTT1GrVi2UL18ebm5uKFy4sMbuS8Db6aw1TSf+5MkT2bbc6IoVHBysuL169eoaj3FwcFAMvqWlpeHs2bNGK1uGIkWKoHnz5ur10NBQXLt2zejnya47d+5I1vv165crs5nlFSsrK+zcuROvXr1Sb/vyyy8NymPgwIHqv3fv3o24uDitQWBd/vjjD8l6t27dsp0XEREVLAzsEBGRybi4uGDChAmy7eHh4fjqq69QqVIl2Nvbw8bGBiVKlMDnn3+u+E911apVMWrUKMm2BQsWqKc3njt3ruL5v/vuO8k0yBUrVpSlUWpNYG9vjzlz5uhs8ZGZl5cXRowYgfr16+t9DAB8/fXXBqXPa97e3or/vEZEROD58+ey7ZqCA9HR0bCxscHAgQPx119/4fHjx0hKSkJ0dDRu3bqFjRs3olevXnq1gFi1ahXS09Nl24cOHQonJyfFY7788kvF65vdsWV0adGihbp1B/B2PJb8ZP/+/UhJSVGvu7u749ChQ4qfmXeBhYUFXr16JWk11aFDB/VAyLo0bNhQMsCxv78/AM2twPRx9uxZSeuzzz77THLPEBERacLADhERmUy7du0UW9p07doVq1evRmhoKJKSkpCamornz5/jzz//RMuWLXHp0iXZMZpmXcoppYBAkSJF0LFjRwBvBzUtV64cHBwc0K5dO4SFhSnmo1Kp4OvrCwB4+fIlvL294ezsDHd3d8yYMUPxPADg6elpstZIxubu7o5Zs2Yp7tu6davia9QU2KlZsyZu374Nf39/dOzYEaVLl4atrS1cXFxQuXJl9O3bF1u2bMGtW7d0znh27do1zJs3T7a9ZMmSOHbsGLy8vODs7AwbGxtUqFABM2bMwOLFi2Xpw8PDNc6WlVMNGzaUrJ8+fdok58mup0+fygbwrVOnDq5duwZ/f3+0bNky292M8rM1a9ao/7a2tkb//v31Om7QoEHqv8PDw/H333/nuCxCCElg297eXt3Fk4iISBsGdoiIyGTef/99xe03btzQeMzr16+xePFiREZGIiQkBPv27cOvv/6KgIAA2NjYmKqoEhlP3RcsWIBRo0bh4cOHSEhIQFBQENq1a4c3b94oHmdpaYmkpCS0atUKmzdvRnx8PCIiIjB79mzMnz9f8RhbW1tUqVLFZK/FWBwcHLBjxw6ULFlSti8xMRFLly5VPE7TGDsTJkzQa+yk999/H3/88QcmT56sNd306dMxd+5cWXCpVq1a2L9/P2JjY5GcnIzQ0FDMnDlT1hLi+vXraNGiBSIiInSWKTuytuTKb4EdAJg6dSoOHjwo2WZra4uBAwfi0KFDiIqKwt9//40ZM2bA09NTY2soc3Lq1Cn8999/6nV9Asj29vaS7qXr16/X+J1gqKz3RYMGDYySLxERvdsY2CEiolzXt29frfs3b96MokWLombNmmjfvj2GDh2KOXPmSLqKmNqzZ88UW6dcu3YNQUFBGo/z8/PD5cuXZduXLl2q8Z8/TQGw/MLJyQl79uxBkyZNFPf/8MMPePDggeI+Y4zTolKpMG/ePPTo0UNrumnTpqF+/frYvHmzXt2p3rx5g6NHj2Lo0KH4+OOPZePMGFPm4F1qairu3btnsnNlV3JyMjp06ICFCxcqftYcHR3RqlUrzJw5EwcPHkR0dDQuXryIn376Ce3bt1ccPNscrF27Vv33Bx98gMaNG2tN37VrV0nAMqMbljFknioeACpXrmy0vImI6N3FwA4REZnMw4cPFbf/8ssv+PPPP9GtWzeDZsrKTZs3b1YcWBkAjh07pvG49evXK26PjIzE9evXFffl55YPJUuWxNGjRyUD/2a2e/duja2RAOMEdjKsWrVK53vl4eGBQoUK6ZWfpaUlSpQogcqVK+doFihd7OzsJGO3PH78WGPXvLyWkpKCSZMm4f3338fSpUs1zjgGvH3/ateujZEjR2LPnj2IiorCH3/8ofFeya82bNggmR1P1yDKgwcPVv997NgxhIaGGq0s9+/fl6ybakZAIiJ6tzCwQ0REJrNv3z7FGZZUKhU6d+6M33//HREREbh58yZ+++03DBo0KN+0XtEWvFGa/QkA4uPjERISYvBx+XWMnXr16uH8+fOoXbu24v5jx46hT58+EEJozENbYCc4OBgdOnRAsWLFYGdnhypVqmDKlCmIi4vTmNfQoUMV92WMp7Nz50507txZ74BSlSpVMG7cONy4cQNTp07V6xhDlS5dWjKorqZxmvKTJ0+eYOzYsShevDg8PT3h6+uLCxcuaJ263M7ODl26dMG///6LCxcumE03ohcvXuCvv/5Sr/fo0UNjALFcuXKSwJUxW+sA8mD4e++9Z9T8iYjo3cTADhERmUxUVJTGGasyqFQqVKlSBYMGDcJvv/2Ge/fu4eHDh/Dz8zN4hilj0vYU/uXLl4rb79+/rzXIoem4nMykYyrdu3fHsWPHUKpUKcX9QUFBaNu2rWS6aCWaxthZs2YNmjVrhr179+Lly5dITk7G7du3MX/+fHzyySeIj49XPK5r166yba6urjh+/DiaNm0q27dr1y58+umnKFy4MOzt7VGpUiWMHz8ekZGRknQ2Njb44YcfdN6v2eHs7CxZ1xS4yo/S0tJw6NAhfPvtt6hbty4KFy6MFi1aYMqUKdi7d6/GFj116tTB8ePH0atXr1wucfZk7o7l4OAgGUMns4EDB6o/r/Hx8fj999+NWo6s931+bs1HRET5BwM7RERkUnPnzsXy5csNOqZMmTIYNmwYzpw5g7/++ktxwF5T0xRYAN4O8KxE17gumo7LbyZNmoTAwEDY2dkp7l+6dCk6duyIhIQEnXl5enpKppzPWIYMGaJxzKGrV69iwYIFivvq1asHR0dHybZly5ahQoUKsrSrV69G586dcezYMcTFxSEpKQmhoaH48ccf0bhxY8UAy+TJk40eUMzaNUyf9y2/SkhIwJEjRzB//nx06NABRYsWRb169TB79mxZSyRra2usW7dOY4uv/OTAgQOS8isNoqxSqTBgwAD1+rZt24z+mc6an77dComIqGBjYIeIiEwqPT0dI0eORNu2bXHu3DmDj+/YsSPOnTun+I+7KWVnDBRtrXXMgaWlJX777TfMnz9fsRXR69ev0adPH4wdO9ZoswBpEhgYqLGMmVsRlS1bFt7e3rJ0iYmJ+O677zTmf/v2bdn03sDbf97Hjh2bjRJrlrWrnVL3RHOVnp6O8+fPY8aMGahQoQKmTJki+ezY2tpqHYMpv0hPT8e6devU6w0bNkTVqlUlaVq2bIly5cqp13/77TeTlCNzd7f82k2TiIjyFwZ2iIgoV+zfvx/169dHjRo1MGHCBPz99996t1woXbo0AgMD82WXpXeFlZUVtm7dikGDBinuv337Nho0aIAtW7bkSnnu37+vMbjm5uam/rtdu3awsJBXZy5duoTY2Fit5zh58qTi9tatWxv1XssayHlX/1lPTU3F/PnzMW7cOMn2Vq1aoUiRInlUKv399ttvkuBs1kGUMw+afPPmTQQHBxu9DBYWFrCyslKvv0tBQCIiMh0GdoiIKFddu3YNPj4+8PLyQuHChVGvXj2MHDkSAQEBGgcXBoCPP/4YLVu2zMWSFhwWFhYICAhAt27dFPfv3r0b9erV0zirlylYWloqBmwAaVcmTS25Hj16pPMcjx8/Vtzu6uqqcWyg7MgawHzXu9csX75cMoaRhYUFatSokYcl0s+DBw9w+PBh9Xq/fv1gbW0N4O1YUV26dFHvM/agyRkcHBwk6+bcbY+IiHIPAztERJRn0tLScP78eSxfvhx9+/aFh4cHWrdujVu3bimm9/T0zOUSFgxLlixBjx49FPf9+OOP6NSpU7YG/G3fvj2WLVuGLVu24PDhw7h+/TpevHgBHx8fncdWrlxZ476IiAj13/b29oppMv4h10bTsQA0ji+UHeYwIK6NjQ3q1q2LoUOHwsbGJkd5paWl4fbt25JtxgyUmdKaNWvUfxctWhReXl4AgG7duqnvl7S0NGzYsMEk5896b2gb64uIiCiDle4kREREuUMIgYMHD6JVq1Z48OCBrMVG6dKlDcpPU4sP+p9+/fph9OjRivumTZuWo1miypUrh1GjRsm29+rVC99//z0SExM1Htu7d2/F7U+ePMHTp0/V6y9evFBMp8+9UqJECcXtQgiNM5hlx+PHjyGEUHfvKlOmjNHyNoYDBw6gRYsW6mBYeHg49uzZk6M8swYoNF2n/ObPP/9EVFSUuutY586dsWfPHsnsXkFBQXj27JlJzl+2bFnJetYBqYmIiJSwxktERCZRsmRJ9T/wAQEBOHfuHJ4/fw4XFxedx4aFhSn+Y21ot4TixYsblL6gqVixIlasWKG479dff83x1N9///234nYPDw8sWrRI43FNmjSRjdOiKc9r164ppqtVq5ZsmnGl8yi5ceOGZADbnEpKSpK0MvLw8MhXQcfHjx9LWjhNnjw5R2MMlSxZElWqVFGvv3nzRtaCJ79KTk5GQECAer1NmzZwdXVF8+bN1dtMMWhyhsyDMwPAw4cPTXYuIiJ6d+SfWgUREb1TPDw8sGXLFsyaNQt9+vRB3bp1Ubx4ccyYMUPnsbVq1UKxYsVk2//77z/F9ElJSYrbP/30U8MKXcD4+vrKpg4HgKdPn2oMrBjizp07OH78uOK+b775BgcOHECjRo3g4OAAW1tbVK9eHXPnzsWhQ4c0doXKOpPVwYMHkZKSIktnZ2endTamcuXKYejQoYr7ctpaRUnmwIa1tTXKly9v9HNk1/LlyyUDVTdu3BizZ8/Odn6LFi2SBIoOHz4sGXMnv8vcHat06dIYOXKkekDjiIgI7N2712TnzhwQA2A2ATEiIspbDOwQEZFJnDt3DpcuXZJtHzNmDLZu3Yr/+7//Q8mSJVGoUCFYWVnB1dUVtWvXVs+YlbXFQGpqKrZt26Z4rufPnytur1u3LubPn49SpUrBzs4OVatWfWdnJDJUs2bN0L59e8V9JUuWRHx8PIQQBi1KAZEpU6ZonAa+devWCA4OxqtXr5CUlISrV69iypQpGq9RYGAgLl68KNkWGxsLPz8/xfRff/01tm/fjqZNm8LZ2RnW1tbw8PDAkCFDcPLkScVxXxISEvDTTz8p5pcTZ8+elaw3aNDA6OfIrkuXLmHt2rWSbdOmTYO/v79igFUTNzc3BAQEoG/fvupt6enp+P77741W1twQEhKC8+fPq9fHjh2r/nvjxo1ITU012bmz3hdnzpwx2bmIiOjdwcAOERGZzMiRI/HmzRvZ9p49e2LXrl148uQJXr9+jdTUVERFReHixYtYuHCh4j+Tc+bMkYytktnp06c1lmHSpEkIDw9HYmIirl+/btA/qu+yxo0b58p5Tpw4gSVLluQ4n+vXr2PIkCGK+2bOnImbN28q7uvatSuOHTuG2NhYpKSkICwsDL/++itKlSqlmH7ChAlaZ2fLrqz3aMOGDY1+jpwYOXIkTpw4Idk2cOBA3L9/H5s2bYK3tzdq1KiBIkWKwNraGtbW1nB1dcVHH32EPn36YN26dXj06BH69OkjyWP69OlaP5/5VeZAV+YAoCm7YalUKtSvX1+9npiYiJCQEJOdj4iI3h0M7BARkcmcPHkSAwYMyPET7hUrVmDevHka91+9ehXBwcE5OgeZznfffadxLB99HD9+HK1atdI4Q1BMTAxat26Nq1evZvsc6enpmDp1Kn755Zds56HN4cOHJeP2ZMy2lB1eXl4Gt6bKvGR0K8osOTkZXl5e2LRpk2S7g4MDvL29sWnTJoSEhCAyMhIpKSlISUlBVFQUrly5goCAAAwYMEAyjXtCQgKGDx+u9XObn23evFk2pteZM2dw48YNk52zXr166kGbAeDQoUNGHeuJiIjeXQzsEBGRSQUEBKBRo0bZemp/69YtfP755xgxYoRiy5/MBgwYgPDw8OwWk0xICIERI0aga9euCA0N1fu4Z8+e4bvvvkPLli01ttbKEBYWhrp162LWrFmIiooyqHzBwcFo2rSpSYMQUVFROHLkiHq9UqVKqFatmsnOlx0JCQno168fWrduLWu9o6/4+HisWbMGlStXxsqVK41cwtwTFxeH7du3S7aZsrUOAHz++eeS9aznJyIi0oTTnRMRkclduHABjRo1wscff4z27dujYcOGeP/99+Hu7g4HBwdYWloiPj4eMTExuHnzJi5duoS//vrLoGBQaGgoateujfHjx6Njx454//33oVKpEBsbi6ioKISEhCA4ONio01iTYf744w/s3LkTbdu2hZeXFxo1aoTSpUvD1dUVABAZGYmIiAicPn0ahw8fxp49ezQOjK0kJSUFM2fOxIIFC9C5c2c0bdoU9erVQ6lSpeDi4gJbW1vExcUhOjoaN2/exOnTp7F7925cuXLFVC9ZIjAwEJ6enur1Hj166DWYeG47ePAgDh48iDJlyqBDhw6oV68ePvjgA7z33ntwcnKCg4MDUlNTER8fj7i4ONy9exdXrlzB6dOnERQUpHUae3Oydu1a9O/fH8DbblFbt2412blUKhW6du2qXk9KSsKuXbtMdj4iInq3qISmEQ0z2b9/P9q2bZsb5SEiIiJ6JxUqVAiPHj2Cm5sbgLezj5UtW9akg/GSeWjTpg2CgoLU66tXr8ZXX32VhyUiIqK85uTkhLi4OH2S/s6uWERERES5ICEhQdI9qWTJkujRo0celojyi5EjR0rWfX1986gkRERkjhjYISIiIsolS5cuRUxMjHp92rRpioMZU8FRr149Scv4wMBAkw7STERE7x4GdqK6wzMAACAASURBVIiIiIhySWRkJGbPnq1e/+CDDzRO404Fw+LFi6FSqQC8HVtnwoQJeVwiIiIyNwzsEBER5RNjxozJ0TTW+iyGzEpFprF8+XJcu3ZNvT5r1iz1uDtUsPTo0QPNmjVTr8+bNw+PHj3KwxIREZE5YmCHiIiIKBelpqbC29sbycnJAIBixYqZ9dTglD3u7u745Zdf1OunT5/GvHnz8rBERERkrhjYISIiIsplISEhmDhxonq9W7du6Nu3bx6WiHKTSqXC2rVrUbRoUQBAfHw8+vbtizdv3uRxyYiIyBwxsENERJRP+Pr6QqVSmXSpWLFiXr9M+v+WLVsGf39/9fqqVatQu3btPCwR5Zbvv/8e7du3BwC8efMGPXv2xN27d/O4VEREZK4Y2CEiIiLKI0OHDsWRI0cAAIUKFcKuXbvg7u6et4Uik+ratStmzJihXh8zZgyCgoLysERERGTuOL8mERERUR5JTU1FixYt8roYlIt27NgBCws+WyUiIuPhrwoRERERERERkZliYIeIiIiIiIiIyEwxsENEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiIiIiIiIiIzBQDO0REREREREREZoqBHSIiIiIiIiIiM8XADhERERERERGRmWJgh4iIiIiIiIjITDGwQ0RERERERERkphjYISIiIiIiIiIyUwzsEBERERERERGZKQZ2iIiIiIiIiIjMFAM7RERERERERERmioEdIiIiIiIiIiIzxcAOEREREREREZGZYmCHiIiIiIiIiMhMMbBDRERERERERGSmGNghIiIiIiIiIjJTDOwQEREREREREZkpBnaIiIiIiIiIiMwUAztERERERERERGaKgR0iIiIiIiIiIjPFwA4RERERERERkZliYIeIiIiIiIiIyEwxsENEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiIiIiIiIiIzBQDO0REREREREREZoqBHSIiIiIiIiIiM8XADhERERERERGRmWJgh4iIiIiIiIjITDGwQ0RERERERERkphjYISIiIiIiIiIyUwzsEBERERERERGZKQZ2iIiIiIiIiIjMFAM7RERERERERERmioEdIiIiIiIiIiIzxcAOEREREREREZGZYmCHiIiIiIiIiMhMMbBDRERERERERGSmGNghIiIiIiIiIjJTVsbMrHXr1mjUqJExsyQiIqJ3xPXr17F9+3ataWbMmJFLpSEiIiLKe7NmzcpxHiohhNCVaP/+/Wjbtq3OzH788UeMHTs2x4UiIiKid8+2bdvQs2dPrWn0qJYQERERvTNUKpXidicnJ8TFxemTxe/sikVEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiIiIiIiIiIzBQDO0REREREREREZoqBHSIiIiIiIiIiM8XADhERERERERGRmWJgh4iIiIiIiIjITDGwQ0RERERERERkphjYISIiIiIiIiIyUwzsEBERERERERGZKQZ2iIiIiIiIiIjMFAM7RERERERERERmioEdIiIiIiIiIiIzxcAOEREREREREZGZYmCHiIiIiIiIiMhMMbBDRERERERERGSmGNghIiIiIiIiIjJTDOwQEREREREREZkpBnaIiIiIiIiIiMwUAztERERERERERGaKgR0iIiIiIiIiIjPFwA4RERERERERkZliYIeIiIiIiIiIyEwxsENEREREREREZKYY2CEiIiIiIiIiMlMM7BARERERERERmSkGdoiIiIiIiIiIzBQDO5Rv7NmzByqVSr08ePAgr4tEBmjVqpXk+qlUKgwaNCivi0VUIHh7e8s+f+3atcvrYhEVKKzHmC/WYYjeLQWxXvTOBXZWrlwpuYAnTpzI6yIRvfPWrFmDf/75R7KtRIkSWLJkiSRN1i/YjGXXrl16n2vx4sWy4ydNmmS010KGCw4OxujRo1GrVi24u7vD2toarq6u+PjjjzFy5EicO3fOoPyePn2KefPmwdPTE++99x7s7e3h5OSEChUqoFevXti4cSPS0tJM9Gr0d+TIEYwaNQp16tSBu7s7bGxs4OTkhDJlyqBdu3aYN28ewsLC9MorNTUVO3bswBdffIGaNWuiWLFisLGxgaOjI0qXLo1mzZph3LhxOH36tOLxy5YtQ7FixSTbgoKCsH79+hy/TnorKioKv//+O4YNG4b69eujfPnycHZ2hp2dHUqXLo1atWqhW7du8PPzQ2hoaF4Xl4j0xDpMwVZQ6zAZNm3aBGdnZ9l9uXjxYoPzYr0ojwk9BAUFCQA6lx9//FGf7EzKz89PUqbjx4/ndZHyndTUVGFvby8ACD8/v7wujtru3bsl1+7+/ft5XSTSQ2RkpHB1dZV9H2zevFmSbvXq1Rq/OypVqiRSUlL0Op+Pj4/s+IkTJ5ripZEOjx8/Fh06dNDr92HAgAEiKSlJZ54LFiwQhQoV0plflSpVxNmzZ3PhVcrduXNHNG7cWK/XbWFhIYYNGybi4+M15rdr1y5RunRpvfIDIBo1aiRu3Lghy2fdunWytG5ubiI6OtqUb4dBAgMDdb6+/Obx48dixIgRwtbWVu9rBEB4eXmJU6dO5XXx8+1vfnbl59fDeoz5YR2m4CqodZgMMTExonfv3hrL6OPjo3derBflnKbX5uTkpG8W2965Fjuk2/Xr15GYmJjXxaB3xMyZMxEdHS3ZVr9+ffTq1UvvPO7cuYPly5cbu2hkQvfu3UPdunWxZ88evdKvX78eXbp0wdvfLmXfffcdJk2ahISEBJ353bp1C56enjhz5ozeZTaGixcvom7duggODtYrfXp6OlauXInPPvsMr169ku1fvnw5OnXqhPDwcL3LcOrUKTRo0ABnz56VbO/Xrx9q1aol2RYZGYk5c+bonTdJbdiwARUrVsQvv/yC5ORkg449cOAAGjVqhGHDhiE1NdVEJdTtXfvNf9deD+Ut1mEKpoJah8lw4sQJ1KxZE1u2bMlxXqwX5R8M7BRA58+fz+si0Dvi0aNHWLlypWz7woULoVKpDMprzpw5iIqKMlbRyITi4uLQqlUrPHv2zKDjgoKCNFZ+AwMDDW72GxcXh27duiEuLs6g47IrLi4OHTt2RGxsrMHHnj17FmPGjJFsu3TpEkaPHp2tssTHx6Nnz56SYIOFhQXmzZsnS7t8+XI8efIkW+cpyCZNmoQBAwYgKSlJvc3NzQ3Dhw/HX3/9hdDQUMTGxiIpKQmPHj3C8ePHMX36dFSpUkWSz6pVq+Dp6Zlr92lW79pv/rv2eijvsA5TMBXUOgwApKWlYcaMGWjevDkePnyY4/xYL8pfGNgpgFgpImNZsmSJ7El0/fr10bx5c4Pzio6OxsyZM41TMDKpH374Affu3ZNss7CwwNSpU/Hw4UPEx8dj3759qFChguzYuXPnylo+pKWlYeLEibK0H330Ef7991+8evUKL1++xMqVK2Fvby9J8/jxYyxdutQIr0o3Hx8fxYrAp59+iuDgYMTFxSEsLAxr165F0aJFZen8/f1x//599frcuXORnp4uS9evXz9cvXoVycnJiI2NxZ49e/Dhhx/K0j148ED2tK1t27aoWbOmZFtKSgp8fX31fp0ErF69GgsXLlSvq1QqjB8/Hnfv3sWKFSvQsWNHVKhQAc7OzrC1tcV7772HTz75BLNnz8b169exZs0aODs7q48/duwYBg8enBcv5Z37zX/XXg/lHdZhCqaCWod58uQJmjZtitmzZ+PNmzfq7aVKlYKDg0O28mS9KJ/Rp8MWx9h5t9SrV0/9/uSn/unsm25e4uPjhaOjo+x7YOvWrYrptfVPz1isrKzEzZs3tZ6X/dPzVlhYmOJYI6tWrZKlvX37trCzs5Ol3bVrlyTdH3/8IUvj7Owsnj17JstzxYoVsrQlSpQQqampJnvNQgjx5s0bUbJkSdm5q1evrnjuAwcOKN7jvr6+6vyU+uE3aNBA8fw3b94UlpaWsvQ9e/aUpV2/fr0sXeHChUVCQoJx35RsMIcxdq5fvy65x62srMTGjRsNzufy5cuiRIkSkte2fPlyE5RYu/z6m59d+fn1sB5jPliHKZgKah1GCCF+//132bl79OghIiMjFcez0TXGDutFxqXpe4Vj7Ojg7++vHvG7cuXK6u1CCOzcuRNeXl4oXrw4rK2t4eLigho1amDUqFG4c+eOxjx9fHzUeZYvX169/eXLl/j+++9Rv359lCpVCra2tihVqhQ++eQTLF26VGvTtQULFqjztLKy0uu1+fr6Kh6TebawzKO7Dx8+XDICenafhKWkpGDbtm3w9vZGjRo1UKRIEVhbW8Pe3h4lS5bEJ598gokTJ+LSpUt655nRDDYtLQ1r166Fl5cXypcvDzs7O7i6uqJ69eoYPXo07t69q1d+b968wd69e/HFF1+gVq1acHNzg42NDRwcHODh4YE2bdpg0aJFiIiI0JqPKa51Vk+ePMHcuXPRqlUreHh4wN7eHs7OzqhYsSLat2+PVatWyfqEZ5X5XlCpVNi/f7/e59fHjh07ZH1jXVxc0LlzZ73zaNy4sWQ9LS0N48ePN0r5sjp58iSmTJmCRo0aoWzZsihUqBAcHR1Rrlw5NGrUCFOmTNFrFr21a9fKZg7w8vJS7xdCIDAwEO3bt1fPrlCsWDE0bNgQCxYsQHx8vF7ljYuLg5+fH7p3765uGWBnZ4dy5cqhRYsW+Omnn3Teq6YQGBgoe1rVqFEjfPXVV7K0lSpVQpcuXVChQgV4eXnhm2++ga+vr+wp2Pbt22XHent7w93dXbZ90KBBsidLz549w/Hjx7PzcvR2+fJlPH36VLZ96tSpit/PrVu3xnvvvSfbfu3aNQBARESEYj/8nj17Kp6/SpUq+Pjjj2XblZpSd+vWDY6OjpJtsbGx+OuvvxTzJqk5c+ZI7vHvv/8effv2NTifmjVrYuvWrbCw+F9Va86cOZKuXZnl9W9+fq7HmLoOA7AeAxivHmOMOgxg2noM6zCmrcMA+bMeU1DrMFm5uLggICAAgYGBKFKkSLbyYL0oH9In/POutdgJCAiQREmFECI6OlrnaN42NjYiICBA8byZI7Bubm5CCCFOnTolihcvrjXP9957T5w8eVIxz/nz56vTWVpa6vX6ly5dqnhM1vdF03Lu3Dm9zpPZ6dOnRcWKFfXKH4Do1q2biImJkeWT9UlXWFiYePr0qahbt67O65J19oKsrl69KmrVqqVX+RwcHMTq1as15mWKa50hNTVVTJgwQdjY2Ogsp5ubm/D399eYV+Z7AYAICgrSem5DeXl5yco0ZMgQjemVnnYtW7ZMlClTRrb9n3/+0ZiPoU+7zpw5I5o2bar3/dmkSROtM9ls2bJFdkzG04TIyEjRvHlzrfmXLl1aXLlyRWP+6enpYvHixcLJyUlnWZ2dnbXeq6bQoEEDWTk2bNiQozyztmoAIHbs2KExfevWrWXpp02blqMy6PLvv/+KFi1aiDp16oiKFSuKYsWKCVtbW8UnchmU7rvPP/9cCCFEeHi44jXdtGmTxvyUZu+oX7++Ytp+/frJ0nbq1Clnb4IR5PcWO/fu3ZM8AaxatapIS0vLUZ7Dhw+XvD5NrUzy+jc/P9djTFmHEYL1GCGMU48xZh1GCNPWY1iH+d9izDqMEPm7HlNQ6zBC/K/FjqenpwgLC5Psy06LHdaLjEvTZ4QtdnSwsbFR/52QkICUlBR4enrqHM07JSUFgwcPxn///Sfblzky+erVKzx+/Bjt2rXTGYkOCwtDhw4dcPv2bQNfRf5w+/ZteHp6IjQ0VO9jtm/fjs6dO2sdWR54+6SrTZs2Op/ApaSkoH///rhx44bi/jt37qBZs2a4fPmyXuV7/fo1hgwZgnXr1inuN9W1TktLQ4cOHbBo0SKkpKToLGdkZCQGDRqEBQsW6ExrbElJSTh69Khse7t27QzKJz4+HnPnzpVtHzt2rGIfW0Nt3LgRTZs2NehJyMmTJ9GsWTNs2LBBcb+tra1sW1xcnPr6HTlyRGv+4eHhaNWqFSIjI2X70tPT0aNHD4wfP16vp2JxcXEYMmQIZs2apTOtMSQmJkqelmfw9PTMdp5Pnz5VHMCwatWqGo9R6ldt6nE3mjdvjsOHD+PChQu4c+cOIiIikJSUpPhELsOLFy9k2zKejJUoUQKFCxeW7dc2mN/z589l2z744APFtEqfxUOHDuXp7Ezm4I8//pCMPTBq1ChYWlrmKM8xY8ZIBmINDAzMUX6mwnoM6zE5udasw/xPQa3DAPm7HlOQ6zAAUKhQIfz000/4+++/4eHhkeP8WC/KfwpkYMfa2lr9d1JSEhYuXIgLFy7gww8/REBAAJ4+fYrU1FS8fPkSe/bswUcffaROn5ycjGXLlsnyzFzxS05OxoQJExAdHY3GjRtj586dePbsGVJSUvDs2TNs2bIFFStWVKePjo7O9gjg+ho2bBiEELIpQv38/CCEUC9169Y1KN+pU6eqm7La2Nhg8uTJOHfuHKKjo5GWlob4+HiEhoZi8+bNkiarR44cwe+//641bx8fH1y5cgVVqlTB+vXr8eTJE6SkpODFixf4448/UK1aNXXatLQ0jaPRjxgxQtLkt3379ti9ezfCw8ORnJyM169f4+LFixg9erSkyfzYsWMVmx2b6lpPnjwZBw4cUK9XqlQJv/76K27cuIHXr1/j1atXCAkJwfz58+Hm5iY57tChQ9reSqM7efKkrDuBpaUlWrRoYVA+0dHR8Pb2lt13ISEhWLt2bY7KuG/fPgwYMECvCmZWqampGDhwIA4ePCjblzkwnCEuLg4+Pj44deqUXvlHRERg9uzZsu3fffedYpNeXWbOnIk///zT4OMM9d9//8kqq8WLF0fJkiWznaemLgjaKh1K+7R1lc0Lly5dws2bN2XbK1WqBODtQI3dunWT7d+0aZPiPwR3795VrPj16NFD8fyenp6yWV1evXqF06dP61X+girzPzUqlUpjE3BDVK5cWfIdd/r0aYOnTjdUdn7z83M9xlR1GID1GGNda9Zh/qeg1mGA/F2PKeh1mHbt2mHkyJEGz/hmLKwX5QJ92vW8a12xMjeVValUws7OTrRu3VrjAEovX74URYoUUR9TtmxZWRp/f3/Z+9G5c2eNg2HFxMSIypUrS9KHhIRI0hizWXaGxMREyTlzMvBgenq6ZJCrxYsX6zymb9++wt3dXdStW1csWbJEsi9rE2ZbW1vh6ekpXr9+rZhXZGSkKFq0qKR5aFZ3796VXRNtFixYIEmv1DTaFNf63r17wsrKSr2/bdu2Wgf0evz4sShXrpw6ffXq1bW+LmPLfG9mLNWqVdN6jFIz5hEjRgghhDh69Khsn7u7u4iLi5Plo08z5qioKMm9kXnx9vYWp06dEvHx8eLVq1ciODhYdOvWTTFtyZIlZfffvn37ZOkKFSokChcuLCwsLMS3334rQkNDRVJSkrh8+bLo2LGjYt5ubm6Se+batWvCwsJClq527dpi37594unTpyImJkacPHlStG3bVpaufPnyIjk5ObuXVC8bN27U2OQ1KSlJrF69Wnh6eorSpUsLGxsbUaxYMdGkSRPxww8/iJcvXyrmuW3bNlmeNjY2Wsuxbt062TH29vZGf73ZlZKSIurXr6943UNDQ9XpwsLChIuLiyxNly5dxOXLl0VSUpKIi4sT+/fvFx9++KEsXcuWLUV6errGclSoUEF2zNKlS3PjLdAov3fFcnNzU5ejatWqRsv322+/lbxGpe4sef2bbw71GGPWYYRgPcZY15p1GNZhhMj/9RjWYTTLTlcsQ7BepJvSewMY1hWrwAd2AAgXFxfx4sULrfkOGzZMckx8fLxkf9YfSUdHR41fAhl27twpOWbevHmS/XldydMlKipKktfBgweznZcQ8uvi6uqq87p88803Wq/LsWPHRNOmTUXlypWFs7Oz1n7PQgjx+vVrYW1trc5v3LhxsjSmuNYjR45U7ytWrJiIjo7Wmp8QQuzfv1+SZ3bHFsiOXr16yT7/ffr00XqMUqVo6NCh6v2dOnWS7Z88ebIsH30qRfPmzVP8jpo1a5bG8mW9lzKWrH2/tX0f/vzzz7J809LSNI7fdfXqVXW63r17y/aXK1dOxMbGKpa3ffv2svSaZvMwFqX33svLS1y7dk1Uq1ZN6++Dk5OT4sxCK1eulKUtUqSI1nJs375d8RyJiYmmeul6e/PmjfD29lYsX5cuXWTpT5w4IQkm6Ls0btxYREVFaS1Lly5dZMcNHDjQVC9dL/k5sJOamiopR9euXY2W99q1ayV5b9++XZYmr3/zzaEeY+zADusxxrnWrMOwDiNE/q/HsA6jmSkDO6wX6UfbvaengjnGTlYDBw5E0aJFtaapVauWZF3XaP7du3eXNDVV0r59e8kI3SdPntRR0vzF2dlZ0px37969Rs1/8ODBOq9LjRo1JOtRUVGS9aZNm+LYsWO4desWYmNj8dlnn2nNr1ChQpIR21++fKmznMa41kFBQeq/vb294eLiovO8Xl5ekrLu3r1b5zHGojQWQZUqVXKU56JFiyTdJAFg6dKliqPb67J69WrZtg8++ADTpk3TeMzChQsVZwbYuHGjXuesW7cuvvnmG9l2S0tLjbNkZDS9ffPmjeQeyDBmzBg4OztrLG9W2Wn+bIisM4gAb8cYaNu2La5fv6712Pj4ePTr1w9r1qyRbFeaISjrfaDv/qzdNHJbamoq+vfvj4CAANk+R0dHxW4WTZo0QUhICEaOHIkSJUpozV+lUqFx48ZYtWoVjh49CldXV63plT6T+s6+UxBlHTMiuzOFKMmal6bxKfIT1mNyrqDUY1iHKdh1GMA86jGsw+Q+1otyFwM7gM4fSQCyH2al6dgy06efrpWVFWrXrq1ez29jROhiaWmJ5s2bq9d9fX0xcuRIhIeHGyV/fQYzy3pdjPGlaG9vr/47LS1NZ/qcXuunT59KKhmZ0+nSsGFD9d8hISF6H5dTSgOZ5aSPMvB2HIphw4ZJtiUlJWHSpEkG5fPo0SPcv39ftr1Pnz6SsQeyKlSoEDp06CDbfu7cOb3ug4EDB2rcl3VK1AwxMTEA3vY7zvg7s/r162vMs2rVqrIfsH///VdnOXNCaSDE4OBghIWF6Z3HN998g3v37qnXMw9Um0HXYLWaKkV5OQBedHQ02rVrp1h5UalU8Pf3l0wrnNnjx48RGxurcyBWIQSePHmCq1ev4sGDBzrLVLp0acVzkbKslf5ChQoZLe+s06wq/YOR37Aek3MFoR7DOsxbBbkOA5hHPYZ1mNzFelHuY2AHQLly5XSmyTqKvK4bLesTGE3Kli2r/tuQL5b8wsfHR1KBWL58OcqUKYMmTZpg+vTpOHTokGI0Wx9lypTRmSbrIHDarsvz58/x22+/YfDgwfjkk09QqVIluLu7w9XVFY6OjrCzs4OVlZXOqH1WOb3Wjx49kqQbMGAAVCqVXkvmgRtzc0YSpVHtdUXV9TFjxgzZiPhbt241aGCzCxcuKG7XZ1BNpQppYmKiXrOlZK6gZlW0aFHFClnGAKpKlTjgbWVK07W3sLCQtRyMjIxUnCHAWLTN8tG0aVP8888/iIyMRHx8PIKCgmQtHYG3r9nHx0e9nnl2lgxKFaXMNFV+dD0lM5XQ0FA0bNgQ//zzj+L+ZcuWKQ4ImJ6ejnHjxqFhw4bYsGGDXtfuwYMHWL58OapVq4YVK1ZoTav0j4op7w9zl7WVgdKgs9mVNS9dTxXzA9ZjWI/JSulasw7zPwW1DgOYRz2GdZjcw3pR3mBgB/InacagbxPuzD8AiYmJRpkeMTfVrl0bBw8exPvvv6/elp6ejuDgYPzwww/w9PSEq6sr2rRpgzVr1hhUUTbW09Lk5GR8++23KFu2LL744gv4+/vj5MmTCA0NRUREBGJiYvD69WskJyfr/DJWktNrnbXZdXYpPSkxhdTUVMUfJWNcLzc3N0ydOlW2/dtvv1X/rWs0f6UKGwCUKlVK5/k1Vez0uUbaKoWWlpaKUzgakr++DJmy11BOTk6K2xs3box//vkHn332GYoUKQJHR0e0adMGx48fV3zfM898oXTf6HpqpWm/MVtY6OvkyZNo1KiR4j8lVlZWWLVqFUaOHKl47PTp07FkyRLJP3JWVlaYPn06bt26heTkZMTGxuLo0aP4v//7P8mxKSkpGDFihNZm60rvx7vY1NtYXF1dJd8v+nRh0VfWz7iubi/5AesxrMdkpXStWYf5n4Jah9H3HPoyVT2GdZjcwXpR3mFgx0QcHBz0Spf1SU12pjXMa02aNMGdO3ewadMmNGjQQPajlZSUhAMHDmDIkCEoV64c5s+fn2sVv+TkZLRs2RK+vr4mm142p9f69evXRilHbjXt1/Q+2tnZGSX/UaNGyVrRnT59Glu2bAGg/HQkM6WmtoC0abommtJoyjOzrK36stLWhNqY1y4uLs5oeWWlqZ/8zJkzFadQdXR0VGyG/vz5c3WfZqV/cHW9H0rXw8HBQec1MLZt27bhs88+UwwAuLq6Ys+ePfjqq68Uj71z5w4WLVok275kyRLMnj0blStXho2NDZydndGsWTPs2rVLcQrPcePGaWxmr3Q/CyFMPtW2ubKwsJCM+XHp0iWj5X3lyhXJeuaWD/kV6zH/w3rMW0rXmnUYqYJYhwHMox7DOozpsV6UtxjYMRF9b5DMzXtVKpXZfqgtLS3h7e2N06dP4+nTp/D390evXr1QrFgxSbqYmBhMmTIFn3/+ebaeKhlq+vTpCA4OVq9bW1tjwIAB2Lp1K86fP4979+4hKioK8fHxSExMRFpaGqpVq2bQOXJ6rbM+QThw4ACEEAYvxuw2kB26uifqy9bWFvPnz5dtnzRpEpKSknRWvjT9cOtT+dSURteTqpzS9BQpO/SpwGWXUt9kQPuYCpqaj2c0fVXK+gNz6AAAIABJREFUMyUlRWvFSOmJpj5dHoxpw4YN6N27t+Lnv3r16jh37hy8vLw0Hr9p0yZZxcPFxUU2RkNmSgNbPnr0SPIdl5mxPpMFSZMmTdR/h4eH69VnXx+Zu2IUKVJE764veYn1GNZjslK61qzDSBXEOgxgHvUY1mFMi/WivMfAjono+wOVuempk5OTziaaupjyab2+3N3dMXDgQGzZsgXPnz/HhQsXMGnSJMn4Bbt27YKfn59Jy5GUlCSZWcDV1RVnzpzBunXr0LNnT3z88cd4//33JX3TLS0tDa6o5fRaZx3XIb/PlqLpiVB2xyBQ0qtXLzRo0ECy7dGjR1iyZInO2TayVsIz6DM4mqYBMzXlaSyaxtu4ePGiwZVjpacXxlKzZk3F7dqeXGuqSGU81a9SpYri917WcRt07fvggw80pje2bdu2YdCgQYqvu3Pnzjh16hQqVKigNY/Lly/LtlWuXFlrH/vKlSsrbr969aridqXPpDn/450bmjVrJln39/fPcZ63bt2SjJvx6aef6nz6rS9T/uazHsN6TFZK15p1GLmCVocBzKMewzqM6bBelD8wsGMiN2/e1Ctd5qeBWZtmZ/6iePPmjV4/1MZ6umgsKpUKderUwfz583H9+nVUqlRJvU+puZ0xXb16VVIJmTJlis7ZGlJSUgwe/DGn1zrrj8K1a9cMOn9us7S0VPyS1TVTnKF+/PFH2bYFCxbo/BzUqVNHcfvZs2d1nlMpjaurq8ZR+43lww8/VNye3wYirVKlimL/5Fu3bmk8JuvAiBkymi8XLlxY8YdZ048yoDx7StZKtKmcOHEC/fv3V6y8fP3119ixY4de47YpPZHU1S9fUz9wTZ89pe3vSh9+U+nevbvkPVq5cmWOAw0///yzZH3AgAGK6fLbbz7rMW+xHvM/SteadRhlBakOA5hHPYZ1GNNgvSj/YGDHRI4fP64zTUpKiiQ6WaVKFcn+rE8VdD0FSU9Px+HDhw0oZe4qVaqUZFC5sLAwk3Ybefr0qWRd24j/Gf766y+D+4vn9Fq7uLhIKop79uwx6Px5oXjx4rJtERERRj1HkyZN0LVrV8m2+Ph4/PLLL1qPK1OmjOJMd5s3b9Y65WdUVBT27dsn296sWbMcP4HWpVq1aopP8fS5t3KTpaWl4nSq2lo1KL0Ga2tryZObjh07ytIcPHhQMb+YmBicOnVKtr1z584ay2AskZGR6Nmzp2Iz4zlz5uCXX37RuyVG1imOAeDevXtaK/2Zp1jNTNPT2KzfgYBxZn55l7m5uUmm/Y2IiMCYMWOynd/p06clrTqqVasmG/AxQ377zWc9Ro71GPm1Zh1GWUGqwwDmUY8p6HUYU2C9KH9hYMdENm/erHPwrD///FMSaWzevLlkf9ZZCpSaqGW2Y8cOPHz40KBy5qR/+C+//IJu3bqhXLly2Lx5s17HZJ1mzljN0ZVkzVtX5SsmJkY2SJo+TXONca0zV/RDQkIQFBSk87zJycmoVasWunfvjnXr1uXajBKA8uwMT548Mfp5Fi5cKBvQTlO/2cyUBma7d+8e5syZo5g+PT0dX3/9tWIkf+jQoXqWNvtUKpXij/rKlSs1zg6xb98+ODo6onz58mjYsCH+7//+TzLzBgDs379fcYrREydOZLusffv2lW3buHGj4hOo+Ph4LFmyRLa9YcOGkickffr0kaUJDAzEs2fPZNt/+ukn2ROcunXryv6hNMVrHzFihOJ9PnToUEybNs2gvJSeysbGxmLDhg0aj1m1apXi9nr16iluVyqrpmbl9D+TJ0+W/P76+/tj9uzZBudz48YNdO3aVf0UU6VSYeHChRr/ycpvv/nmUI/J6Rg3rMe8ldNrzTqMsoJShwFMU49hHca4r90UWC/KZ4QegoKCBACdy48//qhPdibl5+cnKdPx48dlaXbv3i1Jc//+fZ35Zj3mv//+k+z39/eX7FepVGLgwIEiPT1dMb8XL16IsmXLqtNbWlqKBw8eSNJcuHBBkmeXLl00lu/69euiWLFiws7OTpJnVikpKZI8J06cqPO1a9K3b191PuXKlRN3797VecyXX36pPsbDw0Oyz9jX5dq1a5J9gwcP1phPeHi4aNCggXB1dRX169dXH/Pxxx/L0priWt+5c0dYWFio05QoUULcvHlTY3mTk5OFt7e3Or21tbUsT1Pq06eP7PPfp08frcesXr1adszQoUN1nuvbb7/V+d2T9T6Ojo4WRYsWVUz7xRdfiMuXL4ukpCQRHR0t/v77b9GyZUvFtHXr1pVdV03fhy9evND6Otzc3GTH+Pn5qfeHhIQIlUolS+Pu7i7Wrl0rnj17JlJSUsSjR4/Ezz//LJycnHS+D5rKqvS9qK83b96IevXqyfIsVqyYWL9+vYiOjhYJCQni8OHDok6dOornDwgIkOXbtGlTWbpatWqJ48ePi4SEBPHs2TOxcOFCYWlpKUu3efNmWX7Gfu1nzpxRzK9EiRLi1atXBud3+/ZtxddibW0tvv/+e3Hz5k2RnJwsEhISxPnz50Xv3r0Vz1+tWjWN5/j8889l6bV9D+aGwMBAnZ/n/GDnzp2ycvXu3Vs8fvxY57Hp6eli3bp1ss/8hAkTtB6X17/55lCPMWYdRgjWY4x1rVmH0ayg1GGEMH49hnUY4752bUqXLi07l4+Pj9ZjWC8yLk3fD05OTvpmsY2BHZgmsNOjRw8BQDRr1kzs2rVLPH/+XKSkpIinT5+KjRs3Sn4gAYi+ffvKzpmamipKlCghSde/f39x4cIF8fr1a5GcnCxu3rwp5syZI5ycnISlpaX44Ycf1GmVKnlCCOHo6Cj58AUHB4ukpCQREREhHj58qN8bLYQ4d+6c5Au8SJEi4ocffhDnzp0TMTExIi0tTbx69UqEhYWJvXv3ik6dOkley5QpU0x6XdLT04WHh4dk/4gRI8T169dFYmKiiIqKEqdOnRITJkxQvyd+fn5i+PDh6vQqlUps3rxZJCYmiri4OJNdayGEmDhxoiSdg4ODmDFjhggJCRGvXr0ScXFx4ubNm8LPz09Ur15dknb48OGy/JYuXSpJExQUpPe11WXhwoUGfZEKkf1KUVRUlHB1ddX63aNUuQ8KClKsYOi7ODk5idu3byvmq5TeGJWisWPHZru85cuXV9+jusqa04rBhQsXhLW1dbbK2aBBA5GWlibL8/Lly4o/6LqW5s2bK5bR2K998ODB2b42WZeM77avv/46x3nt2bNHY5krVKggS+/r65ut128s5hLYEUIIX19fyT+rwNvv5f79+4vt27eLO3fuiNjYWJGUlCTCwsJEcHCwmDVrlqhRo4bsNXl7eyve95nl9W++udRjjFWHEYL1GGNea2PXYYQwXT2GdRh5emPUYYQwbj2GdRjjvvZx48Zl+9pkXr744gshBOtFxqbts6wnBnYy30zaGBrYuX37tihcuLBe75uHh4d49uyZ4nkXL16s9408ZcoU8c8//6jXVSqVYp6enp4a8xg3bpzuNzmTyZMnZ+tD99FHH4nXr19rfY+NcV2y3g/alh49eog3b96I9evXK+7v1KmTEMJ01zo5Ofn/sXfn8THdi//H3xOyiRCU2KulpVqlrSC0ioaI5dZWO61eWr2tpa7iqm5cS6mtV6lbamlDtar29RatpWqrpbqg9n0Jgsgm5/eHn/lmzEwyk8wkOcnr+Xicx8PZPudzZibJx3vO5/MxoqKi3H4tn3rqKYfJuDeDne+//96uHvny5TOuXr3q9JyMNooMwzAmTJiQ5mvg7FvbOXPmGH5+fm6/psWLFzc2b97ssExvNooSExONFi1auF3f0NBQY//+/S7X1RPf+CxevNjthlGFChWMEydOOC3TnZ9XScZDDz1knD592mFZnr731N8uZ3a5+7stISHBaNKkSYbLGTNmjNP6Xrp0yeF/Cpx9rrOKmYIdwzCM7777zuXf746WfPnyGSNHjnT5etn5N98s7RhPtmEMg3aMp95rT7dhDMN77RjaMPbneCrY8WQ7hjaMZ+/d08EO7SLPcnZP7gQ7jLHjJaVKldKqVavSHZCpSpUqWr16tUJDQx3uf/PNN9WtW7d0rzdw4ECNHDnSps+nYRjW6fhSGzp0qMf6hI8cOVLjxo1zOn2kIx07dtQPP/yQJaOQ9+7dW6+//nq6x/Xo0UPz5s2Tj4+P2rZt61Z/S0+9135+flq6dKneeustl6bds1gsevnll7VhwwYFBQW5XF9PqFevnt17fvv2bW3YsMEr13v99dfTnSbRke7du2vTpk2qW7euS8dbLBa1b99eO3bsUL169dy+Xmb5+vpqyZIlev/9911+T5s1a6YdO3bosccec/k6nvj5f/7557V+/Xo9+uijLh3funVr7dixQ+XKlXN6TO/evTV37lzrbBNpiYyM1MaNGx2OlZAWb46H4S4/Pz+tXLlSo0aNUnBwsMvnPfDAA1qxYoUGDx7s9Jh169bpTjvh/wQHB5t65o3s0KpVKx05ckT//Oc/FRAQ4PJ5Pj4+6tSpk3777TcNHTrU5fNy0t/8nNqO8WQbRqIdI3nmvaYN41xeacNIWdOOoQ2Te9EuyiRX4h+e2HH/iZ27qf+1a9eMTz75xKhfv75RpkwZw8/PzyhVqpRRv359Y+rUqXbf9jizYsUKo127dkb58uWNgIAAw8/PzyhfvrzRvXt3Y8+ePdbj9u3bZ1OPmJgYh+WtWbPGePrpp40CBQoYfn5+RmhoqNGgQQNj8eLFLtXnXhcvXjQmTpxotGjRwqhYsaJRsGBBw8fHxwgMDDRKly5tNGrUyBg2bJhx4MABp2V44325a+3atUa7du2MsmXLGn5+fkZAQIBRsWJFo3v37saPP/5od/xvv/1mNGnSxAgKCjL8/f2NChUqGKNGjTIMw/vvtWEYxokTJ4xRo0YZjRo1MsqWLWsEBgYa/v7+RmhoqFG/fn1j2LBhDh+xTc2bT+wYhmE0bdrU7ndAr169nB6fmW+7DMMwFi5c6PR3jyvjLGzcuNEYOHCgERYWZpQuXdrw9/c3ChYsaFSoUMFo1KiRMXLkyDQ/n3d5+9uuuy5evGhMmDDBaNGihVGhQgWjYMGChp+fn1G8eHEjLCzMePPNN41du3ZlqK579+5N9z5dlZSUZHz77bdG165djSpVqhghISGGr6+vERoaaoSFhRlvvfWWsXv3brfKvHz5sjFhwgQjIiLCKFu2rOHv72+EhIQYjzzyiPHKK68Ya9euTbcMT9+7N76ZSi02Ntb47LPPjK5duxpVq1Y17rvvPsPX19cICAgwSpYsaYSFhRn/+Mc/jGXLlhm3b99Ot77dunWzu26rVq0ydO+eZLYndlKLiYkxZs2aZXTv3t144oknjGLFihm+vr6Gv7+/UaZMGaNGjRpGp06djFmzZjn9FtZV2fE330ztGE+3YQyDdoxheO699kQbxjC8246hDePdNoxhZL4dQxvGs/duhid2Ussr7aK7nL027jyxY/n/BaVp9erVioqKSu8wjR8/XgMGDEj3uNxo9uzZ6tGjh3X9ypUrDqf9g/nxXt8xd+5cvfjiizbbQkJCdO7cOZe+rUPWuv/++3XixAlJ0vHjx1W+fPlsrlHWyWv3HhcXp9DQULtZbhYsWKD27dtnU63u+Prrr9WhQ4c0j3GhWQIv4G9b3sF7TRvGbPLa3/HU8vK9e0pObhfd5WzGzODgYMXGxrpSxDe5+3kuAF7Ttm1bFSxY0Gbb1atXtXjx4myqEZy5efOmTp06JUkqUKCA24/+mllevPeFCxfaNV4KFy5sMyUxAORltGHMIy/+Hb8rL9+7J+WVdhHBDoAMCQoKUs+ePe22T5gwIRtqg7QsW7ZMKSkpkqSnnnpK+fPnz+YaZZ28eO+OfgZfeeUVt8aIAYDcjDaMeeTFv+N35eV796S80i4i2AGQYQMGDJCvr6/Ntu3bt2vjxo3ZUyE4NHXqVOu/W7VqlY01yXp57d5XrVqlvXv32mzz8/NT//79s6lGAJAz0YYxh7z2dzy1vHzvnpKX2kUEOwAyrFy5curdu7fd9sGDBzNORg6xbNkybdq0SdKdx3hdmZ0mt8hr956SkuJwBqY33niDx7cB4B60YXK+vPZ3PLW8fO+ektfaRQQ7ADLl/fffV5EiRWy2bd++XfPnz8+mGuGuCxcu6JVXXrGuDxs2TMWLF8/GGmWdvHjvc+fO1Z49e2y2FStWTO+880421QgAcjbaMDlXXvw7fldevndPymvtIjrqAciUokWLauzYserVq5fN9n/+85+KioqyazAh65QoUUJnz57N7mpki7x275cuXdKgQYPsto8fPz7PzXYDAK6iDZNz5bW/46nl5Xv3lLzYLuKJHQCZ1rNnT0VERNhsO3funN58881sqhGQt/Tr108XL1602da0aVO76XwBALZowwC5T15sF1kMFzqRrl69WlFRUekWNn78eA0YMMAjFQMAALnL119/rQ4dOqR5DGNbAACAvMRisTjcHhwcrNjYWFeK+IYndgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMKr8nC1uzZo1iY2M9WSQAAMglDhw4kO4x77//vvcrAgAAkItYDMMw0jto9erVioqKyor6AAAAAAAA5GnBwcGuPjjzDV2xAAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMyqXpzqtUqaLx48d7uy4AAAAe8fbbbys+Pt5mW+3atdW+fftsqhEAAIDr/P39XT7WpenOAQAAzKRw4cJ2U4T27NlTn332WTbVCAAAwCuY7hwAAAAAAMCsCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApCyGYRjZXQkAAID0DBgwQEuWLHHp2GPHjiklJcVmW3BwsIoXL+7S+dOnT1dERITbdQQAAMhi3xDsAAAAU/juu+/Upk0br18nODhY58+fV2BgoNevBQAAkEnf0BULAACYQrNmzRQSEuL167Ru3ZpQBwAAmAbBDgAAMAV/f/8seWKnc+fOXr8GAACApxDsAAAA0+jUqZNXyy9evLiee+45r14DAADAkwh2AACAaTRs2FAlS5b0Wvnt27dX/vz5vVY+AACApxHsAAAA08iXL586dOjgtfK9/UQQAACApxHsAAAAU/FW+FK+fHnVrVvXK2UDAAB4C8EOAAAwldq1a+uhhx7yeLmdO3eWxWLxeLkAAADeRLADAABMxxvdseiGBQAAzIhgBwAAmE6XLl08Wt4jjzyixx9/3KNlAgAAZAWCHQAAYDpVqlRR9erVPVaep4MiAACArEKwAwAATMmTXae8OdMWAACANxHsAAAAU+rUqZNHBjuuU6eOKlWq5IEaAQAAZD2CHQAAYErly5dXvXr1Ml0OgyYDAAAzI9gBAACmldlQJl++fGrfvr2HagMAAJD1CHYAAIBpvfDCC/L19c3w+Y0aNVLJkiU9WCMAAICsRbADAABMq3jx4nruuecyfD7dsAAAgNkR7AAAAFPLaDjj7++v1q1be7g2AAAAWYtgBwAAmFrr1q0VGBjo9nnNmzdXSEiIF2oEAACQdQh2AACAqQUHB6tFixZun0c3LAAAkBsQ7AAAANNzN6QJDg5W8+bNvVQbAACArEOwAwAATK9Zs2ZudavKaPctAACAnIZgBwAAmJ6/v7/atGnj8vGdO3f2Ym0AAACyDsEOAADIFVztjpXZKdIBAAByEoIdAACQKzRq1EilS5dO97gOHToof/78WVAjAAAA7yPYAQAAuYKPj4/atWuX7nHMhgUAAHITgh0AAJBrpBfalC9fXuHh4VlUGwAAAO8j2AEAALlGnTp19NBDDznd37lzZ1ksliysEQAAgHe51MH8jz/+0PTp071dFwAAgEwrUqSI030nT57Um2++mYW1AQAAcF9AQIBGjx7t0rEWwzCM9A5avXq1oqKiMl0xAAAAAAAApC04OFixsbGuHPoNXbEAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAAAAAATIpgBwAAAAAAwKQIdgAAAAAAAEyKYAcAAAAAAMCkCHYAAAAAAABMimAHAAAAAADApAh2AAAuu3TpkgzDsFvKli2b3VUDTMnX11cbNmyw/iydOHFCoaGh2V0teFG7du2UkpJifc/feOON7K4SAMDkCHYAAACyyaeffqoGDRpIkuLi4tSqVSudP38+eysFr1q4cKGGDx9uXZ80aZKaNm2ajTUCAJgdwQ4AALAKDw/XqFGjtHnzZp04cUI3btxQQkKCzp8/r/3792vOnDnq1auXChcu7HKZGzdudPikl7vLsGHDXLqej4+PoqKiNGHCBP300086efKkbt68qbi4OB07dkxbtmzRBx98oCeeeCKjL5NH9O3bVy+//LJ1vXfv3tq9e7fdcT179rR5HVavXp0l9StYsKBatWqljz/+WOvWrdPRo0d15coVJSYmKiEhQTExMTp+/LjWr1+vadOm6YUXXlChQoXSLDN//vwe+SyktRw7dszuuve+hncXT30GXnvtNYflFyxY0OHxH3zwgVasWCFJypcvnxYsWKAHH3zQI3UBAORBhgtWrVplSGJhYWFhyePLpUuXHP6dKFu2bLbXTZIxcuRIm3oNHDgw2+tkluXJJ580Nm/e7EqzwDAMw4iLizPGjRtnBAYGplv2nj17XC43LcOGDUv3Wh07djQOHz7scpnffvutcf/992f56/3YY48Z8fHxNvVwdmzPnj1t6rx69Wqv1i00NNSYOHGiERcX5/Z7dPPmTWPcuHFGSEiIw7Lz58/vdpnuOnbsWLqv4V1TpkzxyGu2fft2h+UXLFjQ6TklS5a0+Z26detWI1++fFn+WWRhYWFhyZlLcHCwq3/6vuaJHQBAruDj46Nu3bpldzVMqWvXrtq6davq1avn8jmBgYEaOHCgduzYoeLFi6d5bEhISGarmC4fHx/NmDFD8+fPV8WKFV0+r02bNtq1a5eqVavmxdrZ8vX1VXR0tPz9/SXdGbvq1VdfzbLrp+XZZ5/V3r171b9/fwUGBrp9foECBayfiypVqnihhp7VpUsXBQQEZKqMRx99VGFhYW6fd+7cOZvxdcLDwzVkyJBM1QUAkDcR7AAAcoWIiAiVK1cuu6thOhEREZo1a5Y1ZHDXo48+qpUrVypfvnxOj8mKYOejjz7S3//+9wydW6xYMf3vf/9T+fLlPVwrx15//XU9/vjj1vX3339fly5dypJrp6VatWpauXKlzeDN8fHx+uKLL9ShQwdVrVpVRYsWla+vrwIDA1WyZEk988wzGjp0qH777TebsipVqqQVK1aoSJEiNtuTk5NlsVhcWmbOnGlz7r/+9S+XzqtQoUK695qUlCTpzmezTZs2GXzF7kjF5NfFAAAgAElEQVTdnS45Odmtc7/66itt2bLFuv7222/zewwA4D5XnuuhKxYLCwsLi5Szu2LNnz/frl50xUp78ff3N44dO+bqY75peuWVVxxew2KxGLdv37Y7ft26dR67j9q1a3vkHhYuXOj117xYsWJGTEyM9Zp//PGHkT9//jTPyaquWLt377a5zk8//WSUL1/epXN9fHyMfv36GcnJyTZlTJ06NcP1mTFjhk1ZQ4YMyXBZ976GP/zwg/Xf69evz3C5vr6+xvnz561l3dslK62uWM4+v/PmzfP655CFhYWFJecvdMUCAOQpISEhatWqVXZXw3Reeukl3X///Q737dy5U1FRUSpVqpSCg4P1+OOPa/LkydYnHe7l7GmZQoUKycfHvrlx9erVjFf8Hh988IHTfWvXrtUzzzyjoKAghYSE6G9/+5v279/v8Ni2bdvq6aef9li9HHnzzTdtnmIZOXKk2095eEOtWrVsBhK+cOGCoqKidOLECZfOT0lJ0eTJkzV48GCb7T179lTp0qU9WldPSD0AdYMGDTI8cHHz5s1VokQJSdKtW7e0c+dOt8v4+eefberTqVMnVa1aNUP1AQDkTQQ7AIAs4+fnp+eff17Tpk3T1q1bdebMGd24cUPJycm6evWq/vzzTy1evFj9+vVLtzvCkCFDrDPPXLlyxeE4GePGjbOZoebw4cM2+0NCQhzOZLN8+XKb42rVqqW5c+fq2LFjSkhI0PXr17Vv3z6NHTtWZcuWdVi/IkWKaNiwYdq2bZuuXr2qxMREnTp1SitWrNALL7zg5ivnHR07dnS4fe/evapbt65Wr16tc+fO6caNG9q/f7/69++vAQMGODwnLCzM4UxZzrpheSrYKVSokBo1auRw36JFixQVFaXNmzcrLi5O165d07JlyxQeHq4dO3Y4POell17ySL0cCQwMVO/eva3r58+f14IFC7x2PXeEh4fbrM+fPz9D79GkSZN08OBB67qvr686deqU6fp52g8//KD4+HhJksViselO5Y7U561Zs8ZhiOmK//znPzbr/fv3z1A5AIA8ypXneuiKxcLCwsIiZbwrlo+Pj/Haa68ZFy9edPWRUiMxMdH473//axQuXNhhmUOGDHG5rLsOHz5sU4azGXq2bNliSHe6EY0ZM8ZISUlxWmZsbKzRokULm3Lr1atnXLhwIc26rFy50ggKCsq299LPz89ISEhwWLfIyEin5wUGBhpJSUkOz6tatard8dWrV3d47Lhx4zxyH02bNnVYfnJyslGuXDmn5z355JMOz4uJiTF8fX298prf2x1o+PDhGTrPG12xxo4da3ONfv36Zbisjh07GiNGjDA6dOhgVK1aNd2uZs4Wb3bFql27trFkyRLr+qlTp9yekSo0NNTmZ6Fbt27GnDlzbK7jSlcs6c7vmr/++st63q1bt5zOLMbCwsLCkjcWumIBAHIMX19fzZs3T1OnTtV9993n1nm9evXS7t27nXYXyqzk5GSHXYvudpV55513NHjwYFksFqdlBAcHa+HChdbBcB955BGtXLky3ZmioqKiFB0dnYnaZ07x4sW1du1a/fjjj9q7d6+OHj2qmJgYxcbGauPGjU7Pu3XrltMnORzNouToKR7Jc0/sOOvms2/fPp08edLpebt377Yb8Fe6897Xrl3bI3W7V4cOHWzWv/76a69cJyPu7Q7m7Ek0V3z11Vd65513tGDBAv322285oqvZvfz9/fXNN99Y18uUKaPIyEi3yujevbvy588v6c4g00uWLJGvr2+G6mMYhhYuXGhdDwgI0PPPP5+hsgAAeQ/BDgDAq9555x27/9C648EHH9TKlSszPGtTeu52x0gtODhY1atX17vvvutSGf7+/vrwww9lsVg0e/ZsFSpUyKXznn/+eTVr1syt+nrK6dOn1bJlSz377LOqUaOGHnzwQRUrVkyFCxdWQkKC0/MKFCigYsWKOdx35swZu23e7op176xLdx0/fjzdc3ft2uVwe82aNTNVJ0eKFi2qBg0aWNcPHz6sX3/91ePXyahDhw7ZrHfr1i1LZjPLLvnz59fixYt148YN67aePXu6VUbqbnvLli1TbGxsmiFwehYtWmSz3q5duwyXBQDIWwh2AABeExISokGDBtltP336tF555RU99NBDCgwMlJ+fn0qWLKk2bdpo+/btdsdXrVpVffv2tdk2ZswY6/TGI0eOdHj9t956y2Ya5EqVKtkd4+hpgsDAQI0YMSLNKbzvFRkZqddff121atVy+RxJ+sc//uHW8dmtS5cuDv/zeuHCBZ0/f95uu7Nw4MqVK/Lz89NLL72kpUuX6tSpU4qPj9eVK1f0559/6osvvlDHjh3TfQLi+vXrDre7MtbJlStXHG5/+OGH0z3XXQ0bNrQ+3SHdGY8lJ1m9erUSExOt66Ghofr+++8d/szkBj4+Prpx44bNU1MtWrSwDoScnjp16tgMcDxr1ixJylSws337dpvP5HPPPWfzmQEAwBmCHQCA1zRr1szhkzZt27bVZ599psOHDys+Pl5JSUk6f/68vvvuOzVq1Ei//PKL3TnOZl3KrJSUFLttRYsWVcuWLSXdGdS0QoUKCgoKUrNmzZx277FYLJo0aZIk6dKlS+rSpYsKFSqk0NBQvffeew6vI0kRERFeexrJ00JDQ53OQPXVV185vEdnwU716tV18OBBzZo1Sy1btlSZMmXk7++vkJAQPfzww+ratavmz5+vP//8M80Zzy5cuOBwuyuBhLPucukN3J0RderUsVnftm2bx6+RGWfPnrUbwPfJJ5/Ur7/+qlmzZqlRo0YZ7maUk82YMcP6b19fX3Xv3t2l83r06GH99+nTp7V27dpM18UwDJtgOzAw0NrFEwCAtBDsAAC85oEHHnC43dHYJnfdvHlTH330kS5fvqx9+/Zp5cqV+u9//6vo6Gj5+fl5q6o27n7rPmbMGPXt21fHjx9XXFycVq1apWbNmun27dsOz8uXL5/i4+PVuHFjzZs3T9evX9eFCxc0fPhwjR492uE5/v7+qly5stfuxVOCgoL07bffqlSpUnb7bt26pYkTJzo8z9kYO4MGDXJp7KQHHnhAixYt0r/+9S+H+x094SXdecorLCzMabmBgYGKiIhwuM9ZV7PMuPdJrpwW7EjS22+/rXXr1tls8/f310svvaTvv/9eMTExWrt2rd577z1FREQoODg4m2rqOT/99JN+//1367orAXJgYKBN99I5c+Y4/Z3grns/F94a7wkAkLsQ7AAAslzXrl3T3D9v3jzdd999ql69upo3b65XX31VI0aMsOkq4m3nzp1z+HTKr7/+qlWrVjk9b9q0adqzZ4/d9okTJzr9z5+zACynCA4O1vLly1WvXj2H+//973/r2LFjDvd5YpwWi8WiUaNGqX379nb7zpw5owMHDjg8b+zYsU67sowfP97pEzsFChTIeGWdSB3eJSUl6ciRIx6/RmYlJCSoRYsW+vDDDx3+rBUsWFCNGzfW+++/r3Xr1unKlSvavXu3Pv74YzVv3tzh4NlmMHPmTOu/q1Sporp166Z5fNu2bW0Cy7vdsDwh9VTxkne6BQIAch+CHQCA1zgbwPaTTz7Rd999p3bt2rk1U1ZWmjdvnsOBlSXpxx9/dHrenDlzHG6/fPmy0wAiJz/5UKpUKf3www82A/+mtmzZMqdPI0meCXbumj59usPXavLkyQ6Pb9CggdatW6dnn31WQUFBCgoKUoMGDbRq1Sq99tprTq/j6S5HAQEBNmO3nDp1ymnXvOyWmJioIUOG6IEHHtDEiROdjkMk3XlC7YknnlCfPn20fPlyxcTEaNGiRU4/KznV3LlzbWbHS28Q5Zdfftn67x9//FGHDx/2WF2OHj1qs+6tGQEBALkLwQ4AwGtWrlzpcIYli8WiVq1a6ZtvvtGFCxf0xx9/6PPPP1ePHj1yzNMraYU3jmZ/ku4M5Ltv3z63z8upY+yEhYVp586deuKJJxzu//HHH9W5c2cZhuG0jLSCna1bt6pFixYqXry4AgICVLlyZQ0dOlSxsbFOy3r11Vftts+ePVs7d+50eE6DBg20ceNG3bhxQzdu3NCGDRvUtGlTSXJ6nbi4OKd1zogyZcrYDKqb1jTsOcWZM2c0YMAAlShRQhEREZo0aZJ27dqV5tTlAQEBat26tTZs2KBdu3aZphvRxYsXtXTpUut6+/btnYatFSpUsAmuPPm0jmQfhntjvCcAQO5DsAMA8JqYmBinM1bdZbFYVLlyZfXo0UOff/65jhw5ouPHj2vatGluzzDlSWl9C3/p0iWH248ePZpmyOHsvMzMpOMtL7zwgn788UeVLl3a4f5Vq1YpKirKZrpoR5yNsTNjxgzVr19fK1as0KVLl5SQkKCDBw9q9OjRevrpp53OdtW2bVu7bUlJSWrfvr1bgUlycrLTcXucBT4ZVahQIa+W703Jycn6/vvv9eabb6pmzZoqXLiwGjZsqKFDh2rFihVOn+h58skntWnTJnXs2DGLa5wxqbtjBQUF2Yyhk9pLL71k/Xm9fv26vvnmG4/W497PfU5+mg8AkHMQ7AAAvGrkyJGaMmWKW+eUL19evXv31s8//6ylS5c6HLDX25wFC9KdAZ4duXr1applOjsvpxkyZIgWLFiggIAAh/snTpyoli1buvRkS0REhM2U83eXXr16OR1zaP/+/RozZozDfWFhYSpYsKDd9qNHj6p27dp2g/868tdff6lhw4basmWLw/1pvfcZce+YPZ5+IigrxcXFaePGjRo9erRatGih++67T2FhYRo+fLhdsObr66vZs2c7feIrJ1mzZo1N/R0NomyxWPTiiy9a17/++muP/0zfW543xnsCAOQ+BDsAAK9KSUlRnz59FBUVpR07drh9fsuWLbVjxw5VrFjRC7VzLiNjoKT1tI4Z5MuXT59//rlGjx7t8CmimzdvqnPnzhowYIDHZgFyZsGCBU7r6OwporNnz6pJkyZq2LChpk+frt9//13Xrl1TfHy8jhw5oqVLl6pbt26qVq2aNm/erPLlyzss5/z58x67D8m+q52j7olmlZKSop07d+q9995TxYoVNXToUJufHX9//zTHYMopUlJSNHv2bOt6nTp1VLVqVZtjGjVqpAoVKljXP//8c6/UI3V3t5zaTRMAkLM4nioCAAAPW716tVavXq3HHntMUVFRioiI0NNPP+3SN9JlypTRggULFBYWZvrwJKfKnz+/5s+fr3bt2jncf/DgQbVp08bpANCedvToUaWkpMjHx/47qPSmI9+4caM2btyY7jWczTi0f/9+l+roqnuDnNz6n/WkpCSNHj1at27d0sSJE63bGzdurKJFiyomJiYba5e+zz//XMOGDbOGmj179tSAAQOs+1MPmvzHH39o69atHq+Dj4+PzUxuuSkEBAB4D0/sAACy1K+//qpx48YpMjJShQsXVlhYmPr06aPo6GingwtL0lNPPaVGjRplYU3zDh8fH0VHRzsNdZYtW6awsLAsC3WkO0/mOAp1JM91Zapfv77D7Z4Odu6tb27vXjNlyhRdvnzZuu7j46Nq1aplY41cc+zYMa1fv9663q1bN+sMaYULF1br1q2t+zw9aPJdQUFBNutm7rYHAMg6BDsAgGyTnJysnTt3asqUKeratavKli2rJk2a6M8//3R4fERERBbXMG+YMGGC2rdv73Df+PHj9fzzz2dowN/mzZtr8uTJmj9/vtavX68DBw7o4sWLGjduXLrnOnuaRpIuXLjgdl3uFRwc7DAoTExM1J49ezJdfmpmGBDXz89PNWvW1Kuvvio/P79MlZWcnKyDBw/abHM2iHZOM2PGDOu/77vvPkVGRkqS2rVrp8DAQEl37m/u3Lleuf69nw1Pj/cEAMid6IoFAMgxDMPQunXr1LhxYx07dszuiY0yZcq4VZ6zJz7wf7p166Z+/fo53Dds2LB0ZzVLS4UKFdS3b1+77R07dtS7776rW7duOT23U6dODrefOXNGZ8+etdlWv359PfLII6pUqZJ1CQ4OVuXKlZ12ZfnHP/7hcBDm1atX69q1a2ndlttOnTolwzCsXXycje2TXdasWaOGDRtan045ffq0li9fnqky7w0oLl68mKnyssp3332nmJgYFS1aVJLUqlUrLV++3GZ2r1WrVuncuXNeuf79999vs+7OTG8AgLyLFi8AwCtKlSpl/Q98dHS0duzYofPnzyskJCTdc0+ePOlwanB3uyWUKFHCrePzmkqVKmnq1KkO9/33v//NVKgjSWvXrnW4vWzZsho7dqzT8+rVq6d//vOfLpc5dOhQffrppxo4cKBatWqlxx57TPfff7/N+CipPfXUU3rvvfcc7ps/f77TemVUfHy8zVNGZcuWzVGh46lTp6yhjiT961//cjh4tqtKlSqlypUrW9dv375t9wRPTpWQkKDo6GjretOmTVWkSBE1aNDAus0bgybflXpwZkk6fvy4164FAMg9ck6rAgCQq5QtW1bz58/XBx98oM6dO6tmzZoqUaKE0/9Qp1ajRg0VL17cbvvvv//u8Pj4+HiH25999ln3Kp3HTJo0yeFTK2fPnnUarLjj0KFD2rRpk8N9b7zxhtasWaPw8HAFBQXJ399fjz32mEaOHKnvv//e6VTr//nPf+y2LVy40OGxI0eO1MSJE1WlShUFBASoXLlyGjBggDZu3GjtVpPawYMHtWjRIjfu0HWpgw1fX189+OCDXrlORkyZMsVmJqu6detq+PDhGS5v7NixNkHR+vXrbcbcyelSd8cqU6aM+vTpYx3Q+MKFC1qxYoXXrp06EJNkmkAMAJC9CHYAAF6xY8cO/fLLL3bb+/fvr6+++kp/+9vfVKpUKRUoUED58+dXkSJF9MQTT2jQoEFau3at3RMDSUlJ+vrrrx1ey9n01DVr1tTo0aNVunRpBQQEqGrVqrl2RiJ31a9fX82bN3e4r1SpUrp+/boMw3BrcdR9Z+jQoU5nMmvSpIm2bt2qGzduKD4+Xvv379fQoUOdvkcLFizQ7t277bZHR0c7HHfHYrGof//++v3333Xr1i2dOHFC48ePdxhmSVLfvn2VmJjocF9mbd++3Wa9du3aXrlORvzyyy+aOXOmzbZhw4Zp1qxZDgNWZ4oVK6bo6Gh17drVui0lJUXvvvuux+qaFfbt26edO3da11M/+fXFF18oKSnJa9e+93Px888/e+1aAIDcg2AHAOA1ffr00e3bt+22d+jQQUuWLNGZM2d08+ZNJSUlKSYmRrt379aHH37o8D+TI0aMsBtb5a5t27Y5rcOQIUN0+vRp3bp1SwcOHHDrP6q5Wd26dbPkOps3b9aECRMyXc6BAwfUq1cvh/tu3bqlgQMHZqr8CRMmaM2aNZkqIy33fkbr1KnjtWtlRJ8+fbR582abbS+99JKOHj2qL7/8Ul26dFG1atVUtGhR+fr6ytfXV0WKFNHjjz+uzp07a/bs2Tpx4oQ6d+5sU8Y777yT5s9nTpU66Eo98LM3u2FZLBbVqlXLun7r1i3t27fPa9cDAOQeBDsAAK/ZsmWLXnzxxUx/wz116lSNGjXK6f79+/dr69atmboGvOett95yOpaPKzZt2qTGjRunOUPQF198oUmTJmWo/KlTp3qk61la1q9fr+TkZOv63dmWMiIyMtLtp6lSL3e7FaWWkJCgyMhIffnllzbbg4KC1KVLF3355Zfat2+fLl++rMTERCUmJiomJkZ79+5VdHS0XnzxRZtp3OPi4vTaa6+l+XObk82bN89uTK+ff/5Zv/32m9euGRYWZh20WZK+//57m88MAADOEOwAALwqOjpa4eHhGfrW/s8//1SbNm30+uuvO3zyJ7UXX3xRp0+fzmg14UWGYej1119X27ZtdfjwYZfPO3funN566y01atTI6dNaqb355pt64403XJ7V6tSpU9bPl7fFxMRo48aN1vWHHnpIjz76qNev6464uDh169ZNTZo0sXt6x1XXr1/XjBkz9PDDD+vTTz/1cA2zTmxsrN3YTd58WkeS2rRpY7PubOwoAADuxXTnAACv27Vrl8LDw/XUU0+pefPmqlOnjh544AGFhoYqKChI+fLl0/Xr13X16lX98ccf+uWXX7R06VK3wqDDhw/riSee0MCBA9WyZUs98MADslgsunbtmmJiYrRv3z5t3brV4WxbyBqLFi3S4sWLFRUVpcjISIWHh6tMmTIqUqSIJOny5cu6cOGCtm3bpvXr12v58uVOB8Z25pNPPlF0dLQ6duyoyMhIVatWTSVKlFBgYKCuXLmic+fO6ZdfftGiRYu0Zs0at8vPjAULFigiIsK63r59e5cGE89q69at07p161S+fHm1aNFCYWFhqlKlisqVK6fg4GAFBQUpKSlJ169fV2xsrP766y/t3btX27Zt06pVq9Kcxt5MZs6cqe7du0u60y3qq6++8tq1LBaL2rZta12Pj4/XkiVLvHY9AEDuYjGcjWiYyurVqxUVFZUV9QEAAMiVChQooBMnTqhYsWKS7sw+dv/993t1MF6YQ9OmTbVq1Srr+meffaZXXnklG2sEAMhuwcHBio2NdeXQb+iKBQAAkAXi4uJsuieVKlVK7du3z8YaIafo06ePzXpGx4sCAORNBDsAAABZZOLEibp69ap1fdiwYQ4HM0beERYWZvNk/IIFC7w6SDMAIPch2AEAAMgily9f1vDhw63rVapUcTqNO/KGjz76SBaLRdKdsXUGDRqUzTUCAJgNwQ4AADlE//79MzWNtSuLO7NSwTumTJmiX3/91br+wQcfWMfdQd7Svn171a9f37o+atQonThxIhtrBAAwI4IdAACALJSUlKQuXbooISFBklS8eHFTTw2OjAkNDdUnn3xiXd+2bZtGjRqVjTUCAJgVwQ4AAEAW27dvnwYPHmxdb9eunbp27ZqNNUJWslgsmjlzpu677z5J0vXr19W1a1fdvn07m2sGADAjgh0AAHKISZMmyWKxeHWpVKlSdt8m/r/Jkydr1qxZ1vXp06friSeeyMYaIau8++67at68uSTp9u3b6tChg/76669srhUAwKwIdgAAALLJq6++qo0bN0qSChQooCVLlig0NDR7KwWvatu2rd577z3rev/+/bVq1apsrBEAwOyYXxMAACCbJCUlqWHDhtldDWShb7/9Vj4+fLcKAPAc/qoAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASRHsAAAAAAAAmBTBDgAAAAAAgEkR7AAAAAAAAJgUwQ4AAAAAAIBJEewAAAAAAACYFMEOAAAAAACASeX3ZGGhoaEqWrSoJ4sEAABIU3Jysg4dOpTmMRUqVFBgYGAW1QgAAMA1v//+e6bL8GiwM2jQIA0YMMCTRQIAAKTp5MmTKl++fJrHzJs3T+Hh4VlUIwAAANdYLJZMl0FXLAAAAAAAAJMi2AEAAAAAADApgh0AAAAAAACTItgBAAAAAAAwKYIdAAAAAAAAkyLYAQAAAAAAMCmCHQAAAAAAAJMi2AEAAAAAADApgh0AAAAAAACTItgBAAAAAAAwKYIdAAAAAAAAkyLYAQAAAAAAMCmCHQAAAAAAAJMi2AEAAAAAADApgh0AAAAAAACTItgBAAAAAAAwKYIdAAAAAAAAkyLYAQAAAAAAMCmCHQAAAAAAAJMi2AEAAAAAADApgh0AAAAAAACTItgBAAAAAAAwKYIdAAAAAAAAkyLYAQAAAAAAMCmCHQAAAAAAAJMi2AEAAAAAADApgh0AAAAAAACTItgBAAAAAAAwKYId5BjLly+XxWKxLseOHcvuKsENjRs3tnn/LBaLevTokd3VApBBXbp0sfuZbtasWXZXC8hzaB+ZF20jIHvlpbZMrgt2Pv30U5s3bvPmzdldJSDXmzFjhv73v//ZbCtZsqQmTJhgc8y9v1jvLkuWLHH5Wh999JHd+UOGDPHYvcB9W7duVb9+/VSjRg2FhobK19dXRYoU0VNPPaU+ffpox44dbpV39uxZjRo1ShERESpXrpwCAwMVHBysihUrqmPHjvriiy+UnJzspbtx35dffqlChQrZfS4/+ugjt8rZuHGj+vbtqyeffFKhoaHy8/NTcHCwypcvr2bNmmnUqFE6efKky+UlJSXp22+/1d///ndVr15dxYsXl5+fnwoWLKgyZcqofv36+uc//6lt27Y5PH/y5MkqXry4zbZVq1Zpzpw5bt0X0hYTE6NvvvlGvXv3Vq1atfTggw+qUKFCCggIUJkyZVSjRg21a9dO06ZN0+HDh7O7ugBcRNsob8vLbSNP37sjU6dOdfhzU7JkSZvj8lRbxnDBqlWrDEnpLuPHj3elOK+aNm2aTZ02bdqU3VXKcZKSkozAwEBDkjFt2rTsro7VsmXLbN67o0ePZneV4ILLly8bRYoUsft9MG/ePJvjPvvsM6e/Ox566CEjMTHRpeuNGzfO7vzBgwd749aQjlOnThktWrRw6e/Diy++aMTHx6db5pgxY4wCBQqkW17lypWN7du3Z8FdOs6CKEIAACAASURBVHf16lWjU6dOTus4btw4l8o5dOiQUbduXZdeRx8fH6N3797G9evX0yxzyZIlRpkyZVwqU5IRHh5u/Pbbb3blzJ492+7YYsWKGVeuXMnQa+YtJ06cSPcet27dmt3VtHHq1Cnj9ddfN/z9/V1+nyQZkZGRxk8//ZTd1c+xbYnMyKn3RPvIfGgb5V15uW3kjXt35OjRo0bBggUdlhsaGmp3vBnaMs5ep+DgYFeL+DrXPbGD9B04cEC3bt3K7mogl3j//fd15coVm221atVSx44dXS7j0KFDmjJliqerBi86cuSIatasqeXLl7t0/Jw5c9S6dWvd+dvl2FtvvaUhQ4YoLi4u3fL+/PNPRURE6Oeff3a5zp60efNmVa9eXfPnz89UObt371bNmjW1detWl45PSUnRp59+queee043btxweMyUKVP0/PPP6/Tp0y7X46efflLt2rW1fft2m+3dunVTjRo1bLZdvnxZI0aMcLls2Js7d64qVaqkTz75RAkJCW6du2bNGoWHh6t3795KSkryUg3TlxvbErnxnpA9aBvlTXm5beSNe3fEMAy9/PLLTttAjuSVtgzBTh60c+fO7K4CcokTJ07o008/tdv+4YcfymKxuFXWiBEjFBMT46mqwYtiY2PVuHFjnTt3zq3zVq1a5bSRumDBAre7LsXGxqpdu3aKjY1167zMSE5O1nvvvacGDRro+PHjmSorNjZWLVu21LVr19w+d/v27erfv7/d9l9++UX9+vXLUH2uX7+uDh062AQNPj4+GjVqlN2xU6ZM0ZkzZzJ0nbxuyJAhevHFFxUfH2/dVqxYMb322mtaunSpDh8+rGvXrik+Pl4nTpzQpk2b9M4776hy5co25UyfPl0RERFZ+vlPLTe2JXLjPSHr0TbKm/Jy28gb9+7MtGnTtGHDBrfOySttGYKdPIiGCzxlwoQJdt8Y16pVSw0aNHC7rCtXruj999/3TMXgVf/+97915MgRm20+Pj56++23dfz4cV2/fl0rV65UxYoV7c4dOXKk3RMKycnJGjx4sN2xjz/+uDZs2KAbN27o0qVL+vTTTxUYGGhzzKlTpzRx4kQP3FX6zpw5o2eeeUbDhw/X7du3rdtLly6toKAgt8sbN26cwwbFs88+q61btyo2NlYnT57UzJkzdd9999kdN2vWLB09etRm28iRI5WSkmJ3bLdu3bR//34lJCTo2rVrWr58uR555BG7444dO2b3FFJUVJSqV69usy0xMVGTJk1y6T7xfz777DN9+OGH1nWLxaKBAwfqr7/+0tSpU9WyZUtVrFhRhQoVkr+/v8qVK6enn35aw4cP14EDBzRjxgwVKlTIev6PP/6ol19+OTtuJVe2JXLjPSHr0TbKm/Jq20jy/L07c/ToUZvXxJ2gNE+0ZVzpsMUYO7lLWFiY9fWhDzky6vr16w77t3711VcOj0+rH/ndJX/+/MYff/yR5nXpR569Tp486XBMkOnTp9sde/DgQSMgIMDu2CVLltgct2jRIrtjChUqZJw7d86uzKlTp9odW7JkSSMpKclr93zXN998Y3ft9u3bG5cvX3Y4nk1aY+zcvn3bKFWqlN05jz32mMN7WbNmjcOfmUmTJtmU6agPfu3atR3W4Y8//jDy5ctnd3yHDh3sjp0zZ47dcYULFzbi4uIy8Ep6nhnG2Dlw4IDNz07+/PmNL774wu1y9uzZY5QsWdLm3qZMmeKFGqctp7YlMiOn3hPtI/OgbZQ35eW2kTfu3ZGUlBSjYcOGNue1atXKrixHY+zclZPbMs5+/hljJx2zZs2yjpz98MMPW7cbhqHFixcrMjJSJUqUkK+vr0JCQlStWjX17dtXhw4dclrmuHHjrGU++OCD1u2XLl3Su+++q1q1aql06dLy9/dX6dKl9fTTT2vixIlpPoI/ZswYa5n58+d36d4mTZrk8JzUs4WlHon8tddesxlJPKPfViUmJurrr79Wly5dVK1aNRUtWlS+vr4KDAxUqVKl9PTTT2vw4MH65ZdfXC7zbgqbnJysmTNnKjIyUg8++KACAgJUpEgRPfbYY+rXr5/++usvl8q7ffu2VqxYob///e+qUaOGihUrJj8/PwUFBals2bJq2rSpxo4dqwsXLqRZjjfe63udOXNGI0eOVOPGjVW2bFkFBgaqUKFCqlSpkpo3b67p06fb9d2+V+rPgsVi0erVq12+viu+/fZbu/6tISEhatWqlctl1K1b12Y9OTlZAwcO9Ej97rVlyxYNHTpU4eHhuv/++1WgQAEVLFhQFSpUUHh4uIYOHerSLHozZ860G4E/MjLSut8wDC1YsEDNmze3zgRQvHhx1alTR2PGjNH169ddqm9sbKymTZumF154wfoNfkBAgCpUqKCGDRvq448/Tvez6g0LFiyw+2YlPDxcr7zyit2xDz30kFq3bq2KFSsqMjJSb7zxhiZNmmT3jc3ChQvtzu3SpYtCQ0Pttvfo0cPu6Zhz585p06ZNGbmdDAsJCVF0dLQWLFigokWLun3+nj17dPbsWbvtb7/9tsPf902aNFG5cuXstv/666/Wf1+4cMFhH/wOHTo4rEPlypX11FNP2W131MWsXbt2KliwoM22a9euaenSpQ7Lhr0RI0bY/Oy8++676tq1q9vlVK9eXV999ZV8fP6vCTdixAibrl338lR7IiNtCdpHtI/yUvuItpF320ZSzmwf5eW2kTfu3ZGpU6fadMEqWrSo2z8Xub4t40r8k9ue2ImOjrZJMw3DMK5cuZLurCR+fn5GdHS0w+umTkqLFStmGIZh/PTTT0aJEiXSLLNcuXLGli1bHJY5evRo63H58uVz6f4nTpzo8Jx7Xxdny44dO1y6Tmrbtm0zKlWq5FL5kox27doZV69etSvn3m+kTp48aZw9e9aoWbNmuu/LvbMM3Gv//v1GjRo1XKpfUFCQ8dlnnzktyxvv9V1JSUnGoEGDDD8/v3TrWaxYMWPWrFlOy0r9WZBkrFq1Ks1ruysyMtKuTr169XJ6vKNvpSZPnmyUL1/ebvv//vc/p+W4+63Uzz//bDzzzDMufz7r1auX5owz8+fPtzvn7hMRly9fNho0aJBm+WXKlDH27t3rtPyUlBTjo48+MoKDg9Ota6FChdL8rHpD7dq17eoxd+7cTJV579MHkoxvv/3W6fFNmjSxO37YsGGZqoMr7j6xExERYZw8edJmn7tP7GzYsMFo2LCh8eSTTxqVKlUyihcvbvj7+zv8Ju4uR5/jNm3aWPefPn3a4efkyy+/dFqmo9kratWq5fDYbt262R37/PPPOy07K+X0J3aOHDli83RU1apVjeTk5EyV+dprr9ncX1pPmHiqPZGRtgTtI9pHeal9RNvo/xZPto0MI2e3j/Jy28gb936vI0eOGEFBQTbXmDVrlrF79267a6f1xI5h5Ny2jLPPMk/spMPPz8/677i4OCUmJioiIiLdWUkSExP18ssv6/fff7fbl/rbnxs3bujUqVNq1qxZuonxyZMn1aJFCx08eNDNu8gZDh48qIiICB0+fNjlcxYuXKhWrVqlOwq6xWJR06ZN0/2WLDExUd27d9dvv/3mcP+hQ4dUv3597dmzx6X63bx5U7169dLs2bMd7vfWe52cnKwWLVpo7NixSkxMTLeely9fVo8ePTRmzJh0j/W0+Ph4/fDDD3bbmzVr5lY5169f18iRI+22DxgwwOE4Ie764osv9Mwzz7j1jcWWLVtUv359zZ071+F+f39/u22xsbHW92/jxo1pln/69Gk1btxYly9fttuXkpKi9u3ba+DAgS59exUbG6tevXrpgw8+SPdYT7h165bNN9p3RUREZLjMs2fPOhxsr2rVqk7PcTQ2TFaMjVGgQAF9/PHHWrt2rcqWLZupsho0aKD169dr165dOnTokC5cuKD4+HiH38TddfHiRbttqZ8WKlmypAoXLmx3TFoDA54/f95uW5UqVRwe6+jn+/vvv8/WmZnMYtGiRTbjMvXt21f58uXLVJn9+/e3GV9gwYIFmSrPW2gf0T7KK+0j2ka2PNU2knJ2+ygvt428ce/3Mv7/LFg3b960bmvevLleeuklm7+rrsrNbZk8Gez4+vpa/x0fH68PP/xQu3bt0iOPPKLo6GidPXtWSUlJunTpkpYvX67HH3/cenxCQoImT55sV2bqBlpCQoIGDRqkK1euqG7dulq8eLHOnTunxMREnTt3TvPnz1elSpWsx1+5ciXDs5i4qnfv3jIMw24az2nTpskwDOtS8/+xd9/hUVTtw8fvTYOQBBJaaFKlCDaQjkbEIIQiKFU6iIAi0iyA8KD0ooCKgiJdEAQLUkIRpYMEECJSpPceAgFSyXn/8M3+Mruz2d1kN8kk3891zQXTzpzZlnvvPaVmTafK/fDDD81NTn18fGT48OESEREht2/flqSkJImJiZGTJ0/K0qVLNU1Lt2zZIitWrEiz7KlTp8qhQ4ekcuXKsnDhQrl8+bIkJCTIjRs35KeffpJq1aqZj01KSrI5anz//v01zXKbN28uq1evlkuXLkl8fLzcv39fDhw4IAMHDtQ0bR8yZIhu82B3PdfDhw+XDRs2mNcrVqwo33zzjRw5ckTu378v9+7dk8jISJk4caIUKlRIc97mzZvTeihdbufOnVbN/j09PeWFF15wqpzbt29L586drV53kZGRMnfu3AzVcd26ddK9e3eHgkBLiYmJ0qNHD9m0aZPVvtSJ4RR3796VqVOnyu7dux0q//r16zJmzBir7e+9955u01t7PvroI/n555+dPs9ZR48etQoqixYtKsWLF093mba6CqSVONHbl1ZXWVdp1qyZDBgwwOlZTVzhr7/+kmPHjlltr1ixovn/Hh4e0rZtW6tjvvvuO90vA6dOndIN+tq3b69bh9DQUKt7v3fvnuzZs8du/XO71F9qTCaTze5xzqhUqZLms3PPnj1OT53urPTEEsRHxEe5JT4iNtJyVWwkkr3jo9wcG7nj3i19+eWXmr+hBQsWlDlz5qS7vBwdyzjSriendcVK3aTVZDKpvHnzqpdeesnmwEk3b95UBQsWNJ9TpkwZq2Pmz59v9Xi0bt3a5qBV0dHRqlKlSprjIyMjNce4sqlxitjYWM01MzI4YHJysmagzk8++cTuOV26dFHBwcGqZs2aatq0aZp9lk2N8+TJo0JDQ9X9+/d1y7p165YqXLiwphmnpVOnTlk9J2mZNGmS5ni9JszueK5Pnz6tvLy8zPvDwsLSHMjr4sWLqmzZsubjH3/88TTvy9VSvzZTlmrVqqV5jl5z4/79+yullNq6datuU8q7d+9aleNIc+OoqCjNayP10rlzZ7V7924VExOj7t27p3bt2qXatm2re2zx4sWtXn/r1q2zOi5fvnyqQIECysPDQw0ePFidPHlSxcXFqYMHD6qWLVvqll2oUCHNa+bw4cPKw8PD6rjq1aurdevWqStXrqjo6Gi1c+dOFRYWZnVc+fLlVXx8fHqfUocsXrzY6rop3Xbi4uLUnDlzVGhoqCpZsqTy8fFRRYoUUQ0aNFDjxo1TN2/e1C3zhx9+sCrTx8cnzXosWLDA6hxfX1+X368znO2K5YyEhARVu3Zt3dfRyZMnNcdeuHBBBQYGWh33yiuvqIMHD6q4uDh19+5dtX79evXYY49ZHdeoUSOVnJxssy4VKlSwOmf69Okuuc+MyO5dsQoVKmSuR9WqVV1W7uDBgzX3mBldl5RyLpYgPiI+yi3xEbGR62MjpbJ/fJSbYyN33Htqel2wUn/2RERE6L5H7MmOsYyt2MWZrli5PrEjIiowMFDduHEjzXL79eunOScmJkaz3/KPmb+/v90X7C+//KI5Z8KECZr92T1wiYqK0pS1adOmdJellPXzEhQUZPd5efvtt9N8XrZt26aee+45ValSJZU/f/40+ycrpdT9+/eVt7e3ubyhQ4daHeOO53rAgAHmfUWKFFG3b99OszyllFq/fr2mzPT0/0+vjh07Wr3/O3XqlOY5esFL3759zftbtWpltX/48OFW5TgSvEyYMEH3M+rjjz+2WT/L11LKYtlHO63Pwy+++MKq3KSkJJvjd/3999/m41577TWr/WXLllV37tzRrW/z5s2tjrc164ar6D32TZo0UYcPH1bVqlVL8+9DQECA7gxAs2fPtjq2YMGCadZj5cqVuteIjY11163b5a7EzsOHD1Xnzp117/eVV17RPWfHjh2aRIKjS/369VVUVFSa9XnllVeszuvRo0eG7zOjsnNiJzExUVOPNm3auKzsuXPnaspeuXKl7nHZKbFDfOQ84iNjxEfERq6PjZTK/vFRbo6N3HHvKZKTk63GZrL8+5nexE52jGXSepwclDvH2LHUo0cPKVy4cJrHPP3005p1eyPut2vXTtMcVE/z5s01I3Pv3LnTTk2zl/z582ua3a5du9al5ffq1cvu8/LEE09o1qOiojTrzz33nGzbtk2OHz8ud+7ckRdffDHN8vLly6eZeebmzZt26+mK5zo8PNz8/86dO0tgYKDd6zZp0kRT19WrV9s9x1X0xgyoXLlyhsqcMmWKppukiMj06dN1Z+ixR6+JZpUqVWTkyJE2z5k8ebLu7EaLFy926Jo1a9aUt99+22q7p6enzVH7U5rIPnz4UPMaSDFo0CDJnz+/zfpaSk8zZWdYzvQh8t9YAGFhYfLPP/+keW5MTIx07dpVvv32W812vZl8LF8Hju637EphdImJidKtWzdZsmSJ1T5/f3+b3SsaNGggkZGRMmDAAClWrFia1zCZTFK/fn35+uuvZevWrRIUFJTm8Xrvc0dn3smtLMeMSM8sarZYlmVrfIrshPgo44iP0pZV8RGxkbWMxEYixoiPcnNs5I57T2HZBatIkSIya9asDNU3RU6NZUjsiNj9YyYiVn9A9aaUTc2R/rReXl5SvXp183pmjBHhSp6entKwYUPz+owZM2TAgAFy6dIll5TvyMBbls+LKz68fH19zf9PSkqye3xGn+srV65ogoHUx9lTt25d8/8jIyMdPi+j9AZjzWh/2kqVKkm/fv002+Li4mTYsGFOlXP+/Hk5c+aM1fZOnTppxgiwlC9fPmnRooXV9oiICIdeBz169LC5z3Lq0hTR0dEi8t/4KSn/T6127do2y6xatarVl/DU00C6g96Ahbt27ZILFy44XMbbb78tp0+fNq/rDXxnb1BZW8FLThj4LsXt27elWbNmukkdk8kk8+fP10wnbOnixYty584du4OwKqXk8uXL8vfff8vZs2ft1qtkyZK614JtloFvvnz5XFa25bStekF2dkN8lHHER/ZlRXxEbGQtI7GRiDHio9wcG7nj3kVETp8+bfUanz17thQpUiR9FbWQU2MZEjsiUrZsWbvHWI72bi9YtvylxJYyZcqY/+/MmyC7mDp1quYP/cyZM6V06dLSoEEDGTVqlGzevFk36+yI0qVL2z3GcrC2tJ6Xa9euybx586RXr17y7LPPSsWKFSU4OFiCgoLE399f8ubNK15eXnYzzJYy+lyfP39ec1z37t3FZDI5tKQeYDEzZw7Rm53HXssAR4wePdpqVp9ly5Y5NaDZ/v37dbc7MvClXtAYGxvr0KwmqYNIS4ULF9YNnFIGOtULtkT+C3psPfceHh5WLQdv3bqlO8uRq6Q1G8dzzz0nv/32m9y6dUtiYmIkPDzcqqWjyH/3PHXqVPN66llUUtib5cBWkGLv1yyjOHnypNStW1d+++033f2fffaZ7iDJIv89R0OHDpW6devKokWLHHo9nD17VmbOnCnVqlWTr776Ks1j9b6kuPM1lxNYtjDQG3Q2vSzLstfiKjsgPiI+spRT4iNiI2sZiY1EjBEf5ebYyB33rnRmwercubO8+uqrLqt3To1lSOyI9S9eruBoU+vUH9SxsbEumcYwM1WvXl02bdok5cqVM29LTk6WXbt2ybhx4yQ0NFSCgoKkadOm8u233zoV0LrqV834+HgZPHiwlClTRl5//XWZP3++7Ny5U06ePCnXr1+X6OhouX//vsTHx6dr2ryMPteWzaPTS+8XDXdITEzU/ePhiuerUKFC8uGHH1ptHzx4sPn/9mYk0gusRERKlChh9/q2AjBHnqO0gjdPT0/daaidKd9Rzkyt66yAgADd7fXr15fffvtNXnzxRSlYsKD4+/tL06ZNZfv27bqPe+oZKvReN/Z+XbK135UtIbLKzp07pV69erpfRLy8vOTrr7+WAQMG2Dx/1KhRMm3aNM2XOC8vLxk1apQcP35c4uPj5c6dO7J161Z5+eWXNecmJCRI//7902yyrvcY57QucK4WFBSk+dxypAuLoyw/O+x1e8kOiI+IjyzlhPiI2Mi5c0Xsx0aOXsNR7oqPcnNs5I57nzlzpmzdutW8Xrx4cfniiy9cWu+cGsuQ2HETPz8/h46z/EUlPdMPZrUGDRrIiRMn5LvvvpM6depY/XGJi4uTDRs2yBtvvCFly5aViRMnZlqAFh8fL40aNZIZM2a4bRrYjD7XqTPSGZFZTfBtPY558+Z1SfnvvPOOVSu6PXv2yPfffy8i+r9ipKbXLFRE24TcFlvH2CozNctWfZbSaursyufu7t27LivLkq3+7B999JHuVKf+/v66zcWvXbtm7sus90XU3uOh93z4+fnZfQ6yux9++EFefPFF3S/+QUFBsmbNGunTp4/N80+cOCFTpkyx2j5t2jQZM2aMVKpUSXx8fCR//vwSEhIiq1at0p3afOjQoTab2Ou9R5RSbp9m28g8PDw043389ddfLiv70KFDmvXULR+yK+Kj/0N89J+cEB8RG+nLSGwkYoz4KDfHRq6+99OnT8vw4cM1++bMmePy1qg5NZYhseMmjr4wUjfDNZlMhv1i4unpKZ07d5Y9e/bIlStXZP78+dKxY0ervpDR0dEyYsQIefXVV9P164+zRo0aJbt27TKve3t7S/fu3WXZsmWyb98+OX36tERFRUlMTIzExsZKUlKSVKtWzalrZPS5tsx2b9iwQZRSTi+ubN6fHva6JzoqT548MnHiRKvtw4YNk7i4OLtBkq0/Mo4EiLaOsfeLUkbZ+sUjPRwJtNJLr0+ySNrjHthq5p3S5FWvzISEhDQDGL1fHh3pmpCdLVq0SF577TXdz5PHH39cIiIipEmTJmmW8d1331klZAIDA63GZ0hNb1DL8+fPaz43U3PV+zy3adCggfn/ly5dcmg8I0ek7opRsGBBh7u+ZCXiI+IjSzk5PiI2yhgjxEe5OTZy9b1v3LjR6vXWokULm93uatWqpVtO6mPGjRtndUxOjWVI7LiJo39EUjcPDQgIsNuU0h53/lrvqODgYOnRo4d8//33cu3aNdm/f78MGzZMM87AqlWrXDayuS1xcXGaGQCCgoLkzz//lAULFkiHDh3kmWeekXLlymn6kHt6ejodUGX0ubYcfyG7z2pi65eb9I4VoKdjx45Sp04dzbbz58/LtGnT7M6IYWtgNUcGRbM1sKWrBmuzxdYvEQcOHHA6gNVrgeEqTz31lO72tH5htvVHP+UX2cqVK+t+7lmOrWBvX5UqVWwen9398MMP0rNnT93HsXXr1rJ7926pUKGC3XIOHjxota1SpUpp9q+vVKmS7va///5bd7ve+9zIX7ozS0hIiGZ9/vz5GS7z+PHjmnEznn/+ebu/fjvDXfEE8RHxkaWcEB8RG7mHEeKj3BwbuePeM0NOjWVI7LjJsWPHHDou9a92lk2oU7+hHz586NAfVFf9CugqJpNJatSoIRMnTpR//vlHKlasaN6n12XAlf7++29NsDBixAi7MyokJCQ4PUhjRp9ryw/vw4cPO3X9zObp6an7RdHeTHHO+vTTT622TZo0ye77oEaNGrrb9+7da/eaescEBQWlOfuQKzz22GO627PbgKGVK1fW7Zd8/Phxm+dYDmCYIqWZcYECBXSTC7YSCyL6M5xYBrtGsWPHDunWrZtuEPTWW2/Jjz/+6PA4cHq/Rtrrk2+rT7mt97Pe9pwwtpG7tWvXTvM4zZ49O8OJBssxB7p3727z2OwUTxAf/Yf46P/khPiI2Mg9jBAf5ebYyB33nhlyaixDYsdNtm/fbveYhIQEzS+slStX1uy3zP7b+6UiOTlZfv/9dydqmblKlCihGfztwoULbu02cuXKFc16WiPzp/j111+d7tOd0ec6MDBQE9CtWbPGqetnhaJFi1ptu379ukuv0aBBA2nTpo1mW0xMjHz55Zdpnle6dGndme6WLl2a5tScUVFRsm7dOqvtISEhGf6l2J5q1arp/trmyGsrM3l6eupOe5pW6wO9e/D29ta0QGnZsqXVMZs2bdItLzo6Wnbv3m21vXXr1jbrkF3dunVLOnTooNtdYezYsfLll1861QLDcnpjkf+mDE0r4LecYjSFrV9iLT9XRVwz60tOV6hQIc20v9evX5dBgwalu7w9e/ZoWnVUq1bNajDs1LJTPEF8ZI34KGfER8RGrmeE+Cg3x0buund3y6mxDIkdN1m6dKndQa5+/vlnza+lDRs21Oy3nE1Ar5l9aj/++KOcO3fOqXpmpB/3l19+KW3btpWyZcvK0qVLHTrHcno5VzYbt2RZtr0gKTo62mpAL0ea0LriuU4dkEdGRkp4eLjd68bHx8vTTz8t7dq1kwULFmTarFgi+rMoXL582eXXmTx5stXga7bG/khNb4DZ06dPy9ixY3WPT05Olrfeeks3g9+3b18Ha5t+JpNJ94/v7Nmzbc7isG7dOvH395fy5ctL3bp15eWXX9bMkCEisn79et0+yTt27Eh3Xbt06WK1bfHixbq/FMXExMi0adOsttetW1fzy0inTp2sjlm+fLlcvXrVavvnn39u1QqlZs2aVl/83HHvrta/f3/d903fvn1l5MiRTpen94vsnTt3ZNGiRTbP+frrr3W36/VbF9F/n9tqVg2t4cOHa/6ujcdb0wAAIABJREFUz58/X8aMGeN0OUeOHJE2bdqYW3mZTCaZPHlyml+y3B1POBNLEB/pIz76j5HjI2Ij1zNKfJSbYyNX3nu/fv2c6l4XERFhVVZwcLDmGL14KqfGMiR23OT69esyYMAAm4Mz3bx5Uz744APzul7Gs2rVqpr12bNn27zekSNHpH///nYHT/P09NSsZ6Qp4549e8zB0ocffmjzl9/UVqxYYf5/qVKlHJ4xIT1STzEqImlO4Xv58mVp2rSpREVFSe3atc3bHWm67Yrnum/fvppAq1evXmk2Y0xISJDXX39dDh06JCtXrpQ+ffpk6uCAqX9BS5FWfdOrQoUK0r9/f6fPe/PNN3VbL4wZM0Z69+4thw4dkvj4eImOjpZNmzZJ48aNZfny5VbH16xZU5o2bZquujtryJAhVl/M7t27J88++6zMmzdPrl27JomJiXLhwgWZOXOmdOzYUe7fvy9nzpyRP//8U1avXp0pfYObN29u9aU/KSlJQkNDZdGiRRIdHS2xsbHyxx9/SMOGDeXMmTNWZVgO5lu9enV57rnnNNvu3bsnYWFhsmPHDomNjZVr167JlClTdL8IDxkyxAV3lrn27t2r+5orVqyYblN7R7Rp08bqM17kv8+X0aNHy/HjxyUhIUFiY2Nl//790qlTJ/nhhx+sjq9WrZrNQVL13uePPvpouuqb25QqVUrmzZun2TZ69Gjp1KmTzTEsUlNKycKFCyUkJEQTlL733nvSvHnzNM91dTyRkViC+Egf8ZHx4yNiI/cwQnyUm2Mjd9y7u+XYWEY5IDw8XImI3eXTTz91pDi3mjVrlqZO27dvtzpm9erVmmPOnDljt1zLc44eParZP3/+fM3+9u3bKxFRISEhatWqVeratWsqISFBXblyRS1evFiVKVNGc3yXLl2srpmYmKiKFSumOa5bt25q//796v79+yo+Pl4dO3ZMjR07VgUEBChPT081btw487Genp669+Lv728+plixYmrXrl0qLi5OXb9+XZ07d86xB1opFRERoUwmk7msggULqnHjxqmIiAgVHR2tkpKS1L1799SFCxfU2rVrVatWrTT3MmLECLc+L8nJyapUqVKa/f3791f//POPio2NVVFRUWr37t3q/fffNz8ms2bNUm+++ab5eJPJpJYuXapiY2PV3bt33fZcK6XUBx98oDnOz89PjR49WkVGRqp79+6pu3fvqmPHjqlZs2apxx9/XHPsm2++aVXe9OnTNceEh4c7/NzaM3nyZKv3f7Vq1dI8Z86cOVbn9O3b1+61oqKiVFBQUJqfPR988IHVeeHh4ZrXp7NLQECA+vfff3XL1Tv+xo0bad5HoUKFrM6ZNWuW5pghQ4aku77ly5c3v0bt1VXvc9EZ+/fvV97e3umqZ506dVRSUpJVmQcPHlSenp5Ol9ewYUPdOrrj3ocOHZru5yf18vrrr6tevXq5pCwR7WflW2+9leHy1qxZY/MxqFChgtXxM2bMSPdj6irnz5+3e1+7du3K6moqpZSaMWOG8vDw0NTNz89PdevWTa1cuVKdOHFC3blzR8XFxakLFy6oXbt2qY8//lg98cQTVvfUuXNn3feTJXfEE47GEsRHxEe5JT4iNrI+3hWxkVLGiI9ya2zkrnt3REREhFV5wcHBds/LjrFMWu85B/1AYkfck9j5999/VYECBRx63EqVKqWuXr2qe91PPvnE4TfGiBEj1G+//WZeN5lMumWGhobaLGPo0KH2H+RUhg8fnq438ZNPPqnu37+f5mPsiufF8vWQ1tK+fXv18OFDtXDhQt39rVq1Ukq577mOj49XYWFhTj+WzzzzjLp3755Vee5M7GzevNmqHp6enio6OtrmOekNXpRSatq0aWk+BnrBi1JKLVy4UPn4+Dj9mBYpUkTt2LFDt0x3Bi8JCQmqRYsWTtc3ODhY/f333w7XNaN/wJVS6pdffnH6j3jZsmXV+fPnbZbpzPtVRFTFihXVpUuXdMvK7omdzp07u6QsEe1nZXx8vHrppZfSXdakSZNs3v/Nmzd1vxDYeq9kJiMldpRS6ueff3b474be4unpqcaPH+/UNV0dTzgaSxAfObcQH1kzSnxEbGR9jqsSO0aJj3JjbOTOe7cnPYmd7BrL2HqMnEns0BXLTYoXLy7h4eF2B2KqUqWKrF+/XoKDg3X3Dx48WLp27Wr3eu+++66MHz9e0zdTKaU7ddyIESNc1nd7/PjxMnXqVJvTPOrp2LGjbN26NVNGH+/Xr59DzVV79uwpS5cuFQ8PD2nTpo1T/Sxd9Vz7+PjIr7/+Ku+9955DTUZNJpP06tVL/vjjD7c22dbToEEDq+f84cOH8scff7jlev3790/XoGrdunWT7du3S/369R063mQySfv27SUiIkIaNGjg9PUyytvbW1atWiUfffSRw89ps2bNJCIiQh5//HGHr+OK93+rVq3k999/t9llx9Irr7wiERER8sgjj9g8pl+/frJo0SKHZkZo0qSJbNmyRXdMg7S4c9yK7MDHx0fWrVsnEyZMkICAAIfPK1eunKxdu1bTLcLSpk2brLpUBAQEGHZGsqzUunVrOX36tAwdOtRuF6HUPDw85LXXXpMjR47IiBEjnLqmq+OJ9MYSxEe2ER8ZOz4iNnIfo8RHuTk2cse9u0OOjmUcSf/QYsf5Fjsp2fk7d+6oL7/8UoWEhKiSJUsqHx8fVbx4cRUSEqK++uorq19lbFm7dq1q27atKl26tMqbN6/y8fFRpUuXVt26dVMHDx40HxcZGampR1RUlG55GzZsUM8++6zKly+f8vHxUcHBwaphw4bql19+cag+lm7cuKGmT5+uWrRooSpUqKD8/f2Vh4eH8vX1VSVKlFCNGjVSI0eOVP/884/NMtzxvKTYuHGjatu2rSpVqpTy8fFRefPmVRUqVFDdunVT27Ztszr+yJEj6qWXXlJ+fn4qT548qmzZsmrChAlKKfc/10r99+vzhAkTVKNGjVSpUqWUr6+vypMnjwoODlYhISFq5MiRuk1hU3Nnix2llGratKnVZ8Abb7xh8/iM/CqllFIrV660+dlj61ep1LZs2aLeffddVatWLVWiRAmVJ08e5e/vr8qWLasaNWqkxo8fn+brM4W7f5VKcePGDTVt2jTVokULVbZsWeXv7698fHxUkSJFVK1atdTgwYPV/v3701XXQ4cO2b1PRyUmJqoff/xRdenSRVWpUkUFBgYqb29vFRwcrGrVqqXee+89deDAAafKvHXrlpo2bZoKDQ1VpUqVUnny5FGBgYHqscceU3369FEbN260W4Y77t0ILXZSu3v3rpozZ47q0qWLqlq1qipcuLDy9vZWefPmVcWKFVO1atVSb731llq9erV6+PCh3fvv2rWr1bVbt26d7sfTlYzWYie1qKgoNX/+fNWtWzdVvXp1VahQIeXt7a3y5MmjSpYsqZ5++mn12muvqfnz59v8FdYZrownHIkliI+Ij3JTfERs5N7YSCljxEe5KTay5I57tyU9LXayayxj633sTIsd0/8vKE3r16+XsLAwe4fJp59+ashBLF1hwYIF0rNnT/P67du3dafng/HxXP9n0aJF0r17d822wMBAuXr1aqYM4gvnlClTRs6fPy8iIufOnZPSpUtncY0yT26+d1d58OCBBAcHW81ws3z5cmnfvn0W1er/XLhwwe7zumvXLqlXr14m1Qgp+JuZe/BcExsZUW6NEXLjfWfnWMbWzJYBAQFy9+5dR4pYkbPbpANwmzZt2oi/v79mW3R0tPzyyy9ZVCPYcv/+fbl48aKIiOTLl8/pJrpGlpvv3ZVWrlxpFQgVKFBAMxUxAOR2xEbGkltjhNx63zk9liGxAyBd/Pz8pHfv3lbbp02blgW1QVpWr14tycnJIiLyzDPPiJeXVxbXKPPk5nt3Jb33dZ8+fZwaHwYAcjpiI2PJrTFCbr3vnB7LkNgBkG5DhgwRb29vzba9e/fKli1bsqZC0PXVV1+Z/9+6dessrEnmy8337irh4eFy6NAhzTYfHx8ZNGhQFtUIALIvYiPjyK0xQm6879wQy5DYAZBujzzyiPTr189q+wcffGA14jyyxurVq2X79u0i8l9zW0dmkckpcvO9u0pycrLu7Etvv/12rmm6DQDOIDYyhtwaI+TG+84tsQyJHQAZ8tFHH0lQUJBm2969e+X777/PohohxfXr16VPnz7m9ZEjR0qRIkWysEaZJzffuystWrRIDh48qNlWqFAhGTVqVBbVCACyP2Kj7C23xgi59b5zSyyTOzrUAXCbggULypQpU+SNN97QbB86dKiEhYVZBTbIPEWLFpUrV65kdTWyRG6+d1e5efOmvP/++1bbP/3001w30w0AOIPYKHvLrTFCbrzv3BTL0GIHQIb17t1bQkNDNduuXr0qgwcPzqIaAciogQMHyo0bNzTbmjZtajWVLwDAGrERkPVyUyxjUg509ly/fr2EhYXZLezTTz+VIUOGuKRiAAAAjrhw4YKULl06zWN27dol9erVy6QaAQAAOMZkMuluDwgIkLt37zpSxApa7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGJSXKwu7du2a/PPPP64sEgAAIE1Xr161e8yZM2ckf/78mVAbAACAzGVSSil7B61fv17CwsIyoz4AAAAAAAC5WkBAgNy9e9eRQ1fQFQsAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAzKoenOAwMDpU6dOu6uCwAAgEvs27dPHj58qNlWtGhRKVeuXBbVCAAAwHF+fn4OH+vQdOcAAABGUqBAAaspQnv37i1z5szJohoBAAC4BdOdAwAAAAAAGBWJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEF5ZXUFAAAAHLFw4UI5evSoQ8fGx8dbbYuIiJBhw4Y5dH779u2lRo0aTtUPAAAgK5iUUiqrKwEAAGDP559/LgMHDnT7dTw8POT8+fNSsmRJt18LAAAgg1bQFQsAABhC+/btxdPT0+3XCQkJIakDAAAMg8QOAAAwhGLFikmjRo3cfp3XXnvN7dcAAABwFRI7AADAMDp27OjW8r29vaVNmzZuvQYAAIArkdgBAACG0bZtW/H19XVb+WFhYVKoUCG3lQ8AAOBqJHYAAIBh5M+fX5o2beq28umGBQAAjIbEDgAAMBR3JV/8/PykRYsWbikbAADAXUjsAAAAQ2nZsqUUKFDA5eW2bt1a/P39XV4uAACAO5HYAQAAhpI3b15p1aqVy8ulGxYAADAiEjsAAMBwXJ2EKViwoDRu3NilZQIAAGQGEjsAAMBwQkNDJTg42GXltWvXTnx8fFxWHgAAQGYhsQMAAAzHy8tL2rZt67Ly6IYFAACMisQOAAAwJFclY0qUKCHPPfecS8oCAADIbCR2AACAIdWvX1/Kli2b4XI6deokHh6ERAAAwJiIYgAAgCGZTCbp0KFDhsuhGxYAADAyEjsAAMCwMpqUqVy5stSoUcNFtQEAAMh8JHYAAIBhPfXUU1KtWrV0n09rHQAAYHQkdgAAgKF17Ngx3eeS2AEAAEZHYgcAABhap06dxGQyOX1ezZo1pVKlSm6oEQAAQOYhsQMAAAytfPnyUrt2bafPo7UOAADICUjsAAAAw3M2SePh4eGSGbUAAACyGokdAABgeB06dBBPT0+Hjw8JCZGSJUu6sUYAAACZg8QOAAAwvGLFiskLL7zg8PGdOnVyY20AAAAyD4kdAACQIzjaHcvb21teffVVN9cGAAAgc5DYAQAAOULbtm0lb968do8LCwuTQoUKZUKNAAAA3I/EDgAAyBHy588vYWFhdo9jNiwAAJCTkNgBAAA5hr2kjZ+fn7Ro0SKTagMAAOB+JHYAAECO0bJlSylQoIDN/a1btxZ/f/9MrBEAAIB7eWV1BVzp9OnTcu3atayuBgAAyEL16tWT9evX6+6rXr267N69O5NrBAAAspPHHntMAgMDs7oaLmNSSqmsroSrvP766zJv3rysrgYAAAAAAMimwsPDpWnTplldDVdZQVcsAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAOCwmzdvilLKailVqlRWVw0wJG9vb/njjz/M76Xz589LcHBwVlcLbtS2bVtJTk42P+dvv/12VlcJAGBwJHYAAACyyOzZs6Vhw4YiIvLgwQNp3bq1XLt2LWsrBbdauXKljBkzxrw+Y8YMadq0aRbWCABgdCR2AACAWb169WTChAmyY8cOOX/+vNy7d0/i4+Pl2rVr8vfff8vChQvljTfekAIFCmToOo899piMGjVKtm/fLqdPn5YHDx7IgwcP5OLFi7Jx40YZNmxYhlqCFS9eXN5++2356aef5MSJE3L79m2Jj4+Xy5cvy969e2XKlCkSEhKSoXvIqHfeeUd69eplXu/Xr58cOHDA6rjevXtrWsitX78+U+rn7+8vrVu3ls8//1w2bdokZ86ckdu3b0tCQoLEx8dLVFSUnDt3Tn7//XeZNWuWtGvXTvLnz59mmV5eXrqt/ly5nD171uq6lo9hylK9enWXPFZvvvmmbvn+/v66x3/88ceydu1aERHx9PSU5cuXS/ny5V1SFwBALqRykF69eikRYWFhYWFx03Lz5k3dz99SpUpled1ERI0fP15Tr3fffTfL62SUpUaNGmrHjh0O/8198OCBmjp1qvL19XXqOsHBwWrZsmUOXSMuLk6NGTNGeXh4OFy+t7e3mjRpkkpISHDoGrt27VKVK1fO9Mf78ccfV3FxceZ6/PjjjzaP7d27t6bO69evd2vdgoOD1fTp09WDBw8cfj2kuH//vpo6daoKDAzULdvLy8vpMp119uxZu49hipkzZ7rkMdu7d69u+f7+/jbPKVasmOYzddeuXcrT0zPTX4ssLCwsuXEJDw93y9+gLPIDiR0WFhYWFoeX7JzY8fDwUOfPn9fUi8SOY0uXLl00SQZnHD58WBUpUsSh69SoUUPdunXL6WusWLHCoeRO3rx51aZNm5wu//bt26pmzZqZ9nh7e3urQ4cOma9/48YNVbhwYZvHZ2Zi5/nnn1dXr151+jG0dOLECVWlShWr8rNbYuf27dsqb968GXrMqlWrZrMuaSV2RER17NhRc/yHH36Yqe99FhYWlty65LTEDl2xAAA5QmhoqDzyyCNZXQ3DCQ0Nlfnz50uePHnSdX61atVk3bp14unpmeZxVapUkfXr10vBggWdvkbbtm3lgw8+sHvcV199JaGhoU6XHxgYKGvWrJEiRYo4fW569O/fX5588knz+kcffSQ3b97MlGun5YknnpB169ZpBm+Oi4uTxYsXS4cOHaRq1apSsGBB8fb2Fl9fXylWrJg899xzMmLECDly5IimrEcffVTWrl0rQUFBmu1JSUliMpkcWubOnas5d/jw4Q6dV7ZsWbv3mpiYKCL/PfevvvpqOh+x/6TuTpeUlOTUucuWLZOdO3ea1z/88EM+xwAAzsvq1JIr0WKHhYWFxb1Ldm6x8/3331vVixY7aS958uRRZ8+edcnf4D59+ti8joeHh9q/f3+Gyn/w4IEKDg62eY2QkJAM38O8efPc/pgXKlRIRUVFma957Ngx5eXlleY5mdVi58CBA5rr7N69W5UuXdqhcz08PNTAgQNVUlKSpoyvvvoq3fX59ttvNWUNGzYs3WVZPoZbt241///3339Pd7ne3t7q2rVr5rIsu2TZa7EjIqpOnTqac5YuXer21yELCwtLbl9osQMAQDYTGBgorVu3zupqGE6PHj2kTJkyuvv27dsnYWFhUrx4cQkICJAnn3xSPvvsM3NLB0uvv/66zev07NlTatSoobtv+fLlUqtWLfHz85PSpUvLsGHDJD4+3uo4X19f6d+/v81rjBo1Snf75cuXpWPHjlKkSBHx9fWVp556SpYtW6Z7bPfu3W0+Hq4yePBgTSuW8ePHO93Kwx1q166tGUj4+vXrEhYWJufPn3fo/OTkZPnss8+sWlb17t1bSpQo4dK6ukLqAagbNmyY7oGLmzdvLkWLFhURkdjYWNm3b5/TZfz555+a+rz22mtStWrVdNUHAJBLZXVqyZVoscPCwsLi3iWjLXZ8fHxUq1at1KxZs9SuXbvU5cuX1b1791RSUpKKjo5Wx48fV7/88osaOHCgeuSRR9Isa9iwYU7/nTh58qSmjMDAQN3j1qxZozmudu3aatGiRers2bMqPj5excTEqMjISDVlyhSb9x4UFKRGjhyp9uzZo6Kjo1VCQoK6ePGiWrt2rWrXrl2WP5ciov744w/d+z948KDy9vbWPeftt9/WPSc5OVkVKFBA95zTp0/rnjN58mTd4y3HHUlx9OhR3ePLlCmjkpOTrY6Pi4uzOTDyunXrdK/x0Ucfue3x9vX11byHrl69qnx8fOyelxktdgYOHKi5xowZM9JVjqenpzp+/LimrKFDh6arLHe22Klfv76KjY01r48bNy5d5f7666/mMn7++Wc1e/ZszXUcabEjIqpZs2aa87755hu3vQ5ZWFhYWHJeix0SOywsLCwsDi/pTex4eHioN998U924ccPhz/SEhAT1zTff2EwWuCKxY2sg1507dyoRUSaTSU2aNEk3aZDi7t27qkWLFppyGzRooK5fv55mXdatW6f8/Pyy7Ln08fFR8fHxunVr0qSJzfN8fX1VYmKi7nlVq1a1Ot6ym0mKQ4cOpTkD0IEDB9TRo0fV6tWr1bRp09Sbb76pGjdurEwmk9Wx77zzju415s6da7P8evXq2ayXux5zy+TCmDFj0nWeOxI7U6ZM0Vxj4MCB6S6rY8eOauzYsapDhw6qatWqdrua2VrcmdipU6eOWrVqlXn94sWLTs9IFRwcrHkvdO3aVS1cuFBzHUcTOyaTSZ06dcp8XmxsrM2ZxVhYWFhYMr7ktMSOlwAA4Ebe3t7mwVedPe+NN96QF198URo1aiTnzp1zed2SkpIkMTFRvL29NdtTusqMGjXK7qC9AQEBsnLlSqldu7ZERkbKY489JuvWrZP8+fOneV5YWJgsWbIky7qQFSlSRDZu3Cj58+eXAgUKmP/18vKSLVu22DwvNjZWoqOjpXDhwlb7fH19rba1a9dOt5xPPvlEHj58aPM6trpu6QkJCdHdvmrVKpvn7NmzR27cuGE1YPITTzwhQUFBcvv2bYev7yjL98APP/zg8mukl2V3sFKlSqW7LFtd3bKTPHnyyIoVK+Tll18WEZGSJUtKkyZNZN26dQ6X0a1bN/E6pyJCAAAgAElEQVTy+i+UjouLk1WrVklYWFi66qOUkpUrV8r7778vIiJ58+aVVq1aycKFC9NVHgAgd2GMHQCAW40aNcrppE5q5cuXl3Xr1qV71iZ74uLirLYFBATIU089Jf/73/8cKiNPnjwyefJkMZlMsmDBArtJnRStWrWSZs2aOVVfV7l06ZK0bNlSnn/+eXn66aelfPnyUqhQISlQoIDuGDcp8uXLJ4UKFdLdd/nyZattDRo0sNqWnJwsa9asSX/lLdhKAv311182z1FKSWRkpNV2k8nkVFLJUQULFpSGDRua10+ePCmHDx92+XXS68SJE5r1rl27SmBgYBbVxv28vLzkl19+kXv37pm39e7d26kyevToYf7/6tWr5e7du2IymdJdp59++kmz3rZt23SXBQDIXUjsAADcJjAw0PwLdGqXLl2SPn36SMWKFcXX11d8fHykWLFi8uqrr8revXutjq9ataq88847mm2TJk0yT288fvx43eu/9957mmmQH330Uatj9Aau9fX1lbFjx9qdwju1Jk2aSP/+/aV27doOnyMi8tZbbzl1fFbr3Lmz7pfX69evy7Vr16y26w0Ce+TIEZe1iPH29pbSpUtbbY+Pj5cLFy6kea5lMiNFxYoVXVK31F544QVz6w4RkQ0bNrj8Ghmxfv16SUhIMK8HBwfL5s2bdd8zOYGHh4fcu3dP02qqRYsW5oGQ7albt67mtT1//nwRkQwldvbu3at5X7z44oua1wwAALaQ2AEAuE2zZs10W9q0adNG5syZIydPnpS4uDhJTEyUa9euyc8//yyNGjXSbWmR1qxLGZGcnGy1rWDBgtKyZUsREfniiy+kbNmy4ufnJ82aNbOZLDCZTDJjxgwREbl586Z07txZ8ufPL8HBwTJ69Gjd64iIhIaGuq01kqsFBwfLxx9/rLtv2bJlVvdYpkwZ3dZLJ0+eNP//2WefldmzZ8vhw4fl9u3b8uDBAzl37pysWbNG+vfvL/7+/mnWqVixYroJuFu3btm9H71ElMh/3XJcrW7dupr1PXv2uPwaGXHlyhX54osvNNtq1Kghhw8flvnz50ujRo2suizmBN9++635/97e3tKtWzeHzuvZs6f5/5cuXZKNGzdmuC5KKU1i29fXV5588skMlwsAyPlI7AAA3KZcuXK6248cOWLznPv378snn3wit27dksjISFm3bp188803smTJEvHx8XFXVTVSfnWfNGmSvPPOO3Lu3Dl58OCBhIeHS7NmzWyODePp6SlxcXHSuHFjWbp0qcTExMj169dlzJgxMnHiRN1z8uTJI5UrV3bbvbiKn5+f/Pjjj1K8eHGrfbGxsTJ9+nSr7Y888ohuWVeuXJGCBQvKsmXLZPv27dK3b1+pVq2aBAYGiq+vr5QuXVqaN28uM2fOlDNnzkiXLl1s1stWt7Do6Gi793T37l2nyswIy5Zc2S2xIyLy4YcfyqZNmzTb8uTJIz169JDNmzdLVFSUbNy4UUaPHi2hoaESEBCQRTV1nd27d8vRo0fN644kkH19fTXdSxcuXJjmeFHOsHxd1KlTxyXlAgByNhI7AIBMl9YXdRGRpUuXSuHCheWpp56S5s2bS9++fWXs2LGariLudvXqVd3WKYcPH5bw8HCb582aNUsOHjxotX369Ok2v/zZSoBlFwEBAbJmzRrd8XJERMaNGydnz57VPU/Pw4cPZd26dQ6NvVS4cGFZvHixjBgxQne/rRY9jrxWYmNjnSozI1In7xITE+X06dMuv0ZGxcfHS4sWLWTy5Mm6j5+/v780btxYPvroI9m0aZPcvn1bDhw4IJ9//rk0b95cd/BsI5g7d675/1WqVJH69euneXybNm2kQIEC5vWUbliu8O+//2rWK1Wq5LKyAQA5F4kdAIDb2JrJ6ssvv5Sff/5Z2rZtqzu7UnawdOlS3YGVRUS2bdtm8zxbs9jcunVL/vnnH9192bnlQ/HixWXr1q2agX9TW716tc3WSLYSJL169XK6JcK4ceOkefPmVtttdQ9KTEy0W6atRJurW4blzZtXM3bLxYsXbXbNy2oJCQkybNgwKVeunEyfPj3NsZA8PT2levXqMmDAAFmzZo1ERUXJTz/9ZPO1kl0tWrRI83qxN4hyr169zP/ftm2bpmthRp05c0azXqZMGZeVDQDIuUjsAADcZt26dbozLJlMJmndurWsWLFCrl+/LseOHZN58+ZJz549s03rlbSSN3qzP4mIxMTE6M60ZO+87DrGTq1atWTfvn1SvXp13f3btm2TTp06iVJKd7+fn5/u9nz58omIyKlTp6Rbt27y6KOPSt68eaVixYoyatQoefDggdU5JpNJPv30U/Hw8LDant2VLFlSU097gzpnB5cvX5YhQ4ZI0aJFJTQ0VGbMmCH79+/XHWw8Rd68eeWVV16RP/74Q/bv32+YbkQ3btyQX3/91bzevn17m8nWsmXLahJXrmytI2KdDLfVnREAgNRI7AAA3CYqKsrmjFUpTCaTVK5cWXr27Cnz5s2T06dPy7lz52TWrFlOzzDlSmn9Cn/z5k3d7WfOnLGZ5EjrvOyYnGjXrp1s27ZNSpQoobs/PDxcwsLCNNNFW0pr2vR///1XatWqJYsXL5ZTp05JfHy8nDx5UsaNGydhYWG6CYTKlStLkyZNNNtsdblypNWNrYSaq7v8WQ4gbWtsn+woKSlJNm/eLIMHD5aaNWtKgQIF5IUXXpARI0bI2rVrbbboqVGjhmzfvl06duyYyTVOn9Tdsfz8/Gx2E+zRo4f5/RoTEyMrVqxwaT1iYmI069m5NR8AIPsgsQMAcKvx48fLzJkznTqndOnS0q9fP/nzzz/l119/1R2w190sv2Cldv/+fd3t9gbstXVedjNs2DBZvny55M2bV3f/9OnTpWXLlrota1JL6zH84IMPbCYFtm3bJosXL9bd17hxY826rSRJRhI7rk68pLRQSmHvccvOHjx4IFu2bJGJEydKixYtpHDhwlKrVi0ZM2aMVUskb29vWbBggc0WX9nJhg0bNPXXG0TZZDJJ9+7dzes//PCDy9/TluVZvnYAANBDYgcA4FbJyckyYMAACQsLk4iICKfPb9mypUREREiFChXcUDvb0jMGSlqtdYzA09NT5s2bJxMnTtRtRXT//n3p1KmTDBkyxKFZgNJKkGzYsCHNc9esWaO7/emnn9as22oFVbBgQTu1sz371Y0bN+ye6wzLBFJaLZmMJjk5Wfbt2yejR4+WChUqyIgRIzTvnTx58tgcgyk7SU5OlgULFpjX69atK1WrVtUc06hRIylbtqx5fd68eW6pR+rWatm1myYAIHshsQMAyBTr16+X2rVryxNPPCHvv/++bNy40eGWCyVLlpTly5dnyy5LOYWXl5csW7ZMevbsqbv/33//lTp16sj333/vcJnnz5/X3R4fH29zRqoUtgbeLlKkiGb96tWrul2nChUqZPf1knpAY0eunV6WiZyc+mU9MTFRJk6cKEOHDtVsb9y4sUOJtqw2b948TXLWchDl1IMmHzt2THbt2uXyOnh4eIiXl5d5PSclAQEA7kNiBwCQqQ4fPixTp06VJk2aSIECBaRWrVoyYMAAWbJkic3BhUVEnnnmGWnUqFEm1jT38PDwkCVLlkjbtm11969evVpq1aplc1YvW86ePavbPS1Pnjx2xw7x9PTU3W45C1ZycrKcOnXK6jgvLy+7A3FXqVJFd/vRo0fTPM9ZlgnMnN69ZubMmXLr1i3zuoeHhzzxxBNZWCPHnD17Vn7//XfzeteuXc2vtwIFCsgrr7xi3ufqQZNTWA44buRuewCAzENiBwCQZZKSkmTfvn0yc+ZM6dKli5QqVUpeeuklOX78uO7xoaGhmVzD3GHatGnSvn173X2ffvqptGrVKt3jzhw6dEh3u70Zk2wlZVInDFLY6uKX1tgu3t7e8uSTT1ptj4+Pl4MHD6ZZN2cZYUBcHx8fqVmzpvTt2zfD070nJSXJv//+q9lWoECBDJWZWb799lvz/wsXLmwerLtt27bi6+srIv/d36JFi9xyfcvXRlrjVAEAkILEDgAg21BKyaZNm6Rx48a6Y9yULFnSqfIsp8aGta5du8rAgQN1940cOVLefffdDI0dFB4erru9T58+aZ7XsmVL3e2nT5+22rZ582bdY1u3bm2z/MaNG4u/v7/V9m3btrm8+8vFixc1j2Hp0qVdWn5GbdiwQe7duycREREye/ZseemllzJcpmWCwtXjFrnLzz//LFFRUeb1lNdQ6tm9wsPD5erVq265fpkyZTTrlgNSAwCgh4gXAOAWxYsXl44dO8r//vc/WbJkiURERMi1a9ckMDDQ7rkXLlzQHRTX2W4JtsZQwX8effRR+eqrr3T3ffPNN3anqnfEkiVLdJN07dq1s9n1KyQkxOY02Vu3brXatmbNGt1kTPv27XW7W3l6esro0aN1y//hhx90t2dEXFycXL9+3bxeqlSpbJV0vHjxoqaL2/DhwzM0nlXx4sWlcuXK5vWHDx9ateDJruLj42XJkiXm9aZNm0pQUJA0bNjQvM0dgyanSD04s4jrx3sCAORM2SeqAADkKKVKlZLvv/9ePv74Y+nUqZPUrFlTihYtavMLdWpPP/201SC5IrbHPomLi9Pd/vzzzztX6VxmxowZuq1Wrly5YjUAbnpdvHhRVq9erbtv6dKlMm7cOClfvrx4e3tLqVKlZOjQobJ27VrdMXbi4uLk119/tdoeFRWlm5Dx8fGRTZs2SZs2bSQoKEh8fX2ldu3asnbtWqldu7bV8bdv33ZqcGhnpE5seHt7S/ny5d1ynfSYOXOmJvlWv359GTNmTLrLmzJliiZR9Pvvv+t2ocuuUnfHKlmypAwYMMA8oPH169dl7dq1brt26oSYiBgmIQYAyFokdgAAbhERESF//fWX1fZBgwbJsmXL5OWXX5bixYtLvnz5xMvLS4KCgqR69ermGbMsWwwkJibabE1x7do13e01a9aUiRMnSokSJSRv3rxStWrVHDsjkbNCQkKkefPmuvuKFy8uMTExopRyarE1RfmgQYN0W1t5e3vLhx9+KKdOnZKEhAS5cOGCfPLJJ7rJJpH/vnCnbvmS2tixYyUxMdFqe6lSpWTlypUSFRUlDx48kD///NM8boqlCRMmyP3793X3ZdTevXs16/bGGMpMf/31l8ydO1ezbeTIkTJ//nzdBKsthQoVkiVLlkiXLl3M25KTk+V///ufy+qaGSIjI2Xfvn3m9SFDhpj/v3jxYt3XmatYvi7+/PNPt10LAJBzkNgBALjNgAED5OHDh1bbO3ToIKtWrZLLly/L/fv3JTExUaKiouTAgQMyefJk3S+TY8eOlStXruheZ8+ePTbrMGzYMLl06ZLExsbKP//849QX1Zysfv36mXats2fPyqBBgzJUxvHjx2XEiBE29584cSJDCYRdu3bJjBkz0n2+PZav0bp167rtWukxYMAA2bFjh2Zbjx495MyZM/Ldd99J586d5YknnpCCBQuKt7e3eHt7S1BQkDz55JPSqVMnWbBggZw/f146deqkKWPUqFFpvj+zq9SJrtQDP7uzG5bJZNK0JIuNjZXIyEi3XQ8AkHOQ2AEAuM3OnTule/fuGf6F+6uvvpIJEybY3P/333/Lrl27MnQNuNecOXNkwIAB6Tr3+PHj0qJFC7szBE2aNEmmTZvmdPl79+6V5s2bS1JSUrrq54jff/9dU76tVkOOaNKkidOtqVIvKd2KUouPj5cmTZrId999p9nu5+cnnTt3lu+++04iIyPl1q1bkpCQIAkJCRIVFSWHDh2SJUuWSPfu3TXTuD948EDefPPNNN+32dnSpUutWpn9+eefcuTIEbdds1atWlKwYEHz+ubNm936mgQA5BwkdgAAbrVkyRKpV69eun61P378uLz66qvSv39/3ZY/qXXv3l0uXbqU3moiE8ycOVNCQkJsToFuKSEhQWbNmiW1a9eWkydPOnTO0KFDpV+/frqDb1tKSkqSmTNnSuPGjSU6Otqh8tMrKipKtmzZYl6vWLGiVKtWza3XdNaDBw+ka9eu8tJLL1m13nFUTEyMfPvtt1KpUiWZPXu2i2uYee7evSsrV67UbHNnax0RkVdffVWzbnl9AABssf7JBgAAF9u/f7/Uq1dPnnnmGWnevLnUrVtXypUrJ8HBweLn5yeenp4SExMj0dHRcuzYMfnrr7/k119/dSoZdPLkSalevbq8++670rJlSylXrpyYTCa5c+eOREVFSWRkpOzatcuhL/xwn+3bt8szzzwjL7zwgrz88svSoEEDKVasmBQuXFhiY2Pl1q1bcvToUdm8ebOsWLFCLl686PQ1vv76a1m+fLm0a9dOwsLC5Mknn5SiRYuKt7e33LhxQ06fPi0bN26UFStWyIkTJ9xwl/qWL18uoaGh5vX27ds7NJh4Ztu0aZNs2rRJSpcuLS1atJBatWpJlSpV5JFHHpGAgADx8/OTxMREiYmJkbt378qpU6fk0KFDsmfPHgkPD5fY2NisvgWXmDt3rnTr1k1E/usWtWzZMrddy2QySZs2bczrcXFxsmrVKrddDwCQs5iUUiqrK+Eqr7/+utt/TQEAAEiPfPnyyfnz56VQoUIi8t/sY2XKlHHrYLwwhqZNm0p4eLh5fc6cOdKnT58srBEA5Gzh4eHStGnTrK6Gq6ygKxYAAEAmePDggaZ7UvHixaV9+/ZZWCNkF5bjT7lzIG8AQM5DYgcAACCTTJ8+XTOez8iRI3UHM0buUatWLQkLCzOvL1++3K2DNAMAch4SOwAAAJnk1q1bMmbMGPN6lSpV5I033sjCGiGrffLJJ2IymUTkv7F13n///SyuEQDAaEjsAACQTQwaNChD01g7sjg6uxTcZ+bMmXL48GHz+scff2wedwe5S/v27SUkJMS8PmHCBDl//nwW1ggAYEQkdgAAADJRYmKidO7cWeLj40VEpEiRIoaeGhzpExwcLF9++aV5fc+ePTJhwoQsrBEAwKhI7AAAAGSyyMhI+eCDD8zrbdu2lS5dumRhjZCZTCaTzJ07VwoXLiwiIjExMdKlSxd5+PBhFtcMAGBEJHYAAMgmZsyYISaTya3Lo48+mtW3if/vs88+k/nz55vXv/76a6levXoW1giZ5X//+580b95cREQePnwoHTp0kFOnTmVxrQAARkViBwAAIIv07dtXtmzZIiIi+fLlk1WrVklwcHDWVgpu1aZNGxk9erR5fdCgQRIeHp6FNQIAGB3zawIAAGSRxMREeeGFF7K6GshEP/74o3h48NsqAMB1+KsCAAAAAABgUCR2AAAAAPw/9u48vIlqfeD4m5a2QFm6WArKJqssKsoiuyhlV0EpWETZ18uOIAh6RZarLBdQQVCUsokiqChIQVBUKFsFAQVFNmWnFChdaCml5/cHv+Y2nUmTtEmTab+f55nnaSZnzpzJJDlv38ycAwAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYVBF3N8Adtm3bJmXLlnV3MwAAgAcaO3asfPfdd1afb9u2rcydOzcfWwQAABxlqz8vSAplYqdGjRpSoUIFdzcDAAB4oFKlStl8vk6dOvnUGgAAkBu2+vOChFuxAAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHcNDGjRvFZDKZl7///tvdTYID2rRpY3H+TCaT9O3b193NAgqFnj17aj5/HTt2dHezgEKFOMa4iGHgCejLPROJHTdYvHixxQdh586d7m4SUCh89NFHsm3bNot1ZcuWlblz55qfz95RZS5ff/213fuZM2eOZvuJEyc69VjguF27dsmoUaOkXr16EhoaKj4+PhIYGCj169eXESNGSExMjEP1Xbx4Uf7zn/9IWFiYVKhQQYoVKyYlS5aUqlWrSkREhKxcuVLS09NddDT2c/Zx63n//fd1Pzdly5a1KPfOO+9ISEiIxbqoqChZvnx5ntuAu65duyZr166VIUOGSKNGjaRKlSpSqlQpKVq0qNx3331Sr149CQ8Pl0WLFsmJEyfc3VwAdiKGKbx+/vlnGTFihDRs2FBCQkLEx8dHSpUqJZUqVZIOHTrI9OnTHU7Q/vjjjzJy5Eh59NFHJTQ0VHx9faVkyZJSsWJF6dixo/znP/+Rs2fP6m5LX+6hVAHSr18/JSI2lzNnzri1nYsWLbJoz44dO9zaHk90+/ZtVaxYMSUiatGiRe5ujoUNGzZYnL/Tp0+7u0mww9WrV1VgYKDm+2D16tXmMkuWLLH6vVG9enWVlpZm175mz56t2X7ChAmuOjTYcO7cOfXUU0/Z1T/07t1bpaam2qzz7bffVsWLF7dZX82aNdW+ffvy4Si1XHHcek6fPq1KlCihW29oaKim/LJlyzTlgoOD1fXr1/N6yE4THh6e4+sVHh7u7iZqnDt3Tg0bNkz5+fnZdc4zl3bt2qndu3e7u/ke3e/nhicfD3GM8RDDFE4HDhxQDRo0sOu73MvLS/Xt21fFx8fnWOfx48dV06ZN7a5zyJAhKjExUVOPEfpypXLuz6OiotzdPGf6nCt24JGOHDkiKSkp7m4GCpApU6bI9evXLdY1atRIIiIi7Nr++PHjsmDBAlc0DS506tQpadCggWzcuNGu8suXL5dnn31WlFJWy4wfP14mTpwoN2/etFnfsWPHJCwsTPbu3Wt3m53BFcetRykl/fr1k6SkJLu3eemll6RevXoW665evSrTpk1zaN/4nxUrVki1atVk4cKFcuvWLYe23bJlizRp0kSGDBkit2/fdlELbSto/X5BOx64FzFM4RMVFSXNmjWTX375xa7yGRkZEhkZKU2bNpW4uDjdMgcOHJAGDRrIrl277K5z8eLF0rp1a00/T1/ueUjswCPZ+yUG2OPMmTOyePFizfqZM2eKyWSyu55p06bJtWvXnNk0uFBCQoK0adNGLl265NB2UVFRVgPgNWvWyJw5cxxuR3h4uCQkJDi0XW654ritWbRokWzfvt2hbby8vOQ///mPZv2CBQvkwoULDtUFkYkTJ0rv3r0lNTXVvC44OFiGDh0q33zzjZw4cUJu3LghqampcubMGdmxY4e8/vrrUrNmTYt6PvjgAwkLC8u392l2Ba3fL2jHA/chhil8Tpw4Id26dctVcvjo0aMycOBAzfqEhAR5+umn5caNGw7XuW/fPhk9erTFOvpyz0NiBx6JgAjONHfuXM0v0Y0aNZJWrVo5VM/169dlypQpzmsYXGr69Oly6tQpi3VeXl4yefJk+eeffyQxMVE2bdokVatW1Ww7Y8YMzZUP6enpMmHCBE3Zhx56SLZv3y5JSUkSFxcnixcvlmLFilmUOXfunMybN88JR2Wbs4/bmtOnT1u8Ho78g9GhQwd5+OGHLdalpaXJ/Pnz7a4DIkuWLJGZM2eaH5tMJhk3bpycPHlS3n//fXn66aelatWqUqpUKfHz85MKFSpI8+bNZerUqXLkyBH56KOPpFSpUubtf/75Z+nXr587DqXA9fsF7XjgPsQwhc/IkSMlOTlZs3748OFy/PhxSU1NlePHj8tbb70lxYsX15Rbv369HD161GLd7NmzdRMujz/+uOzatUsSEhLk7Nmz8vHHH8s999yjKRcZGSmnT5+2WEdf7llI7MAj7d+/391NQAGRlJQkH3/8sWb92LFjc1XfokWL5NixY3ltFlzs3Llz8u6772rWL1q0SKZPny4VK1aUEiVKSIcOHSQqKkqKFi1qUe7y5cuyZcsWi3UbNmyQf/75x2JdqVKl5LvvvpNWrVqJv7+/BAcHy+DBg+W///2vZt+LFy92+WDKrjhuPUop6d+/v8Wl2Z07d3aorXqfwQ8//JDbV+x09OhRGTFihPlxkSJFZMWKFTJ79mwpXbq0ze29vb2lf//+8vPPP1sMcv3FF1/IwoULXdLmnBS0fr+gHQ/cgxim8Dlx4oRs3rxZs37o0KHy3nvvSbVq1cTPz0+qVasmEydO1O3zRcSiL8/IyNB9H9WtW1e2bdsmTZo0kZIlS0r58uWlX79+8sknn2jKZmRkyDfffKNZT1/uOUjseLDIyEjzaPQ1atQwr1dKyfr166Vdu3ZSpkwZ8fHxkYCAAHnwwVZyYUUAACAASURBVAdl5MiRcvz4cat1zp4921xnlSpVzOvj4uLk3//+tzRq1Ejuvfde8fPzk3vvvVeaN28u8+bNs3rZ3ttvv22ur0iRInYd1/z583W3yTpbWNZZWoYOHWoxMn9efgVLS0uTzz//XHr27CkPPvigBAUFiY+PjxQrVkzKlSsnzZs3lwkTJsivv/5qd52Zv1Knp6fLxx9/LO3atZMqVapI0aJFJTAwUOrWrSujRo2SkydP2lXfnTt35Ntvv5X+/ftLvXr1JDg4WHx9fcXf31/Kly8v7du3l1mzZklsbKzVOpx9nvVcuHBBZsyYIW3atJHy5ctLsWLFpFSpUlKtWjXp1KmTfPDBB5r7wfVkfT+YTCbdziwvvvjiC819wQEBAdKlSxe7tm/atKnF4/T0dBk3bpzT2pdVdHS0TJo0SZo0aSKVKlWS4sWLS4kSJaRy5crSpEkTmTRpkl2z6H388ceaGS3atWtnfl4pJWvWrJFOnTqZZ0kKCQmRxo0by9tvvy2JiYl2tzkhIUEWLVok3bp1M18ZULRoUalcubI88cQT8u677+b4XnWVNWvWaK48adKkiQwaNEhTtnr16vLss89K1apVpV27djJ8+HCZP3++5oqWdevWabbt2bOnhIaGatb37dtX/P39LdZdunRJduzYkZvDsZsrjlvP+++/b3ELVlBQkMOfi/DwcClRooTFuhs3bugGjtCaNm2axbn+97//LS+++KLD9Tz88MPy2WefiZfX/0LCadOmWdzalZU7+31X9G3EMc6NY5wRw4gQx2Qihil8MczWrVs14915e3vr3vYkItKnTx/x8/PTrM86o9XBgwfl4sWLmjKTJ0/W/d5r27atVKhQQbP+999/16yjL/cg7hu42fkK2qxYn3zyiblM2bJllVJKXb9+3eZI5r6+vuqTTz7RrfP999+3GLlcKaV2796typQpk2OdFSpUUNHR0Zr63nrrLXMZb29vu45/3rx5uttkf12sLTExMXbtJ7s9e/aoatWq2T1TSHh4uO7I8tlnkzh79qy6ePGizVHrfX19LWYv0PPbb7+pevXq2dU+f39/tWTJEt16nH2es7p9+7Z65ZVXlK+vr802BgcHq8jIyBzry/p+EBeMUN+uXTtNuwYOHKhbVm9GiXfeeUdVrFhRs37btm1W9+nojBJ79+5VLVq0sPu92axZsxxnsfn000812zz22GNKqbsza7Rq1SrH+u+77z516NChHF/XjIwMNWfOHFWyZEmb7S1VqpTV96qrPPbYY5p2rFixIk91li1bVlPnF198YbV827ZtNeVfe+21PLXBFlccd3anTp1S/v7+FvuIjIxUBw4c0Oxbb1asrF566SXNNp07d3Zqe3PD02fFOnXqlPL29ja3p3bt2io9PT1PdQ4dOtTiGK3N5OTOft8VfRtxjPPiGGfFMEoRx2Qihrm7FKYYZvny5eqZZ55RzZo1Uw888IAKCQlRDRo0yHGbqlWrato9fvx48/Pbt29XTzzxhHr00UdVtWrVVEhIiPLz81OXLl2yWqfeOX3uued0y3pqX64Us2LBQ/j6+pr/vnnzpqSlpUlYWJjNkczT0tKkX79+8scff2iey5qVTUpKknPnzknHjh1tZqPPnj0rTz31lPz1118OHoVn+OuvvyQsLExOnDhh9zbr1q2TLl262JwlxmQySfv27W3+ApeWlia9evXS3POa6fjx49KyZUs5ePCgXe1LTk6WgQMHyrJlyzTPueo8p6eny1NPPSWzZs2StLQ0m228evWq9O3bV95++22bZV0hNTVVfvrpJ836jh072l1HYmKizJgxQ7N+7NixkpGRkaf2iYisXLlSWrRo4dCVHNHR0dKyZUtZsWKF7vN6v9wkJCSYz9+PP/6YY/3nz5+XNm3ayNWrV3Wfz8jIkO7du8u4cePs+mUsISFBBg4cKG+++abNss6QkpJi8Wt5prCwsFzXefHiRd3BiGvXrm11m1q1amnWuXLcDVccd3bq/2fBynrvf6dOnaRPnz5y584dh+vT+yx+//33bp2dyQi+/PJLi9d75MiR4u3tnac6R48ebTFO0po1a/JUnysU1hhGxPPjGGfGMCLEMSLEMFkVphimV69e8vXXX8vOnTvljz/+kNjYWN2+PVNqaqpufJJ17JtWrVrJDz/8IPv375fjx49LbGyspKam6l5xnOnKlSuadUFBQbpl6cs9A4kdD+bj42P+OzU1VWbOnCn79++XWrVqySeffCIXL16U27dvS1xcnGzcuFEeeughc/lbt27JO++8o6kza+B369YteeWVV+T69evStGlTWb9+vVy6dEnS0tLk0qVL8umnn0q1atXM5a9fvy6jRo1y0dGKDBkyRJRSmnsyFy1aJEop89KgQQOH6548ebL5UlZfX1959dVXJSYmRq5fvy7p6emSmJgoJ06ckNWrV1tctvrjjz/K2rVrc6x79uzZcujQIalZs6YsX75cLly4IGlpaXLlyhX58ssvpU6dOuay6enpVmfUGTZsmMUlv506dZINGzbI+fPn5datW5KcnCwHDhyQUaNGWVwyP3bsWM2lx646z6+++qrFPbvVq1eXDz/8UI4ePSrJycmSlJQkhw8flrfeekuCg4Mttvv+++9zfB1dITo6WnM7gbe3tzzxxBN213H9+nXp2bOn5n13+PBh3fuVHbFp0ybp3bu3XcFldrdv35Y+ffrI1q1bNc9lTQpnSkhIkNmzZ8vu3bvtqj82NlamTp2q+9z48eN1b0uyZcqUKfLVV185vJ2j/vjjD03AWqZMGSlXrlyu67R2C0L58uWtbqP3XE63yuaVK447u4ULF1oE1UFBQbJkyZJc1xcWFqYZdDkpKUn27NmT6zoLg6znwGQyyfPPP5/nOmvUqGHxPbdnzx6Hp053lKP9vifHMLk5Hkd4ehzjzBhGhDhGhBgmq8IUwzhq7ty5moGWAwMD5Zlnnsl1nb/++qv8+eefmvXVq1fXLU9f7iHccJmQyxS0W7GyXiprMplU0aJFVdu2bdXNmzd1y8fFxamgoCDzNpUqVdKUiYyM1LweXbp0Ubdv39atMz4+XtWoUcOi/OHDh83PO/MS5kwpKSkW+7N2Obi9MjIyVPHixc31zZkzx+Y2L774ogoNDVUNGjRQc+fOtXgu+yXMfn5+KiwsTCUnJ+vWdfXqVXXPPfdYXCKa3cmTJzXnJCdvv/22Rfnsl0Y7+zwrdffS/yJFipif79Chg9X3olJKnTt3TlWuXNlcvm7dujkekytkfX9mLnXq1LFaXu8y5mHDhimllPrpp580z4WGhqqEhARNPfZcxnzt2jWL90XWpWfPnmr37t0qMTFRJSUlqV27dlm9lLRcuXKa996mTZs05YoXL65Kly6tvLy81JgxY9SJEydUamqqOnjwoHr66ad16w4ODta8Z37//Xfl5eWlKfvII4+oTZs2qYsXL6r4+HgVHR2tOnTooClXpUoVdevWrdyeUrusXLlSs99GjRoppZRKTU1VS5YsUWFhYeq+++5Tvr6+KiQkRDVr1kxNnz5dxcXF6db5+eefa+r09fXNsR3Lli3TbFOsWDGnH28mVxx3Vnq3YGX97omJidH9jNiidwn5vHnzcv9COIGn34oVHBxsbkvt2rWdVu+YMWMsjtPVt2Bnsrffd0XfRhyT9zjG2TGMUsQxShHDFNYYxpY7d+6o2NhYtW3bNhUREaFpo5eXl1q3bl2u609LS1ONGjXSfU1PnDhhdTtP7MuV4lYseCCllBQtWlQ++eQTzTS6mYKDg6V79+7mx//8849mwLXsSpQoIR999JHVAQNLly4ts2bNsli3ceNGB1vvXvHx8XLz5k3z4+zT8ulZuXKlXLp0SWJiYmTMmDE5li1evLh8+umnutMNitz9RTsiIsL8+Pz585rzcv78eWnRooXUqFFDSpUqJcOHD89xnyNGjLC4osvW7BvOOM/z5s0zz+gTEhIiq1evtvpeFBG57777ZPHixebHv//+e75P/3ro0CHNOnvOf1aZx9yyZUvNrD+XL1+Wt956K1dtW7x4scTFxWnWv/nmm7Jq1Spp3LixlChRQvz9/aVJkyaydu1a3ffFxYsXZfXq1Rbr9Kadvnnzpty4cUPeeecdmTt3rlStWlX8/Pzk4Ycflq+++kozwKLI3UvQs/9iM2PGDM1VIZUrV5Yff/xROnToIGXLlpXSpUtL06ZNZdOmTdKpUyeLsqdOnXL5L156lyQHBgbKkSNHpH79+jJw4EDZtm2bnD9/3vyrdHR0tLz22mty//33y6pVqzTbX7t2TbMu+2CB9jyfkpJidVDavHLFcWdSOrdgde3aVXr06JHndme92jST3mcXd6Wnp1vcYqB3y19u1a1b1+Kx3mCbnqQwxDAinh/HuDqGESmccQwxzP8UphjGmj179ojJZBJvb28pU6aMhIWFyWeffWZR5t5775VvvvlGunbtmqt9ZGRkSN++fWXfvn2a5zInW7CGvtz9SOwYSJ8+feSee+7JsUy9evUsHtsazb9bt24Wl5rq6dSpk8U/KNHR0TZa6llKlSplcUnvt99+69T6+/XrZ/O8PPjggxaPs/+T2KJFC/n555/l2LFjcuPGDWndunWO9RUvXtxitHq9zjUrZ5znqKgo8989e/aUgICAHOsTEWnXrp1FOzds2GBzG2fSG4ugZs2aua5v1qxZFsGoyN1AMfsU2PbQu33lgQcekNdee83qNjNnztS9v3nlypV27bNBgwa6gZW3t7fVWTKy3jp0584di/dBptGjR0upUqWstjm73FwC7Qi9hHZiYqJ06NBBjhw5kuO2iYmJ8tJLL8lHH31ksV4vGZP9vWDv866aAtQVx50p+y1YISEhsmjRojy1N5PeZ9LeWQQLo+zjRlgb8yA3stdlbYwKT1EYYhgRz49jXB3DiBTOOIYYxlJhiWEc5e3tLV26dJHIyEg5ceKEJhllr9u3b0uvXr10pzovUaKE1aEkMtGXux+JHQOx1VGKiKZjzvoLjx577tMtUqSIPPLII+bHrhwjwhW8vb2lVatW5sfz58+XESNGyPnz551Svz0Dk2Y/L874xy7rr0yZv8hYk9fzfPHiRYsAI2s5Wxo3bmz++/Dhw3Zv5wwXLlzQrMvLeCM1atSQIUOGWKxLTU2ViRMnOlTPmTNn5PTp05r1L7zwgsXYA9kVL15cnnrqKc36mJgYm+8BkbvJYWv0fu0SuftLcaZff/3V4nGmRo0aWa23du3aEhgYaLEu6zTZrqA3GOKuXbsspv60Zfjw4XLq1CnzY72BgW0NVmstseOqwQRdcdwid3+hzP4eX7x4sYSEhOSuodncd999mnXnzp1zSt0FUfYEnrWrLHIj+1Vmtq76dbfCEMOIFMw4xpEYRqRwxjHEMJYKSwzjqDt37siWLVvk448/lqVLl+bqquDr169Lx44ddZM6JpNJIiMjpUqVKjnWQV/ufiR2DKRy5co2y2QfSV7ZmAkh+y8w1lSqVMn8tyP/JHiK2bNnWwQRCxYskIoVK0qzZs3k9ddfl++//z7Xt0dUrFjRZpnsA8HldF4uX74sS5culX79+knz5s2levXqEhoaKoGBgVKiRAkpWrSoFClSxOYv8Fnl9TyfOXPGolzv3r3FZDLZtWQdtDG/ZyTRG9G/bNmyearzjTfekNKlS1us++yzzxwaIM7aZef2DKipF4ympKTYNVNK1uA0u3vuuUc3IMs6eKpeICdyN6Cydv69vLw0Vw5evXpVLl++bLO9uZXTTB8tWrSQbdu2ydWrVyUxMVGioqI0VzqK3D3u2bNnmx/rXf5vaxYoawkcW1f65JYrjlvvFqyePXvKc88957R26/2j4sr3h9Flv8pAb+DZ3MpeV/Z/aDxNYYlhRIwTx7gihhEpnHEMMYylwhLD5EZKSors3LlThg8fLrVq1ZIDBw7Yve2JEyekcePGsm3bNt3n33nnHQkPD7dZD325+5HYMRBb4znkhr2XcGftBFJSUpwyRWJ+euSRR2Tr1q1y//33m9dlZGTIrl27ZPr06RIWFiaBgYHSvn17+eijjxwKlJ31a+mtW7dkzJgxUqlSJenfv79ERkZKdHS0nDhxQmJjYyU+Pl6Sk5Pl1q1bDk8rnNfzrDe+SG7o/VLiKrdv39b9xzqv5ys4OFgmT56sWZ91DAO9+8Oz0gvWRO7eG22LtaDOnnOUU0Do7e2tCfZysw97OTJlr6NKliypu75p06aybds2ad26tQQFBUmJEiWkffv2smPHDt3XPut99HrvG1tX3lh73plXWGTliuNesGCBxXS75cqVk/fee8+p7dZ7PVx1u1pBEBgYaPEdY89tLPbK/hm3deuLuxWWGEbE8+MYV8YwIoUvjiGGsX9bkYIVw1jTuHFjUUpJRkaGXL16VX799VeZPn26JgH/999/y5NPPmnXbVDR0dHSpEkT3YRlkSJF5IMPPpARI0bY1T76cvcjsVPI+fv721Uu+y81uZna0N2aNWsmx48fl1WrVsljjz2m6bhSU1Nly5YtMnDgQKlcubK89dZb+Rb83bp1S5588kmZP3++S6aXzet5zj6NYm7l52X91l7HokWL5rnukSNHaq6g27Nnj3z66acion91R1Z6t8yISI6DONoqY63OrLJf0ZddTpdQizj3/CUkJDitruys3Ss/ZcoU3WlUS5QooXsp+uXLl82Bkd4/uLZeD71z4u/vb/M85Jazj/vUqVPy6quvWjy3ZMkSp1/FofeeVkq5fKpto/Ly8rIY8+PXX391Wt3ZB7rMevWDJypMMYyI58Yxro5hRApfHEMMo1VYYhhbTCaTBAUFSb169WTy5Mnyyy+/aG6NvnHjhowfPz7Hej7//HNp3bq17o8DgYGBsnHjRhk0aJDd7aIvdz8SO4WcvR+2rJf3mkwml/1j4mre3t7Ss2dP2bNnj1y8eFEiIyMlIiJC84UYHx8vkyZNkueeey5Xvyw56vXXX5ddu3aZH/v4+Ejv3r3ls88+k19++UVOnTol165dk8TERElJSZH09HSpU6eO3fXn9TxnvxJgy5YtopRyeHHmLQO5Zev2RHv4+fnpziQxceJESU1NtRl4WfsH3J7A01oZW79UOYO1K0Jyw54gLrf07vMWyXlMBWuXkGdeRqxXZ1paWo6Bot6vmvbc8pBbzj7u7777TvN+e+qpp6xest6wYUPderKWmT59uqaMMz6ThU2zZs3Mf58/f17+/vtvp9Sb9XaMoKAgu29/cZfCFsOIeGYc4+oYRoQ4JhMxTO4ZJYZxVJUqVXSTOBs2bLCagFqxYoX06NFD93NVt25diYmJkXbt2jnUDvpy9yOxU8jZ20FlvfS0ZMmSNi/TzIk7s9xZhYaGSp8+feTTTz+Vy5cvy/79+2XixIkW4xd8/fXXTpv5xZrU1FSL2QUCAwNl7969smzZMnn++eelfv36cv/991vcn+7t7e1QoJbX85x9TAdPnylFxPqvQs6aajoiIkIee+wxi3VnzpyRuXPn2pxpw9qgs/YMMmdtsExnDWSbE2tXahw4cMDh4Lh79+4ua6e16WBz+uXaWlIk89femjVr6n7vZR+3wdZzDzzwgNXyeeWK484Pep9Jo//z7WotW7a0eBwZGZnnOo8dO2Yxdsbjjz9u8xdwe7mq33dHDCNCHJNVfsQwIoUvjiGGcT6jxDC5offDSnp6uu5YVp9//rn07dtXNzbo0qWL7N69O8dpza2hL3c/EjuF3J9//mlXuay/Bma9NDtrcHTnzh27Ompn/bLoTCaTSR599FF566235MiRI1K9enXzc7NmzXLpvn/77TeLQGTSpEk2Z2tIS0tzaADIvJ7n7P/U/v7773bv2128vb11B6m1NVOcI/773/9q1r399ts2PwePPvqo7vp9+/bZ3KdemcDAQJuzFThDrVq1dNd72mCkNWvW1L3X+9ixY1a3yT44YqbMW7BKly4tNWrU0Dz/22+/Wa1Tb/aU7IG0M7niuPOD3mfSVeMQFRTdunWzeI0WL16c52RD9rGTevfurVvOk/r9vPZtIp51PHnhrjgmP2IYkcIXxxDDOJ8RYpjU1FQZNmyYdOvWTR5//HGpVauWBAcH6067npW1JHz2H2l27twpvXr10k3q/Otf/5Ivvvgi12O60pe7H4mdQm7Hjh02y6SlpcnBgwfNj2vWrGn+O/svCrZ+AcnIyJAffvjBwVbmr3vvvddiYLmzZ8+69JLLixcvWjzOadT/TN98841D94vn9TwHBARYBIkbN260e9/uVKZMGc262NhYp9XfrFkz6dq1q8W6xMREWbhwYY7bVaxYUXeWu9WrV+c45ee1a9dk06ZNmvUtW7bM8y/Q9qhTp47uL3n2vL/yk7e3t+6Uqjld1aB3DD4+Pha/Wj399NOaMlu3btWtLz4+Xnbv3q1Z36VLF6ttyCtXHberZf8OFMn7zC8FXXBwsMXUv7GxsTJ69Ohc17dnzx6Lqzrq1KkjzzzzjG5ZT+r389q3iXjW8ThLfsYx+RHDiBTOOIYYxrmMEMMULVpUvvzyS1m3bp38/PPP8ueff8q1a9fk22+/zXG77OOjZQoNDTX/ffXqVXn++ed1b7+aNm2aLFy4ME9XadKXux+JnUJu9erVNgcT++qrryxGNW/VqpX57+yzFGTtUPV88cUX8s8//zjUxrzeG75w4UIJDw+XypUry+rVq+3aJvuUfc66HF1P9rptBV/x8fGaAU9tXZqb1/MsIhZB/uHDhyUqKirH+kTu3hNfr1496datmyxbtixfZ8US0Z+h4cKFC07dx8yZMzWDNWYda8AavQHpTp06JdOmTdMtn5GRIf/61790fxEZPHiwna3NG5PJpJuYWLx4sdUZIjZt2iQlSpSQKlWqSOPGjeWZZ56xmH1DRGTz5s26Y7bs3Lkz12198cUXNetWrlypexVNYmKizJ07V7O+cePGFr82vfDCC5oya9askUuXLmnWv/vuu5oZTRo0aGDxj4anH/eQIUMcujQ9JiZGU1doaKhFmddee01TRu8zae0WMfzPq6++atEHR0ZGytSpUx2u5+jRo9K1a1fzL7gmk0lmzpxp9R8tT+r3ndG3edLxWOPJcUx+xDAihTOOIYZxLqPEMJ06ddKs27Fjh6xcuVK3fHJysixYsECzPigoyCKZOWzYMN33z+DBg3X7ZkfRl7sfiZ1CLjY2VkaMGGF1wKu4uDiZMGGC+XH2X4Rr165tUX7x4sVW93X06FEZNmyYzUHZvL29LR7n9RLJPXv2mAOxyZMny6lTp2xus3btWvPf5cuXt3s2htzIOnWpiMi6deuslr1w4YK0b99erl27Jo0aNTKvt3VZeF7Ps8jdL/6sAVy/fv1yvMUjLS1N+vfvL4cOHZJ169bJoEGD8n3QwawdWqac2pwbVatWlWHDhjm83dChQ+Wee+7RrJ86daoMGDBADh06JLdu3ZL4+HjZunWrtGnTRtasWaMp36BBA2nfvn2u2p4bY8eO1fzDl5SUJM2bN5elS5fK5cuX5fbt23L27FlZsGCBRERESHJyspw+fVr27t0rGzZsyJf7rTt16qS55zw9PV3CwsJkxYoVEh8fLykpKbJ9+3Zp1aqVnD59WlPHkCFDLB4/8sgj0qJFC4t1SUlJ0qFDB9m5c6ekpKTI5cuXZdasWbr/YI8dO9YJR5YzVxy3q+l9JqtVq5avbTCi8uXLy9KlSy3WvfHGG/LCCy9YHcciK6WULF++XFq2bGkRkI8fP173H4tMntTvO6Nv86TjscaT45j8iGFECmccQwzjfEaIYYYOHaqbWO/bt6+MGzdOTp48Kbdv35Zz587Jl19+KQ0aNNCdrrxr167m76J9+/bpvv5ly5bVvSUvN+jLPYAqQPr166dExOZy5swZt7Zz0aJFFu3ZsWOHbrkNGzZYlDt9+rTNurNv88cff1g8HxkZafF89+7dlYioli1bqq+//lpdvnxZpaWlqYsXL6qVK1eqSpUqWZR/8cUXLeq7ffu2Klu2rEWZXr16qf3796vk5GR169Yt9eeff6pp06apkiVLKm9vbzV9+nRzWW9vb93jKFGihLlM2bJl1a5du1RqaqqKjY1V//zzj30v9P+LiYlRJpPJXF9QUJCaPn26iomJUfHx8So9PV0lJSWps2fPqm+//VZ17tzZ4ngmTZrk0vOSkZGhypcvb/H8sGHD1JEjR1RKSoq6du2a2r17t3rllVfMr8uiRYvU0KFDzeVNJpNavXq1SklJUQkJCU4/z5kmTJhgUc7f31+98cYb6vDhwyopKUklJCSoP//8Uy1atEjVrVvXouzQoUN165w3b55FuaioKPtPrg0zZ87UfP7r1KljtfySJUs05QcPHmxzP9euXVOBgYE5fu9MmDBBs11UVJTFe9PRpWTJkuqvv/7SrVev/JUrV3I8juDgYM02ixYt0pQbO3ZsrttcpUoVlZCQYFd7rX032mv//v3Kx8cnV+187LHHVHp6uqbOgwcPKm9vb4fra9WqlaYuIx23PWJiYjT1hYaG2tyuatWqmu3mz5+fqzY4S3h4eI6vU3h4uFvbl9X8+fOVl5eX5ru5V69eat26der48ePqxo0bKjU1VZ09e1bt2rVLvfnmm+rBBx/UHFfPnj1tnn939vuu6NuIY/IWx7gihnHVuVbKWHEMMYzlUphimMGDB+e6jZnv67Nnz5rrs/d/ZHsWa98XntiXK5Vzf+7M/zk8wOckdtzAkxI7f/31lypdurRdr1v58uXVpUuXNPucM2eO3V8GkyZNUtu2bTM/NplMuscRFhZmtY6XX37Z9ouczauvvpqrL6+HHnpIJScn5/gaO+O8ZH9P5LR0795d3blzRy1fvlz3+c6dO7vkPCul1K1bt1SHDh0cfh3r16+vkpKSdOt0ZWLn+++/17TF29tbxcfH65bPbVCklFJz587N8TXQC4qUUmr58uXK19fX4dc0Dn7/OQAAIABJREFUJCRE7dy5U7dOVwdFaWlp6qmnnnK4zaGhoeq3336zu715TXAopdT69esdTnJUrlw5x37Ckc+riKjq1aur8+fPG/64bclNYicuLk73HwNr7+38YqTEjlJKffXVV3Z/x+st3t7easaMGXbvz139vqv6NuKY0zb3n1Mc4+wYRinXnWsjxTHEMJZLYYph0tLS1NNPP52rz7yvr6/asmWLRX09e/bMVV16i973haf25UoVrsQOt2IVcuXKlZOoqCibg1s98MADsnnzZotBuDKNGTNGXnrpJZv7GjdunMyYMcNizAqllO60upMmTXLq/eAzZsyQ2bNnW50+Uk9ERIT89NNP+TKi+5AhQ+y6FLZv376yevVq8fLykq5du9p976ozzrOIiK+vr3zzzTcyfvx4uy5FNZlM0q9fP9m+fbtLb2ezplmzZppzfufOHdm+fbvT9zVs2LBcDTjbq1cv2bFjhzRt2tSu8iaTSbp37y4xMTHSrFkzh/fnDD4+PvL111/LlClT7D6vHTt2lJiYGKlbt67d+3HGd0Dnzp3lhx9+kDp16thV/tlnn5WYmBipUKGC1TJDhgyRFStW2DVzVLt27eTHH3/UHSvBGk89blfYunWr5taKkiVLunT2sIKoS5cucurUKXn55Zdt3iaUlZeXl/To0UOOHj0qkyZNsns7T+n3ndW3ecrx5MST4xhXxzAihTOOIYZxDSPEMJltnDNnjtVp2vU0bNhQYmJipG3btrned27Ql3uGIu5uANzrzp070qRJEzl27JisWrVK1qxZIydPnpQrV65IcHCwVK9eXSIiIqR3795WAwMvLy9ZsWKFRERESGRkpOzbt09iY2MlIyNDypYtK61atZKxY8fKww8/LCKimUYvOTlZM3DbE088IVFRUTJt2jQ5cOCApKenS2BgoNSqVUszxoU9TCaTjBs3Tvr06SOrVq2S77//Xv744w+5fPmy3Lx5U/z8/CQwMFAeeOABadq0qfTo0UNz372rLViwQDp37iwffvih7NmzR2JjY8XLy0vuu+8+adasmQwYMMDi2P39/WXr1q0yevRoiY6OlvT0dClXrpzul6gzznOmIkWKyKxZs2TEiBGyatUq2bZtm/z1119y9epVycjIkICAAKlZs6a0bNlSevXqpXuPeH7x8/OTxx9/XDZv3myxftOmTU6fncjX11dmzpwp4eHhDm/bqFEjiY6Olp9++kk2btwoP/30k5w/f16uXr0qPj4+cs8990iVKlWkdevW0qVLl3x/b+rx8vKSN954Q4YNGyYrV66UH374QX7//XeJi4uTtLQ0KV26tFSuXFmaN28uL774otXpUXOS2yk3s2vevLkcPHhQvvnmG/nqq6/kl19+kUuXLklycrIEBQVJxYoVpVWrVtKjRw+b0/Rmeumll6RTp06yfPly2bRpk/z5559y5coVKVasmJQrV05atGgh4eHh0qZNG4fb68nH7Wx6M6S0bt1aihQhPHFUUFCQzJkzRyZPnixff/21bN++XX777Tc5c+aMJCQkiJeXl9xzzz0SEhIitWrVkrZt20rbtm0dSjpm8pR+31l9m6ccT048PY5xZQwjUjjjGGIY1zFCDGMymeTll1+WwYMHy5o1a2T79u2yf/9+iYuLk/j4ePH19ZWAgACpWrWqNGzYUJ577jm3Jcvoyz2EWy8YcjKj3IrlTtkvbb1+/bq7mwQX4Dz/j97l3gEBASo1NdXdTYOOihUrms+To+NQGFlhPO7k5GSLcUgylzVr1ri7aYa7FauwoG8rPDjXdxHDGAt9uWf15UpxKxYAFBhdu3bV/GoSHx8v69evd1OLYE1ycrKcO3dORESKFy+eqysJjKiwHve6des00xeXLl3aYkpiACjMiGGMg778f+jL3YPEDoACzd/fXwYMGKBZP3fuXDe0BjnZsGGDZGRkiIhI/fr1C80lvIX1uPU+g4MGDXJojBgAKMiIYYyDvvx/6Mvdg8QOgAJv7Nix4uPjY7Fu37598uOPP7qnQdD1/vvvm/929vgBnqwwHndUVJQcOnTIYp2vr6+MHj3aTS0CAM9EDGMM9OV30Ze7D4kdAAVehQoVZMiQIZr1EyZM0IziD/fYsGGD7NixQ0TuXsJszww1BUFhPO6MjAzdGZiGDx9eaC5dBwB7EcN4Pvry/6Evdx8SOwAKhSlTpmimjNy3b598+umnbmoRMsXGxsqgQYPMj1977TUJCQlxY4vyR2E97hUrVsjBgwct1gUHB8vrr7/uphYBgGcjhvFc9OX/Q1/uXoXj5j8AhV5QUJDMmjVLBg4caLH+5Zdflg4dOmgCJuSfMmXKyMWLF93djHxXGI87Li5OXnnlFc36//73vxIQEOCGFgGA5yOG8Vz05f9DX+5eXLEDoNAYMGCAhIWFWay7dOmSjBkzxk0tAgqXUaNGyZUrVyzWtW/fXnr37u2mFgGAMRDDwFPQl3smkypAN2f2799fli5darPcmTNnpEKFCvnQIgAAYDTdunWTdevWWX0+PDxc1q5dm48tAgAAjsqpP4+KipL27dvnc4tcZi1X7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGFQRdzfAHVq3bi1FihTKQwcAADacO3cux+e3bNkitWvXzqfWAACA3LDVnxckhTK7cfz4cXc3AQAAGFRiYqL88ccf7m4GAACAiHArFgAAAAAAgGGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGJRJKaXc3QhnuX79uiQlJbm7GQAAwM1q166tiQl69OghM2fOdFOLAACApwgJCZGiRYu6uxnOsrZATXceGBgogYGB7m4GAABwMy8v7UXJ/v7+UqFCBTe0BgAAwHW4FQsAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQRdzdAAAAAHscO3ZMkpKS7Cp7584dzbq4uDjZv3+/XdtXqFBBypQp41D7AAAA3MGklFLubgQAAIAt48ePlzlz5uTLvvbu3SuNGjXKl30BAADkwVpuxQIAAIYQERGRL/upWrWqNGzYMF/2BQAAkFckdgAAgCHUr19fatas6fL99OjRQ0wmk8v3AwAA4AwkdgAAgGH06NHD5fvIryuDAAAAnIHEDgAAMIyePXu6tP569epJnTp1XLoPAAAAZyKxAwAADKNatWrSoEEDl9XP1ToAAMBoSOwAAABDcVXyxWQyyfPPP++SugEAAFyFxA4AADCUHj16iLe3t9Prbd68uVSuXNnp9QIAALgSiR0AAGAo9957r7Ro0cLp9ebHwMwAAADORmIHAAAYjrOTMEWKFJGuXbs6tU4AAID8QGIHAAAYTrdu3cTX19dp9bVt21bKlCnjtPoAAADyC4kdAABgOIGBgdKuXTun1cdtWAAAwKhI7AAAAENyVjKmaNGi8swzzzilLgAAgPxGYgcAABhS586dpUSJEnmu55lnnpFSpUo5oUUAAAD5j8QOAAAwpOLFizvlShtuwwIAAEZGYgcAABhWXpMyAQEB0qFDBye1BgAAIP+R2AEAAIbVrl07CQ4OzvX2Xbt2FT8/Pye2CAAAIH+R2AEAAIbl4+MjXbt2zfX23IYFAACMjsQOAAAwtNwmZ8qWLSutWrVybmMAAADyGYkdAABgaC1btpTy5cs7vF1ERIR4e3u7oEUAAAD5h8QOAAAwNC8vL3n++ecd3o7bsAAAQEFAYgcAABieo0maqlWrSsOGDV3UGgAAgPxDYgcAABhe/fr1pVatWnaXf+GFF8RkMrmwRQAAAPmDxA4AACgQunfvbnfZ3Ny6BQAA4IlI7AAAgALhxRdftKtcvXr1pE6dOi5uDQAAQP4gsQMAAAqEatWqSf369W2WY9BkAABQkJDYAQAABYatpI3JZHLoli0AAABPR2IHAAAUGD169BBvb2+rzzdv3lwqV66cfw0CAABwMRI7AACgwLj33nulRYsWVp/nNiwAAFDQmJRSyt2NMLrExESHplgFAACuk5ycLPHx8brPlStXTry8+F0LAAB3a9WqlaxatcrdzSgI1hZxdwsKgoyMDDl//ry7mwEAAGy4ePGiu5sAAABE5MqVK+5uQoHBT1YAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AAAAAAIBBkdgBAAAAAAAwKBI7AAAAAAAABkViBwAAAAAAwKBI7AAAAAAAABgUiR0AAAAAAACDIrEDAAAAAABgUCR2AAAAAAAADIrEDgAAAAAAgEGR2AEAAAAAADAoEjsAAAAAAAAGRWIHAAAAAADAoEjsAAAAAAAAGBSJHQAAAAAAAIMisQMAAAAAAGBQJHYAAAAAAAAMisQOAAAAAACAQZHYAQAAAAAAMCgSOwAAAAAAAAZFYgcAAAAAAMCgSOwAAAAAAAAYFIkdAAAAAAAAgyKxAwAAAAAAYFAkdgAAAAAAAAyKxA4AQEREmjdvLkopzXLw4EF3Nw1AFj4+PrJ9+3bzZ/TMmTMSGhrq7mbBA4SHh0tGRob5vTF8+HB3NwkAkA9I7AAAABjI4sWLpVWrViIicvPmTenSpYtcvnzZvY2CR1i3bp1MnTrV/Hj+/PnSvn17N7YIAJAfSOwAAIA8a9y4scyePVt++uknuXDhgty8eVNSU1Pl0qVL8ttvv8myZcukf//+UqpUKafut1ixYnLs2DHdq82UUtKgQQND7MNeI0eOlH79+pkfDxkyRA4cOGBRZsCAAVbbmnXJyMiQGzduyD///CMHDx6UL774QiZMmCBPPvmkFCtWLN+OCc715ptvyrfffisiIt7e3rJmzRqpUqWKm1sFAHAphTyLj49XIsLCwsJi6KV58+a633EHDx50e9tYPHdp0qSJOnDggN19ZlJSkpo9e7YqVqyYU/Y/b968HPfXoEEDQ+zDnqVu3boqNTXVvN8vvvhCt9yAAQPsPh/WXL9+Xb377ruqbt26bn+PsTi+lC1bVsXFxZnP565du5S3t7fb28XCwsKSdWnbtm2e+ysopZT6nCt2AABArowaNUqio6PlkUcesXsbf39/GTdunBw4cEDKlSuXp/23aNFCRo4cmac6PGEf9vDx8ZFPPvlE/Pz8REQkLi5OBg8e7LL9BQQEyIgRI+Tw4cOycOFC8ff3d9m+4HyXLl2yGF+nSZMmMnHiRDe2CADgSiR2AACAwwYPHizz588Xk8mUq+0feOAB2bx5sxQpUiRX2/v7+0tkZKR4ebkulMmPfdhr2LBh8tBDD5kfT5kyReLi4uzadsuWLWIymTSLl5eXBAYGSpUqVaR169by2muvybZt20QpZd7WZDLJv/71Lzl8+LDF/uH5PvvsM4mOjjY/njx5slSoUMGNLQIAuIr7IxUAAGAoNWvWlHnz5uW5noceekgGDRqUq21nzZolVatWzXMb3L0PewQHB8u///1v8+Njx47JBx98kOd6lVISHx8vp0+flh9++EFmzJghbdq0kerVq8v7779vkeCpUqWKfPfdd1KtWrU87xf55+WXXzb/XaxYMZk5c6YbWwMAcBUSOwAAwCGvvvqq1cF1ly1bJvXr15eiRYtKSEiING/eXNavX2+1rl69ejm8/yeffFKGDh1qse769esO1+PufdhrzJgxEhgYaH48Y8YMSU9Pd9n+Tp48KcOGDZN27dpJbGyseX1oaKhs3bpVgoKCXLZvONfevXtl8+bN5sc9evSQ2rVru7FFAABXILEDAAWYv7+/9OnTRzZv3iynTp2SlJQUuXLlivz666+yePFiadiwobls1l/nc8vPz0969OghH374oRw6dEguX74saWlpEhcXJ7///rt8/vnnEhERYfd4HQEBAbqz+WzcuNGiXHBwsLz66qsSHR0t165dk7S0NLl06ZLs2bNHJk2aJGXKlHH4WHx9faVz586yaNEi2bVrl1y4cEGSkpIkPT1d4uPj5dixY7J+/XoZNWpUnm5vcPZr5molS5aU559/Xve5uXPnSt++feXAgQNy69YtiYuLk+joaHn22WetXmHSsGFD8fb2dmj/S5cutbgFLDExUZYuXerYgbh5H/YqVqyYDBkyxPz48uXLsmbNmnzZ99atW6Vjx46SnJxsXle5cmV54403HKonMDBQhg0bJmvXrpUTJ05IfHy8pKamytmzZ+WXX36RBQsWyBNPPGH3+6BUqVIW3wcffvihxfNt2rSRlStXyvHjxyU5OVnS0tIkNjZWdu7cKW+++abDYzsVK1ZMunfvLsuWLZMDBw7IlStXJDU1VdLS0uTq1aty8OBB+eSTT6RXr165/pw6+zXK6r333rN4PHr06Fy1EQDgwdwzaHPBwqxYLCwsnri0bNlS/f333za/w5YtW6b8/PzUY489pvu8PbNimUwmNXr0aHX58mW7vjcvXryounfvbrPeIkWK6G4fHR1tLhMeHq7i4+Nz3N+1a9dUt27d7HrdvLy81NChQ9WVK1fsOhallEpLS1MffvihKl26tN3nx1WvmauXJ554Qrd9cXFxytfX1+p21atXt3psISEhdu9/yZIlmu3HjBmjpk+frlt3bmasyo992Ltkn+Fq6tSpDm+zefPmPLWhR48eFvWlpaWpGjVq2NzOx8dHzZgxQyUmJlo991kdOHBAPfroozbrzf69sHr1aiUiKjg4WEVFRdncT0pKioqIiLDr2CMiItSFCxfsar9Sdz8HgwYNsvu1ddVrlHUxmUzq5MmTFscfEBDgsvcsCwsLi70Ls2I5zeckdpyAxA4LC4unLe3bt1e3b9+2+3vs22+/zXVip0SJEmrTpk25+v6cNWuWzWNJS0vTbHf06FElIur5559XGRkZdu0rPT1dPf300znuy8fHR3322We5OhallDp58qSqVKmSzWNy9WvmyqVFixZqxYoV6ttvv1W7d+9Wf/31l4qLi1Pr1q3LcTt/f3+rx2Tv1Oft2rXTbLtnzx7l7e2t5s6dq1u3o0mX/NiHI8vWrVst9mXP9OPOTuyYTCb1yy+/WNT50Ucf5bhNYGCg2rFjh9Vzbk16erp69tlnbbbpzp075m2+/vpr5e/vrw4ePGj3fu7cuaOaNWuW4z5GjhzpcPszTZs2zeYxuPo1yrrMnDnToo7evXu77D3LwsLCYu9CYsdpSOw4A4kdFhYWT1ruv/9+u3/9zWr58uW663NK7Hh5ealvvvkmT9+h48aNy/F4EhISNNucPXtWValSRSUlJTm0rwsXLqiSJUta3dfUqVPzdCxKKXXkyBHl5+fn1tfME5dHH33U6utlz/YBAQHq3LlzFtvevHlT1axZU4mImj9/vm79jiRd8mMfjixBQUEWCdrjx4/btZ2zEzsid6+My+rGjRvKx8fH6ns8+5Uz6enp6oMPPlAtW7ZUpUuXVr6+vqpixYqqZ8+eKiYmxqJsamqqatKkSY7tSU1NNZffsmWLeu+995RSSiUmJqpp06aphx56SBUvXlwVK1ZM1ahRQ40bN07zXbJ3716r9desWVPdunXLXDYjI0N9/PHHKiwsTIWGhipfX19VvHhxValSJdW9e3f15Zdfat4XjRs3tlp/frxGWZfsifsNGzbk6+efhYWFRW8hseM0JHacgcQOCwuLJy2ffvqp1e+r9evXqyZNmqjixYurgIAA1aVLF3X48GGllLJ65UtOiZ1x48bpbpOYmKjGjh2rKleurHx8fFTZsmXVgAED1KVLlzRlU1JS1P333291H9euXdNsExcXp9auXWvPV7TGkCFDdPcTEBBg8c9ipnPnzqmBAweqatWqqaJFiyqf/2PvzuNjuv7Hj78nIUgIEWmotZaiVaWW2oq2sZcqoVpKaWv5qBZdUG1p6WIp2g+lVaWKVlG1VPii9r0UVaW2IrZISCIhm5zfH37mkzv3TmYmmcnkJq/n43Efj9w755x75t7JvGfec+85BQuq0NBQ9cwzz6g9e/YY7uOtt97y6jHLbYufn5/6v//7P5ePVcbFKPE4ZMgQ6+PuSLrkxD5cWbp27arZz/Tp052q54nETmBgoO4qQHuJC9srXeLi4jK9OsbHx8eamLnrwIEDymKx2K1z8+ZNa9mrV6+q9PR0derUKVW5cmW7dVq0aKF7n7N3S9nEiRM15f7zn/84PEa9evXStJ/ZVWw5cYwyLhaLRfNeevPmTVWgQAGPvG5ZWFhYnF1I7LgNiR13ILHDwsKSW5aKFSvaTdAsWLDAsE7RokXV/v377b7H2UvsFCtWTEVHR+vKp6Sk2P3Cd99996mYmBin+yYihvtIT0+3Ps8DBw6o9u3bq8DAQBUYGKjat2+vjh49avf5rF+/3nA/zz//vGH5Rx991G7fAgIC1IEDB3R1jh075tVjlhuWwMBAVb16dfXaa6+pI0eOGB7bAwcOZHp1092lY8eOurobNmzQfKnNbtIlJ/bh6jJp0iTNfnr16uVUPU8kdkREd9vQ4MGDdWX8/Px0Vz099dRTDtv28fFR27dv19Tr2rWr3fK2V+ulpKSohx9+2OF+Nm7c6NQx3bRpk7XMrVu3nE6CLFq0SJ09e1Zt3bpVzZw507BMTh0j22Xt2rWauq6O1cPCwsLi7oXEjtuQ2HEHEjssLCy5ZXnjjTcM36cSEhJUcHCw3Xp169a1+x5nL7EzbNgww/Jz5szJtI9GV6wkJiaqgIAAw/JGiZC7fvvtN8PEQHBwsDp//rxhnZiYGMP9jB492rB8ZrduidxJCEVHR6tDhw6pX3/9VX311VfqvffeMxxIOKeOmbeWRo0a2T1XtrZu3apKlSrlsM2SJUuqS5cuaerGxsaq8uXLa8plJ+mSE/vIyrJlyxbNfqpWrepUPU8ldubNm6dpd/Lkyboy3bt315Sxl0g1Wmw/4C9evNhuWdvEzvz5853ah+3/ub3BqA8dOmQtk5CQ4NbzmlPHyHYZO3aspu6gQYM88rplYWFhcXYhseM2PzHdOQDkIa1atTLcvnLlSomJibFb748//pDdu3e7tK8uXboYbv/5558zrffTTz/ptvn7+0v79u1d2v/Nmzeld+/ekpycrHssJiZGPv30U8N6JUuWlKCgIKf306tXr0wfX7RokZQqVUoefvhh6dChgwwYMEDGjRsnKSkpurLePma5we+//y69e/eWFi1aSHR0tMPyM2bMkNKlS2u2vfbaa3L+/Hm39Skn9pEV1atXt/6dmpoqp0+f9mJvRHe+SpYsqSvzxBNPaNYXLlzodPsbNmyQ69evW9fbtWvn9PTeixYtcqrcmTNnNOvFixc3LBcVFWX9OyAgQDp27OhU+87w1jH6559/NOv333+/0/sFAORuJHYAIA+pVauW4fZNmzY5rBsREeH0fgoUKCD169c3fOz48eOZ1j137pzExcXptjdo0MDp/YvcSXZERkbafXz16tV2HzP6Mnf27FnDsjNmzJDly5dLeHi4lCpVyqU+ZpQbjpk3xcfHy9SpU+Wtt96ShQsXilLKYZ2uXbtKjx49NNuWL18u8+fPd1u/cmIfWVG4cGG55557rOuRkZGSnp7uxR6JLjns7++vK9O8eXPN+vbt251uPz09XXbu3GldL1asmFStWtWpunv27HGqXEJCgmbd6DmI3EmgZLRo0SIZOHCg+Pn5ObVjvfuLAAAgAElEQVSfzHjrGNkmtSpWrOj0fgEAuRuJHQDIIwICAqRs2bKGj9n+Umvk4MGDTu+rYsWKUrhwYcPHTpw4IUqpTBejxMpDDz3k9P5FRNauXZvp4+fPn7f7RbhQoUK6bWvWrDG8+sdisUjnzp1lyZIlEhUVJceOHZNvv/1W+vbtK/fdd5/T/c0Nx8ybAgMDZdiwYbJp0yaJjIyU119/XQoWLGi3fEhIiMycOVOzLSoqSgYMGOC2PuXEPrKqbNmyYrFYrOvevnpIRJ8ESU1N1ZXJ+D+hlHK537bvVTVr1nRYJyUlRXMVi6OyGWU8xhl99dVX8u+//1rXixYtKjNnzpSLFy/KvHnzpGfPnlKmTBmn9mnLG8dIRJ+8Ll++vEv7BQDkXiR2ACCPyOz2osuXLzus70yZu2xvW3EHV5IkIiJ///13po+np6fbvdXH6MvctWvX5KOPPsq0TYvFItWrV5e+ffvKt99+K6dPn5azZ8/KzJkzpWHDhpnWzQ3HLLcoU6aMTJs2TdavX2/3VpiZM2dKSEiIZlv//v3l6tWrbutHTuwjqwIDAzXr8fHxXurJ/wQHB2vWb9y4oVkvUqSIJnlpsVgkKSnJYdIy4zJs2DBNm84kT2z74Q6xsbHSoUMHXTIkODhY+vTpIwsWLJCLFy/K33//LdOnT5e2bdtKgQIFHLbrrWMkoj9OxYoVc6oeACD3I7EDAHlEZh/Sb9686bC+K1+OihQp4nRZZ7n6JcPo1iRbrn7h++ijj2T69Oku1alQoYIMHDhQ9uzZIytXrrT7JSs3HDNP2717t1gsFrFYLFKsWDGpVKmSdOzYUX744QfDW69atGghCxYs0G1/7rnnpGvXrppt8+bNkxUrVritrzmxj+ywvTrGmf9hTwsNDdWs215pUqJECbfv05uv8aNHj0rdunVl2rRpdo9/jRo1ZPDgwRIRESGXL1+WDz74QJeUy8ibxygxMVGzbu82NACA+ZDYAYA8wt4tBSLi1Hgmzg7AKaK/ncEdMvsyZOT27dtu70N6eroMGTJE2rVrJ/v27XO5fseOHWXfvn1SpUoV3WO54ZjlpISEBDl79qysXr1ann/+eenQoYPhMXjqqackLCzMul66dGldcu3cuXPy+uuvu61vObGP7LK9XdDoNsGc1qRJE8267dhQnvifLFq0qNvbdMX169dl2LBhcu+990rfvn1l2bJldq+eCg4Olvfff19OnDghjRo1MizjzWOUnp4uaWlp1nWjW1IBAObk+JpRAIApZHZ1ijO/zLryy3hm41mUK1dOLly44HRbudHatWtl7dq1UqtWLWnXrp2EhYVJs2bNnDqOZcuWlcWLF0uDBg00CbW8fswciYiIkLlz5xqOX/Pcc89ZB6tt1qyZbralChUqOHWFlhHbBN1jjz0mpUuX9vg+XBkQ14htIsfbX8Jr1qypu51w165dmnXb43fr1q08c1VIXFyczJs3T+bNmycFCxaUJk2aSOvWraV169ZSr149TWL9nnvukd9++03CwsI0Ax3fbSejnDxGPj4+mtvFckOyEADgHlyxAwB5RGxsrN3HnBmDwZWBNK9du2b3MdvbNczsyJEjMmnSJGnTpo0UL15cGjRoIEOGDJGFCxfKxYsX7darV6+ebkrj/HLMMrNjxw7D7XXr1s3hnuR+trf+eDtB8txzz2nW9+/fL5cuXdJsS05O1vS7SJEibplFKrdJTU2VLVu2yOjRo6VBgwZSrlw5GTNmjGbGrSJFisisWbN0db15jAICAjTrueH2PgCAe5DYAYA84saNG3YHQK5evbrD+q58ub5w4YJu6uO7PDFIcG6QlpYmv//+u0yfPl169eol5cqVk9atW9udqjzj7UUieeeYvf/++zJ79mxZsWKF7Ny5U06ePClxcXHSsWNHh3Xt3RJo+4UTuWug26JFi8qrr76q2TZv3jzDsn/99Zdm3Zn3HrO7ePGifPjhh1K/fn1NAvehhx6SOnXq6Mp76xjZvoY8Meg0AMA7SOwAQB5i+4XhLturR4w488U8I9vbMO6yHYcjr1JKyfr166VVq1aG06obTT2fF45Zx44d5eWXX5ZOnTpJ48aNpUqVKhIYGCjdunVzWLdBgwaG23PDLFS5TWRkpCYRVqFCBa/15cMPP9TMuhcZGSmzZ882LGt7W1rTpk092rfc5Pjx4/Lll19qtj3wwAO6ct46RhUrVtSsuzrNOgAg9yKxAwB5yMaNGw23d+rUSTetc0ZhYWHy4IMPurSvX3/91XB77969M721oG3bthIfHy8nTpyQ7du3y9KlS2XGjBm6K1xyUpkyZaRHjx7y/vvvy8KFC2Xfvn1y5coVp2awOX/+vOG06ka3OeSFY2bvNdarVy/p1KmT3XrVqlWTvn37Gj6W8aqnpUuXWmfWcmX5/PPPDdtu0KCBptzd4+fpfWRXUlKSREVFWdfLlSsnPj45/7HtmWee0U2vPX78eLvjs6xdu1az/sILL3isb57SqlUrmTx5smzdulW2bNniUt1Tp05p1o0GpffWMapUqZJm3XYqdwCAiSlkW2xsrBIRFhYWFq8v1atXt/te9eOPPyqLxaKrExISok6cOGG33sGDBw33FRAQoK5du2ZYZ+rUqYZ1ihQpovbu3asrn56ermrXrm1YJzo62nAf5cqVc3g8Tp48aVi3Ro0amnINGjRw6XlkXOrUqaPS09N1dV9//XWvHTNPLrVq1TJ8vkoplZaWpr766itVu3ZtVaRIEVW0aFH10EMPqXfffVfFxsYa1lFKqWeeeSbb/Zo2bZph2/Xr13fbc8+JfWRctm7dqtlP1apVnar38ssva+qtXbs2S/t/4YUXVFJSkqat1atXKx8fH7t1fH191fnz5zV1unTp4tT+ChQooHbu3Kk2bNigRo0apR555BG7ZRMSEqztR0dHO/2c2rZtq+nbN998oyszceJETZnmzZs73f748eM1dVu2bOm1Y2S7jB07VrPPQYMGeeR1y8LCwuLs0rp1a8O4Cpf9RGLHDUjssLCw5KZlzZo1dt+vVq9erRo1aqT8/f1VcHCw6tmzpzpz5oxSSum+wN116NAhu/saOXKk3X0tWbJEPfrooyogIEAFBwertm3bqt27dxuW/fbbb+3uIycSOyKiDhw4YFj2xx9/VJ06dVJlypRR/v7+qkCBAiooKEjVrVtXvf322yoqKkpXJyUlRZUpU8Zrx8zTy8KFC+0+B1cdO3ZMFSxYMNt9youJncmTJ2v207NnT6fqZTexU7FiRTV37lzd8zx69KgKDAx0WP8///mPpl58fLxq1qxZpnUCAgLUDz/8oKk3a9Ysu+U9mdipXbu2Jnl57tw5df/99ztsu2rVqpr3q+vXrys/Pz+vHSPbJSIiQlPXlaQQCwsLiycWEjtuQ2LHHUjssLCw5Kalbt26KiUlxeX3Mttfc+86cuSI3X35+PiojRs3Zus99MSJE5l+WcypxE7Tpk1VWlpatp7LXe+9955Xj5mnl1KlSmV6lZezUlJS1OOPP+6WPuXFxE54eLhmP//973+dqudKYsfHx0fdc8896qGHHlL9+/dXy5YtU8nJybrnuGvXLlW2bFmn9m+xWNT69es19dPS0tTXX3+tWrZsqUqVKqUKFiyoypQpo+rXr6/Gjh2r/v33X035K1euqJCQELv78GRiR0TUvHnzNOUSExPVF198oZ588kkVGhqqChYsqIoUKaLKlSunmjZtqsaPH6+7Ku2dd97x6jGy3V9MTIy17s2bN1WBAgU88rplYWFhcXYhseM2JHbcgcQOCwtLblv69+/v0vvYd999pypVqmT42MmTJzPdV4kSJXRfUJz1999/O0zQ5FRiR0RUz549s5QUy2jGjBnK19fXq8csJ5b77rtPHTx4MMvH6ebNm6pr165u609eTOyULFlSpaamWvfzzz//OFXPNrGTHbdv31YzZsywe+WJvaV48eJq06ZNWdpndHS0atCgQabtezqx4+/vr/bs2ZPl47Z8+XKHiRNPH6OMS8OGDTX1V61a5ZHXLAsLC4srC4kdt/mJwZMBIA/6+uuvpU+fPpKYmJhpOaWUfP7559KvXz/DAYBFRPz9/TNtIzY2Vtq1ayejR4+W69evO9W/pKQkmTp1qtSrV08iIyOdqpMTFi5cKI0bN5bdu3e7XPf48ePSpUsXGTx4sNy+fTvTsnnhmJ05c0YeffRR+eCDDzRTPDuilJI1a9ZI7dq1ZdmyZR7sofldu3ZNNm/ebF2vVq2ay4OcZ9Xt27dl4cKFUqtWLRk8eLCkpKS4VD8uLk7atGkjH374oSQkJDhdb/ny5VKvXj3dzFE57ebNm9KiRQv54osvXHruN27ckJEjR0p4eLikpaVlWjYnj1GXLl0060uXLnW6LgAg9yvg7Q4AADxj/vz58ttvv0m/fv2kY8eOUrFiRQkMDJSoqCg5f/68rF27VhYtWmSdxSUhIUHi4uKkePHimnYCAwMd7istLU0+/vhjmT59unTp0kWefPJJqVevnoSEhEiJEiUkMTFRrl27Jn/++ads2rRJFi5cmGunuN6/f780btxY6tWrJx06dJBGjRrJfffdJ6GhoRIQECC+vr5y48YNiY2NlWPHjskff/whK1eudDkZlBeOWXJysowdO1YmTZokTz/9tLRo0UIaNmwoISEhEhQUJAULFpS4uDjr89i7d68sXbpUTp8+7e2um8bixYs1s591795dxowZ49Z9JCYmytWrV+Xq1aty+PBh2bBhg2zcuDHbr7eUlBQZM2aM9TXeqlUrqV27tpQqVUoCAwOtr/G//vpLdu7cKYsXL9bNKuVNSUlJ8vrrr8vEiRMlPDxcHn/8calevbqUKVNGAgICJD09XW7cuCGRkZHW47Z8+XK5ceOG0/vIiWNksVika9eumue1YsUKl9oAAORuFqWU8nYnzC4uLs6pKXEBAABc4e/vL+fOnZPg4GAREbl06ZJUrFhRUlNTvdwzmEXbtm0lIiLCuj579mzp37+/F3sEAHe0bt1a1q1b5+1u5AVLuBULAAAgl7p586bMmjXLul6mTBnp3r27F3sEsxkyZIhmfdq0aV7qCQDAU0jsAAAA5GJTp06V2NhY6/q7774rBQpwNz0ca9CggbRr1866vnjxYjl69KgXewQA8AQSOwAAALlYTEyMfPjhh9b1GjVqyCuvvOLFHsEsJk+eLBaLRUTujK3z9ttve7lHAABPILEDAIDJDR06VJRSHl1Onjzp7aeZr02fPl2OHDliXf/ggw+s4+4ARrp37y7Nmze3rn/88cdy7tw5L/YIAOApJHYAAAByudTUVOnZs6ckJyeLiEhISIhm7B0go9DQUJkxY4Z1fffu3fLxxx97sUcAAE8isQMAAGAChw8flhEjRljXw8PDpVevXl7sEXIji8Uic+bMkVKlSomIyI0bN6RXr15y+/ZtL/cMAOApJHYAADC5adOmicVi8ehStWpVbz9NiMjnn38uc+fOta5/9dVXUrduXS/2CLnN+++/Lx06dBARkdu3b8uzzz4rp06d8nKvAACeRGIHAADARAYMGCCbN28WERF/f39ZsWKFhIaGerdTyBW6du0qY8aMsa4PHTpUIiIivNgjAEBOYK5MAAAAE0lNTZXHH3/c291ALrRs2TLx8eF3WwDIb3jnBwAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmFQBb3cgP3nggQekW7du3u4GAAC5XmRkpMyZMyfTMsOGDZPAwMAc6hEAAHCVM/Ec2UdiJwc98MADMnbsWG93AwCAXG/Xrl1OJXbKly+fQz0CAACuciaeI/u4FQsAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgCTWL16tVgsFuvy77//ertLcEGrVq00589isUjfvn293S3kMz179tS9Dtu3b+/tbgH5DjHdvIjnyA2I57BFYiefmTVrluYNYPv27d7uEpDnffPNN7JhwwbNttKlS8uUKVM0ZWwD9N1lxYoVTu9r8uTJuvojR45023OBa7Zu3SpDhgyRBg0aSEhIiBQsWFACAwOlYsWK0q5dOxk/frzLX+g2b94sr732mjzyyCMSGhoqfn5+UqxYMalQoYK0b99ePv74Yzl//rxh3c8//1xCQkI02yIiIuS7777L6lOEgWvXrsmSJUtk4MCB0rBhQ6lcubIEBgZK4cKFpWzZslKnTh0JDw+XmTNnysmTJ73dXQBOIp7nH//++6/d8+jskpCQkOk+Ll26JB9//LGEhYVJ+fLlpUiRIlKsWDGpUqWK9OjRQ77//ntJS0szrEs8h45CtsXGxioRcbiEh4d7u6tq5syZmj5t27bN213KdVJTU1WRIkWUiKiZM2d6uztWq1at0py7M2fOeLtLcEJMTIwKCgrSvR8sWrRIU2727Nl23zuqVaumUlJSnNrfpEmTdPVHjBjhiaeGTBw4cEDVr1/fqdjg4+Oj+vbtq2JjYzNt88SJE6pJkyZOtzlw4EB148YNXTvz5s3TlQ8ODlbXr1/31OHIkp07dzp8nufOnfN2NzUiIyPV4MGDVaFChZw6T3eXNm3aqF27dnm7+7k2/mVVbn4+xHTzIZ7nL3/88YdL7+NGi1EMvuvTTz9V/v7+DtuoXr262rt3r2EbeSGet27d2tvdyyt+4oodwMZff/0lt27d8nY3kEeMHTtWrl+/rtnWsGFD6dGjh9NtnDhxQqZPn+7ursFDIiIipGnTpvL77787VT49PV3mzp0rTZo0kejoaMMyBw4ckPr168vOnTudbnPWrFny5JNP6n4xfOGFF6ROnTqabTExMTJu3Din2oax+fPnS9WqVWXGjBmSnJzsUt1169ZJ48aNZeDAgZKamuqhHjqW1+JfXns+8C7ief4SGxvrsbbfeustGTlypNy8edNh2ePHj0tYWJjs2bNH9xjxHBmR2AFsOPtlDHDk3LlzMmvWLN32CRMmiMVicamtcePGybVr19zVNXjIyZMnpVu3bln6Mnn06FF55ZVXdNvj4+OlY8eOEhcX53Kbe/fulaFDh2q2+fj4yMcff6wrO336dLl48aLL+4DIyJEjpU+fPpKUlGTdFhwcLIMGDZKVK1fKyZMnJS4uTpKSkuTcuXOybds2ee+996R69eqadr766isJCwuT+Pj4nH4KIpL34l9eez7wHuJ5/pOVmOuMxYsXy+TJk12qEx8fL+Hh4brYQDxHRiR2ABt8EIS7TJkyRffre8OGDaVly5Yut3X9+nUZO3asezoGj3nttdckMTFRt/3VV1+VEydOSFJSkpw4cUI++eQT8ff315X75Zdf5OjRo5ptkyZNMvyA1qJFC9m5c6fEx8fL+fPnZc6cOVKqVCldublz58qZM2c029q1aycPP/ywZltKSopMmzbNqeeJ/5k9e7ZMmDDBum6xWOTNN9+UU6dOyZdffikdO3aUKlWqSGBgoBQqVEjKly8vzZo1kw8//FD++usv+eabbyQwMNBaf+vWrdKvXz9vPJU8F//y2vOB9xDP8x+jK3bCwsJEKeX0UrRoUU39tLQ0GTFihK7d2rVry6ZNmyQhIUGio6Nl1qxZUqRIEU2ZyMhImTp1qq4u8Rx3kdgBbOzfv9/bXUAekJCQIHPmzNFtHz58eJbbnDlzphw/fjw73YIHnTx5UtauXavbPmjQIPnvf/8rVatWlUKFCknVqlVl5MiR8sUXXxi2s27dOuvf6enphq+jWrVqyYYNG6Rx48ZSrFgxKVeunPTr108WLlyoK5ueni4rV67UbTd6LX799dfcuuKCo0ePypAhQ6zrBQoUkPnz58ukSZOkePHiDuv7+vrKSy+9JFu3bpXSpUtbty9btkxmzJjhkT5nJq/Fv7z2fOAdxPP8ySixExQUlK02V61aJWfPntVsCwwMlP/7v/+Tli1bSkBAgAQHB8uAAQPks88+09WfNWuW4WDKxHOIkNiBgblz51pHc7///vut25VS8ssvv0ibNm3knnvukYIFC0qJEiXkoYcektdee01OnDhht81JkyZZ26xcubJ1e3R0tLz//vvSsGFDuffee6VQoUJy7733SrNmzWTq1KmZXgb56aefWtssUKCAU89t2rRphnUyzha2b98+6/ZBgwZpRrfPzq9/KSkp8tNPP0nPnj3loYcekpIlS0rBggWlSJEiUqZMGWnWrJmMGDFC/vjjD6fau3vpb1pamsyZM0fatGkjlStXlsKFC0tQUJDUqlVLXn/9dTl16pRT7d2+fVt+/fVXeemll6ROnToSHBwsfn5+EhAQIOXKlZO2bdvKxIkTJSoqKtN2PHGubV28eFE++ugjadWqlZQrV06KFCkigYGBUrVqVenQoYN89dVXuvvgjWR8PVgsFsMv5Vm1bNky3dgmJUqUkM6dOzvdRpMmTTTraWlp8uabb7qlf7Z27Ngh77zzjjRu3FgqVqwo/v7+UrRoUalUqZI0btxY3nnnHadm0ZszZ45uVog2bdpYH1dKyeLFi6VDhw4SGhoqBQsWlJCQEGnUqJF8+umncuPGDaf7HB8fLzNnzpRu3bpZr4goXLiwVKpUSR5//HH54osvHL5e3Wn9+vWilNJs8/X1NbxMWkTkxRdflEKFCum2Z5zR6uDBg3Lp0iVdmdGjRxu+77Vu3VrKly+v237kyBHdtvDwcN2viXFxcYZJIBgbN26cZjyd999/X3r16uVyOw8//LD8+OOP4uPzv49l48aN09zaZctdMTAr8S83x3QzxnMRYnp2Yzrx/H+I5+7hicTO0qVLddt69uwpoaGhuu19+/aVgIAAzbbLly/Ltm3bdGWJ5xARZsVyh7w2K9bChQutj5cuXVoppdT169cdzsbi5+enFi5caLjfL7/8UjNau1JK7dq1S91zzz2Ztlm+fHm1Y8cOwzY/+eQTazlfX1+nnv/UqVMN69geF3vLvn37nNqPrd27d6uqVas6PYp+eHi4boYc2xk0zp8/ry5duuRw5h0/Pz/djA22/vzzT1WnTh2n+hYQEKBmz55tty1PnOu7UlNT1dtvv638/Pwc9jM4OFjNnTs30/Yyvh5EREVERGRa3hVt2rTR9emVV16xW95oFo3PP/9cVahQQbd9w4YNdttxdRaNPXv2qMcee8zp12bTpk0znb3nhx9+0NV59NFHlVJ3ZhRp2bJlpu2XLVtWHTp0KNNjm56eriZPnqyKFSvmsL+BgYGZvl7d6bvvvlOdOnVSTZs2VTVq1FAhISGqfv36mdapUqWKrs9vvfWW9fFNmzapxx9/XD3yyCOqatWqKiQkRBUqVEhdvnzZbptG57NLly6GZV944QVd2aeffjprB8DNcvusWKdPn1a+vr7WvjzwwAMqLS0tW20OGjRI8/wym8nJXTEwK/EvN8d0M8RzpYjpSrk3phPPiefuNmzYMF0f3n777Wy1Wbp0aV2by5Yts1u+devWuvLvvvuuYVmzxnNmxXIbZsWCnp+fn/XvmzdvSkpKioSFhTmcjSUlJUX69esnf//9t+6xjL++JSQkSGRkpLRv395h9v38+fPy1FNPyT///OPis8g9/vnnHwkLC5OTJ086XWfp0qXSuXNn3a//GVksFmnbtq3DXx1TUlKkd+/eunE77jpx4oQ0b95cDh486FTfEhMT5ZVXXpF58+YZPu6pc52WliZPPfWUTJw4UVJSUhz2MyYmRvr27Suffvqpw7LulpSUJFu2bNFtb9++vUvt3LhxQz766CPd9uHDh0t6enqW+3fX999/L4899pjhrz/27NixQ5o3by7z5883fNzoCpT4+Hjr+du8eXOm7V+4cEFatWolMTExho+np6dL9+7d5c0333Tq18D4+Hh55ZVX5IMPPnBYNrt69+4tK1askO3bt8vff/8tUVFRmisGbCUlJcnly5d12zPeK9+yZUv57bffZP/+/XLixAmJioqSpKQkw1/37rp69apuW8mSJQ3LGr0mN27c6NWZmczi559/ltu3b1vXX3vtNfH19c1Wm0OHDtUMxLp48eJstecp+TWmeyqeixDTHfFWTCeea+WXeC7i/it2Ll26ZBjzH3jgAbt1atasqdtm7z2CeA4SO9ApWLCg9e+kpCSZMGGC7N+/X2rWrCkLFy6US5cuSbXXS/EAACAASURBVGpqqkRHR8vq1auldu3a1vLJycny+eef69rM+GE3OTlZ3n77bbl+/bo0adJEfvnlF7l8+bKkpKTI5cuX5YcffpCqVatay1+/fl1ef/11Dz3bOwYOHChKKd29qDNnztQMgla/fn2X2x49erT1El4/Pz8ZNWqU7Nu3T65fvy5paWly48YNOXnypCxatEhzqe7mzZtlyZIldtudNGmSHDp0SKpXry7fffedXLx4UVJSUuTq1avy888/y4MPPmgtm5aWZncE/sGDB2suce7QoYOsWrVKLly4IMnJyZKYmCgHDhyQ119/XXObwPDhww0vtfbUuR41apRm7JFq1arJ119/LUePHpXExERJSEiQw4cPyyeffCLBwcGaehs3brR7HD1hx44dulsofH195fHHH3epnevXr0vPnj11r7vDhw8b3u/vijVr1kifPn2c+kBtKzU1VV588UVZv3697rGMieG74uPjZdKkSbJr1y6n2o+KipIPP/zQ8LG33nrL8FJmR8aOHSvLly93uZ4nTZkyRTfQclBQkHTq1CnLbf7xxx9y7Ngx3fZq1aoZlg8LC9PN6JKQkCC7d+/Och/yi4xfaiwWizz77LPZbvP+++/X/L/v3r3b5anTXZWV+JebY7oZ47kIMT23xnTiuVZ+iuf2EjuRkZEyatQoqVOnjhQvXlwKFy4s5cuXl/bt28uXX35pOIGCiNi9jbJcuXJ2+2D0mL2hL4jn4FYsN8hrt2JlvDzYYrGowoULq9atW6ubN28athkdHa1KlixprVOxYkVdmblz5+qOR+fOnVVqaqphm7Gxser+++/XlD98+LCmjDtvxbrr1q1bmn1mdhm8M9LT05W/v7+1vcmTJzus06tXLxUaGqrq16+vpkyZYt1ue9l2oUKFVFhYmEpMTDRsJyYmRpUqVUpzSaytU6dO6c5JZj799FNNeaPLwT1xrk+fPq0KFChgfbxdu3Z2X49KKRUZGakqVapkLV+rVq1Mn5e7ZXxt3l0efPDBTOsYXbo9ePBgpZRSW7Zs0T0WGhqq4uPjde04c+n2tWvXNK+NjEvPnj3Vrl271I0bN1RCQoLauXOnCg8PNyxbpkwZ3etvzZo1unL+/v6qePHiysfHRw0bNkydPHlSJSUlqYMHD6qOHTsath0cHKx7zRw5ckT5+PjoytatW1etWbNGXbp0ScXGxqodO3aodu3a6cpVrlxZJScnZ+WUusXt27dVVFSU2rBhg+rRo4eufz4+Pmrp0qVZbj8lJUU1bNjQ8HiePHnSbj2j28GmTp2a5X64S26/FSs4ONjajwceeMBt7dpe/p8TtyMr5Vr8M0NMz83xXCliulliOvE8/8bzxx9/XLffDh06qMKFC2cal0qXLq2WL1+ua++nn37SlfXz88u0D/PmzdPVKVKkiN3yZozn3IrlNtyKhcwppaRw4cKycOFC3bR7dwUHB0v37t2t62fPntUNMmeraNGi8s0339gdILF48eIyceJEzbbVq1e72Hvvi42NlZs3b1rXbacjNPL999/L5cuXZd++fTJs2DC75fz9/eWHH34wnDJZ5M6tFz169LCuX7hwQXdeLly4II899pjcf//9EhgYKK+++mqmfRsyZIjmii5nZhxxx7meOnWqdRaAkJAQWbRokd3Xo4hI2bJlZdasWdb1I0eO5Oi0t4cOHdJtc+bc27r7nJs3by5PP/205rErV67IJ598kqX+zZo1S6Kjo3XbP/jgA1mwYIE0atRIihYtKgEBAdK4cWNZsmSJ4Wvj0qVLsmjRIs0221+LRO7c0hkXFyeff/65TJkyRapUqSKFChWShx9+WJYvX64bVFLkzmX3tleefPTRR7pL1itVqiSbN2+Wdu3aSenSpaV48eLSpEkTWbNmjXTo0EFT9vTp0165amf37t1isVjE19dX7rnnHgkLC5Mff/xRU+bee++VlStXSteuXbO0j/T0dOnbt6/s3btX99gzzzwjVapUsVs341WXdxm9hvE/aWlpmtsLjC6Xz6patWpp1o0Gz85t8kNM92Q8FyGm59aYTjzXyk/x3OgKtl9//TXTQe1F7gxw3LVrV/nmm280269du6YrazvgsTOP37p1y24fiOf5G4kdOPTiiy9KqVKlMi1Tp04dzbqj2Qu6deumubTWSIcOHTRvaDt27HDQ09wnMDBQcxnzr7/+6ra2+/Xr5/C8PPTQQ5p126Dy2GOPydatW+X48eMSFxcnTz75ZKbt+fv7a2bcMfowYcsd5zoiIsL6d8+ePaVEiRIO99umTRtNX1etWuWwjrsYjb9QvXr1bLU5ceJEzQdwkTsfjm2nzXTG7Nmzddtq1Kgh7777rt06EyZMMByn5fvvv3dqn/Xr1zf8MOnr62t3ZpCMlxvfvn1b8zq4a+jQoRIYGGi3z7ayctm3p/j6+krnzp1l7ty5cvLkSd0HV2elpqZK7969Dac6L1q0qN1bNu4yem06O/NOfmU7ZoS9MYyywrYte+NT5Cb5IaZ7Mp6LENMd8VZMJ57r5Zd4bnQrlrPS09Nl8ODBmpnxjJIxtq8DZx+3N4058Tx/I7EDhxx9MBAR3YeRjL9qGXHm3uQCBQpI3bp1reuZTaeeW/n6+krLli2t69OmTZMhQ4bIhQsXst12WFiYwzK258VeIHBFxl/V7v4ClZnsnutLly5pPlhlLOdIo0aNrH8fPnzY6XrZdfHiRd22MmXKZKvN+++/XwYOHKjZlpSUJCNHjnSpnXPnzsmZM2d0259//nnNeAu2/P395amnntJt37dvn1OvgxdffNHuY0a/8IloP1T98ccfhh+yGjZsaLfdBx54QDfQ4aZNmxz0NOfcvn1b1q1bJ3PmzJFvv/3W4a+ARq5fvy7t27c3TOpYLBaZO3euZopiI2XLltVti4yMdLkv+YntlRL2rrLICttfaB1dAZsb5IeY7sl4LkJMd4Y3YjrxXC+/xHN7iZ0nnnhCduzYIQkJCXL9+nVZtmyZ1KhRQ1cuJSVF3nvvPet6xsH273I04L69xI69AZGJ5/kbiR04VKlSJYdlbEfOVw5mf7D91cmeihUrWv8+f/68U3Vym0mTJmk+OE2fPl0qVKggTZs2lffee082btyYpS90FSpUcFjGduC7zM7LlStX5Ntvv5V+/fpJs2bNpFq1ahIaGipBQUFStGhRKVy4sBQoUED++usvl/qZ3XN97tw5Tbk+ffqIxWJxask4WGVOzsJiNCtR6dKls93umDFjpHjx4pptP/74o0sD49m71N6ZgUSNPoDfunXLqRliMn4gt1WqVCnDD6EZB401+vAqcudDpL3z7+Pjo7t6MCYmRq5cueKwvznl1q1bsn37dnn11VelZs2acuDAAafrnjx5Uho1aiQbNmwwfPzzzz+X8PBwh+0YfUnJTccoN7K9wsDokv2ssm0rO7Ow5JT8EtM9Fc9FiOm5NaYTz/XySzyPj4/XbXv66aclIiJCmjRpIgEBAVKiRAnp0qWL7Ny5U+677z5d+TVr1liTv0a3LxolezKyl8Cxl/AhnudvJHbgkKP7P7PC2cvWMwa9W7duuWVKyJxWt25dWb9+veYNPz09XXbu3Cnjx4+XsLAwCQoKkrZt28o333zj9BcEd/1CnJycLMOGDZOKFSvKSy+9JHPnzpUdO3bIyZMnJSoqSmJjYyUxMVGSk5MdBiAj2T3XRvckZ0V2Lql1RWpqqmEgdsf5Cg4OltGjR+u2Zxy7weie+IyMPqSK3BnjxRF7H2adOUeZfRD29fXVfcDNyj6c5cpUxe7QqFEjUUpJenq6xMTEyB9//CHjx4/XfWH/999/5YknnnDqsukdO3ZI48aNDb/cFChQQL766isZMmSIU/0zem2640qAvCwoKEjzv+bMLSzOsn2tO7rtJTfILzHdU/FchJjuqpyI6cRz1+qK5K14npqaqplJTyklv/zyi+FsYUFBQTJ+/HjddqWU9coio9eNo6nI7T1u7zVIPM/fSOzAKwICApwqZ/vmmZWpHHODpk2byokTJ2TBggXy6KOP6oJ1UlKSrFu3Tl555RWpVKmSfPLJJznygTc5OVmeeOIJmTZtmsem1M3uubY3baSrcup2BnvHsXDhwm5p/7XXXtNdRbd792754YcfRMT4F6GMbty4Ybg9s4ErHZWx12ZGtlf12crssnER954/o1/hcoLFYpGSJUtKnTp1ZPTo0fL7779LSEiIpkxcXJy89dZbmbbz008/yZNPPmmYTAgKCpLVq1dL//79ne6X0XlVSnl8mm0z8/Hx0Yz3kXEcheyyHegy45UPuVV+ium5NZ6LENPdjXhujHhurEOHDobJuLs/wBgl6R0dC6PzERAQYPccEM/zNxI78Apn32AyXtJssVgcBpPczNfXV3r27Cm7d++WS5cuydy5c6VHjx66L3axsbHyzjvvSJcuXbL0a5or3nvvPdm5c6d1vWDBgtKnTx/58ccf5ffff5fTp0/LtWvX5MaNG3Lr1i1JS0uTBx980KV9ZPdcFytWTFNu3bp1ul9QnFnceatEVji6PdFZhQoVMpw9Y+TIkZKUlOTwA6e9gQmd+bBtr4yjX+fcwfZ1kB3OfHDNCZUrVzZM4qxatcruh9X58+fLc889Z/h/VatWLdm3b5+0adPGpX6467WZ3zRt2tT694ULF+Tff/91S7sZb8UoWbKk07e+eFN+i+m5MZ6LENNzCvE8e/JiPBe5c+yMBgK/OwC+0fg3KSkpmSZ3jK7Kyuy2TeJ5/kZiB17hbEDOeKltsWLFHF6W6khuyeyHhobKiy++KD/88INcuXJF9u/fLyNHjtQEhBUrVsjMmTM91oekpCTNbApBQUGyZ88emTdvnjz77LNSr149ue+++zT34/v6+rr84TS759o2SOb2GWLs/QqW1XEXjPTo0UMeffRRzbZz587JlClTHM4uYvvF4y5nBtezN0iovTbdyd44IwcOHHD5C0H37t093l9nNWjQQLctLS3NcNyLn376Sfr27Wv463/nzp1l165dmU5rbo/Ra9PMX7pzSvPmzTXrc+fOzXabx48f14yb0aJFC4e/frvCUzEwP8f03BDPRYjpnkA894y8Gs9FjG+duvs6ql69uuF7nu24U44eMxqo+S7ief5GYgdecezYMafKZfwF1PZy9Ixvjrdv33bqw4m7flF1J4vFIo888oh88skn8tdff0m1atWsj02cONFj+/3zzz81H7zeeecdh7NTpKSkuDzgZXbPtW0gPHLkiEv7z2m+vr6Gg9o5minOVZ999plu26effurw/+CRRx4x3L53716H+zQqExQU5HDWJXeoWbOm4fbcMgBrUlKSDB48WLp16yYtWrSQmjVrSnBwsOEUrRnZ+9Jue4vK9u3bpXfv3oZJnf/85z+ybNmyLI+HZvTadOcsT3lVt27dNMdp1qxZ2U40/Pe//9Ws9+nTx27Z3BQDiel3eCueixDTPYF47hm5PZ6LiHz55ZfSq1cvadWqlTz88MNSunRp6datW6Z1oqKiDK++uTsmUfHixeX+++/XPf7nn3/abdNo9jfbRGBGxPP8jcQOvGLbtm0Oy6SkpMjBgwet69WrV9c8bvtLiqNffdLT0+W3335zoZc5795779UMpnf+/HmPXWZ66dIlzXpmsxzctXLlSpfvj8/uuS5RooTmw/Hq1atd2r833HPPPbptUVFRbt1H06ZNpWvXrpptN27ckBkzZmRar0KFCoYz3S1atCjTaU6vXbsma9as0W1v3rx5tn91d8aDDz5o+OulM6+vnFC4cGH5+eefZenSpbJ161Y5duyYXLt2TX799ddM69mOp3JXaGio9e+YmBh59tlnDW+BGDdunMyYMSNbV3XYvheIuGfWl7wuODhYM+1vVFSUDB06NMvt7d69W3NVx4MPPiidOnWyWz43xUBiul5OxnMRYrqnEM/dL7fHcxGREydOyMKFC2XDhg1y+PBhuXLliqxduzbTQbtXrlxpuL1x48bWvzt27Kh7fP369Yb1YmNjZdeuXbrtnTt3ttsH4nn+RmIHXrFo0SKHA4YtX75cM5J7y5YtNY/bzsyQ8UOEkWXLlsnZs2dd6md274mfMWOGhIeHS6VKlWTRokVO1bGdqtCdl+Fn1q6jD5yxsbEycuRIzTZnLkd2x7nO+OXm8OHDEhER4XC/ycnJUqdOHenWrZvMmzcvx2bFEjGekeLixYtu38+ECRN0A1RmHF/BHqOBdU+fPi3jxo0zLJ+eni7/+c9/DH8JGjBggJO9zR6LxWL4YWbWrFl2Z8VYs2aNFC1aVCpXriyNGjWSTp06aWYcERFZu3at4dSq27dvd7mPHTp00G3btm2bfP/994blExMTZfr06brtJUuW1HzxGTx4sOHrZ8CAAfLuu++63E9bRm0bjQUAvVGjRmli0dy5c+XDDz90uZ2jR49K165drVdkWSwWmTBhQqZfsjwdA12Jf2aI6Xk5nhu1TUx3D+K5+5khnj/99NO6bQkJCTJq1CjD8pcvX5YxY8botoeGhmqusHn++ed1ZRYvXiyXL1/Wbf/iiy90t3bVr19flxTPiHiev5HYgVdERUXJkCFD7A7yFR0dLSNGjLCu+/r6ylNPPaUp88ADD2jWZ82aZXd/R48elcGDBzsciM7X11eznt3LQnfv3m398Dl69Gg5ffq0wzpLliyx/l2uXDmnZ6BwVcbpWkVEli5darfsxYsXpW3btnLt2jVp2LChdbszl8G741wPGDBA86G1X79+cvz4cbv7TElJkZdeekkOHTokS5culf79++foQIsZv5TflVl/s6pKlSoyePBgl+sNGjRISpUqpdv+4YcfyssvvyyHDh2S5ORkiY2NlfXr10urVq1k8eLFuvL169eXtm3bZqnvWTF8+HDdF92EhARp1qyZfPvtt3LlyhVJTU2V8+fPy/Tp06VHjx6SmJgoZ86ckT179siqVas8ep/5oEGDDL+I9+3bV9588005deqUpKamSmRkpPz8889Sv359w+nKu3btan0v2rt3r+GxL126tOHl+1lh9NqsWrWqW9rO68qVKyfffvutZtuYMWPk+eeftzuGRUZKKfnuu++kefPmmg/kb731lmGiMCN3x8DsxL/cGNPzUzwXIaZ7CvHcM3J7PG/RooXhwPWzZs2SZ599Vo4ePSopKSkSHR0tCxculEcffdQwqfL2229rZjerW7euPPbYY5oyCQkJ0q5dO9m+fbvcunVLrly5IhMnTjT8kWD48OGZ9pt4ns8pZFtsbKwSEYdLeHi4t7uqZs6cqenTtm3bdGVWrVqlKXPmzBmH7drW+fvvvzWPz507V/N49+7dlYio5s2bqxUrVqgrV66olJQUdenSJfX999+rihUrasr36tVLt8/U1FRVunRpTbnevXur/fv3q8TERJWcnKyOHTumxo0bp4oVK6Z8fX3V+PHjrWV9fX0Nn0vRokWtZUqXLq127typkpKSVFRUlDp79qxzB/r/27dvn7JYLNb2SpYsqcaPH6/27dunYmNjVVpamkpISFDnz59Xv/76q3r66ac1z+edd97x2HlJT09X5cqV0zw+ePBg9ddff6lbt26pa9euqV27dqm3337bekxmzpypBg0aZC1vsVjUokWL1K1bt1R8fLzHzrVSSo0YMUJTLiAgQI0ZM0YdPnxYJSQkqPj4eHXs2DE1c+ZMVatWLU3ZQYMGGbY5depUTbmIiAgXzq59EyZM0P3/P/jgg5nWmT17tq7OgAEDHO7r2rVrKigoKNP3nhEjRujqRUREaF6bri7FihVT//zzj2G7RuWvXr2a6fMIDg7W1Zk5c6au3PDhw7Pc58qVK1tfp476a/Te6IwBAwZkuX93X9fnz5+3ttevX79stefMe0aVKlV0ZadNm5al5+9OO3fudPiczp075+1uKqWUmjZtmvLx8dGdy969e6ulS5eqEydOqLi4OJWUlKTOnz+vdu7cqT744AP10EMP6Z5Tz549VVpamsN9eiIGOhv/zBLTc2s8V4qY7u6YTjwnnrs7nm/dulX5+vpmuY9NmjRRycnJunYPHjyYpXZbtmzpsM9mjOetW7f2dvfyip9I7LgBiR3XEzv//POPKl68uFPHrVy5cury5cuG+508ebLTb4jvvPOO2rBhg3XdYrEYthkWFma3jTfeeMPxQbYxatSoLAWE2rVrq8TERLvH2B3nxfb1kNnSvXt3dfv2bfXdd98ZPv70008rpTx3rpOTk1W7du1cPo716tVTCQkJhm166oPgxo0bdf3w9fVVsbGxdutk9YOgUkpNmTIl02Ng9EFQKaW+++475efn5/IxDQkJUdu3bzds09MfBFNSUtRTTz3lcp9DQ0PVn3/+6XR/s/pBMCUlRXXs2DFL//N+fn5q3bp1mvZ69uyZpbaMFqP3jOjoaMMvBPbOb04yU2JHKaWWL1/u9Hud0eLr66s++ugjl/bp7hjobPwzS0zPrfFcKWK6u2M68Zx47u54rpRSX3/9tS5p7+zr9MqVK3bbdeV/VURUtWrV1IULFzLtq1njOYkdt/mJW7HgFWXKlJGIiAiHA3rVqFFD1q5dqxlINKNhw4bJCy+84HB/b775pnz00UeakeGVUrqZZ0TuzCThzvvgP/roI5k0aZLdaTON9OjRQ7Zs2eLxkewHDhzo1KW/ffv2lUWLFomPj4907drVpft13XWu/fz8ZOXKlfLWW285dfmtxWKRfv36yaZNmzx6+buRpk2b6s737du3ZdOmTR7Z3+DBg7M0zXXv3r1l27Zt0qRJE6fKWywW6d69u+zbt0+aNm3q8v7coWDBgrJixQoZO3as0+e1ffv2sm/fPqlVq5bT+8nqe8Dd/k2ePNnulK5GGjRoIPv27ZPWrVtnab9ZtX79et0tFcWKFct01g0Y69y5s5w+fVreeOMNh7f9ZuTj4yPPPfecHD16VN555x2X9unuGJjV+JdbY3p+iucixHRPIJ57Tm6P5yIir7zyimzYsMHp25mKFCkib7zxhmzfvt1w4O27Bg4cKPPnz5fg4GCHbbZp00Y2b95sON5TRsRzFHBcBHC/27dvS+PGjeX48eOyYMECWbx4sZw6dUquXr0qwcHBUq1aNenRo4f06dMn0w9DPj4+Mn/+fOnRo4fMnTtX9u7dK1FRUZKeni6lS5eWli1byvDhw+Xhhx8WEdFNB5yYmKgbrO7xxx+XiIgIGTdunBw4cEDS0tIkKChIatasqbsv1hkWi0XefPNNefHFF2XBggWyceNG+fvvv+XKlSty8+ZNKVSokAQFBUmNGjWkSZMm8txzz+nGGvCk6dOny9NPPy1ff/217N69W6KiosTHx0fKli0rTZs2lZdfflnzvAMCAmT9+vUydOhQ2bFjh6SlpUmZMmXsBg53nWsRkQIFCsjEiRNlyJAhsmDBAtmwYYP8888/EhMTI+np6VKiRAmpXr26NG/eXHr37m14b3xOKFSokLRo0ULWrl2r2b5mzZpMZzPIKj8/P5kwYYKEh4e7XLdhw4ayY8cO2bJli6xevVq2bNkiFy5ckJiYGClYsKCUKlVKKleuLE8++aR07tw5R1+b9vj4+MiYMWNk8ODB8v3338tvv/0mR44ckejoaElJSZHixYtLpUqVpFmzZtKrVy+7U8JmJqtTh4vc+Z9/4403ZMCAAbJ48WLZtGmT7N+/X6KjoyU2Nlb8/PykRIkSUqVKFWnQoIF06dLFax+sjWZGefLJJzVjAsB5JUuWlMmTJ8vo0aNlxYoVsmnTJvnzzz/l3LlzEh8fLz4+PlKqVCkJCQmRmjVrSuvWraV169YOP7Db4+4YmNX4l1tjen6L5yLEdHcjnntWbo/nInfeR44fPy6rVq2S1atXy+7du+XSpUsSFxcnAQEBEhwcLLVq1ZInn3xSevTokWlCJ6MXXnhBOnToIN99952sWbNGjh07JlevXpUiRYpImTJl5LHHHpPw8HBp1aqVU+0Rz2FRtqk9uCwuLs5w2j5b4eHhmoH08pN58+ZJ3759revXr1936pjBfDjXd8yfP1/69Omj2VaiRAm5fPmyRwf8Q9ZVrFhRzp07JyIiZ8+elQoVKni5R5518+ZNCQ0N1c1ws3jxYunevbuXevU/u3btcvjr87lz56R8+fI51CPcxft8/sG5Jp6bEfH8DjPE89atW8u6detyuEd50hJuxQIAD+jatavuV6LY2Fj55ZdfvNQjZCYxMVEiIyNFRMTf3z/LV1CYydKlS3UfAosXL66ZihgA8jviubkQz+8gnuc/JHYAwAMCAgLk5Zdf1m2fMmWKF3oDR1atWiXp6ekiIlKvXr18cemy0Wuxf//+Lo0PAwB5HfHcXIjndxDP8x8SOwDgIcOHD5eCBQtqtu3du1c2b97snQ7Bri+//NL6tyfGTchtIiIi5NChQ5ptfn5+MnToUC/1CAByL+K5eRDPief5FYkdAPCQ8uXLy8CBA3XbR4wYoZu5AN6zatUq2bZtm4jcuWzbmVl5zCw9Pd1w9qVXX301X1yyDgCuIp6bA/H8DuJ5/kRiBwA8aOzYsbppr/fu3Ss//PCDl3qEjKKioqR///7W9XfffVdCQkK82CPPmz9/vhw8eFCzLTg4WN577z0v9QgAcj/iee5GPL+DeJ5/kdgBAA8qWbKkTJw4Ubf9jTfekOvXr3uhR8jonnvukUuXLolSSpRSMmrUKG93yaOio6Pl7bff1m3/7LPP8t1MNwDgCuJ57kY8v4N4nn+R2AEAD3v55ZclLCxMs+3y5csybNgwL/UI+dXrr78uV69e1Wxr27atbipfAIAe8Ry5BfEctiyKG0OzLS4uzqnMaHh4uCxZsiQHegQAgLnt2rVLmjRpkmmZc+fOSfny5XOoRwAAwFWZxfPWrVvLunXrcrhHedISrtgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAGu5GnAAAIABJREFUAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADCpAt7uQH5y9OhRGTt2rLe7AQBArhcZGemwzNSpUyUwMDAHegMAALLCmXiO7LMopZS3O2F2cXFxUqJECW93AwAAAAAAU2jdurWsW7fO293IC5ZwKxYAAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgU0527QZEiReSzzz7zdjcAAMD/N3r0aElKStJse/TRR6V79+5e6hEAAMioUqVK3u5CnsF05wAAIM8pXry4xMfHa7a9/PLLMnv2bC/1CAAAwCOY7hwAAAAAAMCsSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAD8P/buOzqK6n38+LOpJCEhIYSA9F6kKh1EQHqTDgKCKFUExA8qRREpSvtSFASkWmgCIh0ERJEqiICAIEWalBAgkABp5P7+8LC/zO5sS3az2fB+nXPPyczee+fO7GTv7LMz9wIAAHgoAjsAAAAAAAAeisAOAAAAAACAhyKwAwAAAAAA4KEI7AAAAAAAAHgoAjsAAAAAAAAeisAOAAAAAACAhyKwAwAAAAAA4KEI7AAAAAAAAHgoAjsAAAAAAAAeisAOAAAAAACAhyKwAwAAAAAA4KEI7AAAAAAAAHgoAjsAAAAAAAAeisAOAAAAAACAhyKwAwAAAAAA4KEI7AAAAAAAAHgoAjsAAAAAAAAeisAOAAAAAACAhyKwAwAAAAAA4KEMSinl7kYAAADY8s4778i6devsynvx4kVJSUnRrAsODpaIiAi7ys+bN08aNmzocBsBAAAy2CoCOwAAwCOsXbtW2rVr5/LtBAcHy82bNyUgIMDl2wIAAEinVTyKBQAAPELz5s0lNDTU5dtp27YtQR0AAOAxCOwAAACP4O/vnyF37HTt2tXl2wAAAHAWAjsAAMBjvPLKKy6tPyIiQl566SWXbgMAAMCZCOwAAACPUb9+fcmTJ4/L6u/UqZP4+Pi4rH4AAABnI7ADAAA8hre3t3Tu3Nll9bv6jiAAAABnI7ADAAA8iquCLwULFpRatWq5pG4AAABXIbADAAA8SvXq1aVEiRJOr7dr165iMBicXi8AAIArEdgBAAAexxWPY/EYFgAA8EQEdgAAgMfp1q2bU+srU6aMVKhQwal1AgAAZAQCOwAAwOOULl1aKlas6LT6nB0oAgAAyCgEdgAAgEdy5qNTrpxpCwAAwJUI7AAAAI/0yiuvOGWw4xo1akjx4sWd0CIAAICMR2AHAAB4pIIFC0rt2rXTXQ+DJgMAAE9GYAcAAHis9AZlvL29pVOnTk5qDQAAQMYjsAMAADxWx44dxdfXN83lGzRoIHny5HFiiwAAADIWgR0AAOCxIiIi5KWXXkpzeR7DAgAAno7ADgAA8GhpDc74+/tL27ZtndwaAACAjEVgBwAAeLS2bdtKQECAw+VatGghoaGhLmgRAABAxiGwAwAAPFpwcLC0bNnS4XI8hgUAALICAjsAAMDjORqkCQ4OlhYtWrioNQAAABmHwA4AAPB4zZs3d+ixqrQ+vgUAAJDZENgBAAAez9/fX9q1a2d3/q5du7qwNQAAABmHwA4AAMgS7H0cK71TpAMAAGQmBHYAAECW0KBBA3nmmWds5uvcubP4+PhkQIsAAABcj8AOAADIEry8vKRDhw428zEbFgAAyEoI7AAAgCzDVtCmYMGCUrNmzQxqDQAAgOsR2AEAAFlGjRo1pESJEhZf79q1qxgMhgxsEQAAgGvxgLkTxMfHy4gRI9zdDAAAICJhYWEWX7ty5YoMHTo0A1sDAAD0lC5dWvr16+fuZmQJBqWUcncjPN29e/ckNDTU3c0AAAAAAMAjNG7cWLZt2+buZmQFq3gUCwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAAAAAAAA8FIEdAAAAAAAAD0VgBwAAAAAAwEMR2AEAAAAAAPBQBHYAACIiUqdOHVFKmaWjR4+6u2kAUvH19ZVdu3YZ/0cvX74skZGR7m4WMoEOHTpISkqK8dx466233N0kAEAGILADAADgQebOnSv16tUTEZGHDx9KmzZt5ObNm+5tFDKF1atXy9ixY43LM2bMkKZNm7qxRQCAjEBgBwAApFuNGjVkypQp8ssvv8i1a9fk4cOHEh8fLzdu3JA///xTlixZIm+88YaEhIQ4dbsBAQFy5swZ3bvNlFJSpUoVq+V//vlni2UdSR988IFT98uSwYMHy+uvv25c7t+/vxw5ckSTp3fv3na1OSUlRe7duyeXLl2So0ePypo1a+T999+XBg0aSEBAQIbsD5zv448/lk2bNomIiLe3t6xcuVKKFi3q5lYBAFxKId1iYmKUiJBIJJJHpzp16uh+xh09etTtbSNl3lSzZk115MgRu/vMuLg4NWXKFBUQEOCU7U+fPt3q9qpUqWK1/NGjRx3q8y354IMPXH6sy5Urp+Lj443bXLNmjW6+3r17p3t/7t69qz777DNVrlw5t59jJMdTnjx5VHR0tPH93Ldvn/L29nZ7u0gkEil1aty4cbr7KyillPqOO3YAAECaDBkyRPbu3SuVK1e2u0xQUJAMGzZMjhw5Innz5k3X9l944QUZPHhwuuoIDQ1NV/mM4uvrK0uXLhV/f38REYmOjpZ+/fq5bHuhoaEyaNAgOX78uMyePVuCgoJcti04340bNzTj69SsWVOGDx/uxhYBAFyJwA4AAHBYv379ZMaMGWIwGNJUvnTp0rJ161bx8fFJU/mgoCBZvHixeHml71LGUwI7AwcOlAoVKhiXx4wZI9HR0XaV3bZtmxgMBrPk5eUlYWFhUrRoUXnppZfkgw8+kB07dohSyljWYDDIm2++KcePH9dsH5nfihUrZO/evcblUaNGSYECBdzYIgCAqxDYAQAADilVqpRMnz493fVUqFBB+vbtm6aykydPlmLFiqVr+waDQYKDg83W79ixQzcQYi2NHz8+XW2xJjw8XEaPHm1cPnPmjMybNy/d9SqlJCYmRv755x/56aefZMKECdKoUSMpUaKEfPHFF5oAT9GiReXHH3+U4sWLp3u7yDj/+9//jH8HBATIpEmT3NgaAICrENgBAAAOGTFihMXBdZcsWSLPP/+8ZMuWTSIiIqROnTryww8/WKyrR48eDm+/QYMGMmDAAM26u3fvOlxPSEiI7h0/MTExDtflSkOHDpWwsDDj8oQJEyQ5Odll2zt//rwMHDhQmjRpIlFRUcb1kZGRsn37dsmZM6fLtg3nOnjwoGzdutW4/Morr0jZsmXd2CIAgCsQ2AGALCwoKEhee+012bp1q1y4cEEePXokt27dkj/++EPmzp0rVatWNeZN/et8Wvn7+8srr7wiX375pRw7dkxu3rwpiYmJEh0dLSdOnJDvvvtOunTpYvd4HaGhobqz+WzcuFGTLzw8XEaMGCF79+6VO3fuSGJioty4cUMOHDggI0eOlNy5czu8L35+fvLyyy/LnDlzZN++fXLt2jWJi4uT5ORkiYmJkTNnzsgPP/wgQ4YMSdfjDc4+Zq4WHBwsnTt31n1t2rRp0qtXLzly5IgkJCRIdHS07N27V9q2bWvxDpOqVauKt7e3Q9tftGiR5hGw2NhYWbRokWM7IpYfw8pMgZ2AgADp37+/cfnmzZuycuXKDNn29u3bpXnz5vLgwQPjusKFC8tHH33kUD1hYWEycOBAWbVqlZw7d05iYmIkPj5erly5IocPH5ZZs2ZJ/fr17T4PQkJCNJ8HX375peb1Ro0ayTfffCNnz56VBw8eSGJiokRFRcmePXvk448/dnhsp4CAAOnUqZMsWbJEjhw5Irdu3ZL4+HhJTEyU27dvy9GjR2Xp0qXSo0ePNP+fOvsYpfb5559rlt9+++00tREAkIm5Z9DmrIVZsUgkUmZMdevWVRcvXrT5GbZkyRLl7++vqlevrvu6PbNiGQwG9fbbb6ubN2/a9bl5/fp11alTJ5v1+vj46Jbfu3evMU+HDh1UTEyM1e3duXNHdezY0a7j5uXlpQYMGKBu3bpl174opVRiYqL68ssvVY4cOex+f1x1zFyd6tevr9u+6Oho5efnZ7FciRIlLO5bRESE3dufP3++WfmhQ4eq8ePH69ZtbVasihUr6paZMmWK24/zk2Q6w9XYsWMdLrN169Z0teGVV17R1JeYmKhKlixps5yvr6+aMGGCio2Ntfjep3bkyBH13HPP2azX9HNh2bJlSkRUeHi42rJli83tPHr0SHXp0sWufe/SpYu6du2aXe1X6r//g759+9p9bF11jFIng8Ggzp8/r9n/0NBQt5/bJBKJxKxYTvMdgR0nILBDIpEyW2ratKlKSkqy+3Ns06ZNaQ7sZM+eXW3evDlNn5+TJ0+2uS+JiYlm5U6dOqVERHXu3FmlpKTYta3k5GTVqlUrq9vy9fVVK1asSNO+KKXU+fPnVaFChWzuk6uPmSvTCy+8oL7++mu1adMmtX//fvX333+r6OhotXr1aqvlgoKCLO6TvVOfN2nSxKzsgQMHlLe3t5o2bZpu3dYCO3Xr1tUtM2rUKLf/Dz9J27dv17TNnunHnR3YMRgM6vDhw5o6FyxYYLVMWFiY+vXXXy2+55YkJyertm3b2mzT48ePjWXWrVungoKCHJq6/vHjx6p27dpWtzF48GCH2//EuHHjbO6Dq49R6jRp0iRNHT179nT7uU0ikUgEdpyGwI4zENghkUiZKRUpUsTuX39T++qrr3TXWwvseHl5qfXr16frM3TYsGFW9+f+/ftmZa5cuaKKFi2q4uLiHNrWtWvXVHBwsMVtjR07Nl37opRSJ0+eVP7+/m49ZpkxPffccxaPlz3lQ0ND1dWrVzVlHz58qEqVKqVERM2YMUO3fmuBndatW+uWGThwoNuPl4ionDlzagK0Z8+etaucswM7Iv/dGZfavXv3lK+vr8Vz3PTOmeTkZDVv3jxVt25dlSNHDuXn56cKFiyounXrpg4dOqTJGx8fr2rWrGm1PfHx8cb827ZtU59//rlSSqnY2Fg1btw4VaFCBRUYGKgCAgJUyZIl1bBhw8w+Sw4ePGix/lKlSqmEhARj3pSUFLVw4ULVsGFDFRkZqfz8/FRgYKAqVKiQ6tSpk/r+++/NzqMaNWpYrD8jjlHqZBq437Bhg9vPbxKJRCKw4zQEdpyBwA6JRMpMafny5RY/r3744QdVs2ZNFRgYqEJDQ1WbNm3U8ePHlVLK4p0v1gI7w4YN0y0TGxur3nnnHVW4cGHl6+ur8uTJo3r37q1u3LhhlvfRo0eqSJEiFrdx584dszLR0dFq1apV9nxEm+nfv7/udkJDQzVfFp+4evWq6tOnjypevLjKli2b8vX1VZGRkapt27bq4MGDutt499133XrMMlvy8/NTP/74o8PHKnXSCzwOGjTI+HpaAjs9evTQLdO1a1fl5+enXnvtNbV+/Xp19epVFR8fr+7evavOnDmjvvnmG9WlSxeLgQ1npfbt22vaNWvWLLvKuSKwExISYnYXoKXAhemdLvfu3bN6d4yXl5cxMPPEkSNHlMFgsFjm4cOHxry3bt1SKSkp6vz586po0aIWy7z44otmn3OWHimbPHmyJt+bb75p8xh1795dU7+1u9gy4hilTgaDQfNZ+vDhQ+Xj4+PS85dEIpFsJQI7TkNgxxkI7JBIpMySChUqZDFA8+233+qWyZ49u/r9998tfsZZCuwEBwer6Ohos/yJiYkWv/AVKVJE3b592+62iYjuNlJSUoz7eeTIEdW8eXMVEhKiQkJCVPPmzdWpU6cs7s/27dt1t9O1a1fd/NWrV7fYtqCgIHXkyBGzMqdPn3brMcsMKSQkRJUqVUoNHjxYnThxQvfYHjlyxOrdTU9Sq1atzMru2LFD86U2LYEdS4/aTJo0ya7xqS5cuKDatGnjsmM4ZcoUzfa6d+9uVzlXBHZExOyxIb07m/z8/MzurGrZsqXNur28vNSePXs05dq3b28xv+ndeomJiapixYo2t7Nz5067jumuXbuMeR49emR3EGTZsmXq0qVLavfu3WrOnDm6eTLqGJmmrVu3aso6OlYPiUQiOTsR2HEaAjvOQGCHRCJllvS///1P93MqLi5OhYeHWyxXuXJli59xlgI7Q4cO1c2/cOFCq23Uu2PlwYMHKigoSDe/XiDkiZ9++kk3MBAeHq6uXLmiW+b27du62xk1apRufmuPbon8FxCKjo5Wx44dU5s2bVLz5s1TH374oe5Awhl1zNyVatSoYfG9MrV7926VK1cum3XmzJlTXb9+XVM2JiZGFShQQJMvLYGdDz/80O72WpKSkqJGjBjhkuP5yy+/aLZVvHhxu8q5KrCzZMkSTb1Tp041y9OpUydNHkuBVL1keoG/cuVKi3lNAztff/21Xdsw/T+3NBj1sWPHjHni4uKc+r5m1DEyTWPGjNGUHTBggEvOWxKJRLI3Edhxmu+Y7hwAspBGjRrprl+/fr3cvn3bYrk//vhDDhw44NC22rVrp7v++++/t1ruu+++M1sXGBgozZs3d2j7Dx8+lB49ekhCQoLZa7dv35aJEyfqlsuZM6eEhYXZvZ3u3btbfX3ZsmWSK1cuqVixorRo0UL69esn48aNk8TERLO87j5mmcHhw4elR48e8uKLL0p0dLTN/LNnz5Y8efJo1g0ePFiuXLmS7rZYmu7cEQaDQT755BPp1KlTuusyVapUKePfSUlJcuHCBadvwxGm71fOnDnN8jRo0ECzvHTpUrvr37Fjh9y9e9e43KxZM7un9162bJld+f755x/Nco4cOXTzRUVFGf8OCgqSVq1a2VW/Pdx1jP7++2/NcsmSJe3eLgAgcyOwAwBZSLly5XTX79q1y2bZLVu22L0dHx8fqVKliu5rZ86csVr28uXLcu/ePbP1VatWtXv7Iv8FO65evWrx9Y0bN1p8Te/L3KVLl3Tzzp49W9auXSsdOnSQXLlyOdTG1DLDMXOn+/fvy/Tp0+Xdd9+VpUuXilLKZpn27dtLly5dNOvWrl0rX3/9tVPa5IzAzhPz5s2T4OBgp9WXLVs2yZ07t3H56tWrkpKS4rT608I0OBwYGGiWp27duprlPXv22F1/SkqK7Nu3z7gcHBwsxYsXt6vswYMH7coXFxenWdbbB5H/AiipLVu2TPr37y9+fn52bccadx0j06BWoUKF7N4uACBzI7ADAFlEUFCQ5MuXT/c1019q9Rw9etTubRUqVEiyZcum+9rZs2dFKWU16QVWypcvb/f2RUS2bt1q9fUrV65Y/CLs7+9vtm7z5s26d/8YDAZp06aNrFq1SqKiouT06dOyaNEi6dWrlxQpUsTu9maGY+ZOISEhMnToUNm1a5dcvXpVhgwZIr6+vhbzR0REyJw5czTroqKipF+/fk5rk7XAzr59+6Rly5YSEREh2bJlk1KlSsnIkSPl/v37FutyZtvy5csnBoPBuOyMO5TSyzQIkpSUZJYn9f+EUsrhdpt+VpUpU8ZmmcTERM1dLLbyppb6GKc2b948uXjxonE5e/bsMmfOHLl27ZosWbJEunXrJnnz5rVrm6bccYxEzIPXBQoUcGi7AIDMi8AOAGQR1h4vunHjhs3y9uR5wvTRGGdwJEgiIvLXX39ZfT0lJcXioz56X+bu3LkjEyZMsFqnwWCQUqVKSa9evWTRokVy4cIFuXTpksyZM0eqVatmtWxmOGaZRd68eWXGjBmyfft2i4/CzJkzRyIiIjTr+vbtK7du3XJaOyxte8GCBVK3bl3ZtGmTREdHS0JCgvz999/y6aefSp06dSQ2Nla3XPv27Z3WtpCQEM2ypYBSRgoPD9csmx6HgIAATfDSYDBIfHy8zaBl6jR06FBNnfYETyy9H+kRExMjLVq0MAuGhIeHS8+ePeXbb7+Va9euyV9//SWzZs2Spk2bio+Pj8163XWMRMyPkzPvMAMAuBeBHQDIIqxdpD98+NBmeUe+HAUEBNid116OfsnQezTJlKNf+CZMmCCzZs1yqEzBggWlf//+cvDgQVm/fr3FL1mZ4Zi52oEDB8RgMIjBYJDg4GApXLiwtGrVSpYvX6776NWLL74o3377rdn6V155xSxIsmTJElm3bp1T29uwYUNje1OnPn36yOPHj3XL/PnnnxbHb6patapkz57dKW0zvTvGnv9hV4uMjNQsm95p4sxH255w5zl+6tQpqVy5ssyYMcPi8S9durQMHDhQtmzZIjdu3JCPP/7YLCiXmjuP0YMHDzTLlh5DAwB4HgI7AJBFWHqkQETsGs/E3gE4RcwfZ3AGa1+G9Fj64p0eKSkpMmjQIGnWrJkcOnTI4fKtWrWSQ4cOSbFixcxeywzHLCPFxcXJpUuXZOPGjdK1a1dp0aKF7jFo2bKlNGzY0LicJ08es+Da5cuXZciQIS5vs71Wrlypu97b21ueeeYZp2zD9HFBvccEM1qtWrU0y6ZjQ7nif9JZgbK0unv3rgwdOlSeeeYZ6dWrl6xZs8bi3VPh4eEyevRoOXv2rNSoUUM3jzuPUUpKiiQnJxuX9R5JBQB4JgI7AJBFWLs7xZ5fZh35ZdzaeBb58+fXvQvCVspMd59s3bpVqlWrJuXLl5f33ntPfvzxR7vvmMiXL5+sXLnSLNCW1Y+ZLVu2bJHFixfrvvbKK68Y/65Tp47ZbEsFCxaUe/fuWX08xVLg59ChQ5p8derUSfe+/PPPPxbHbzJ9XCmtTAM57v4SXqZMGbPHCffv369ZNr2L7tGjR2k6r1On0aNHu3zf7HHv3j1ZsmSJcRD1evXqySeffCKHDx82C5znzp1bfvrpJ7NA2JN6UsvIY+Tl5aV5XCwzBAsBAM5BYAcAsoiYmBiLr9kzBoMjA2neuXPH4mumj2t4shMnTsiUKVOkSZMmkiNHDqlataoMGjRIli5dKteuXbNY7vnnnzeb0vhpOWbW7N27V3d95cqVM7gl6ePt7S1eXvqXUM56ZMq0Hnc/NpM6+CYi8vvvv8v169c16xISEjTtDggIcMosUplNUlKS/PLLLzJq1CipWrWq5M+fXz766CPNjFsBAQEyd+5cs7LuPEZBQUGa5czweB8AwDkI7ABAFhEbG2txAORSpUrZLO/Il+t///3XbOrjJ1wxSHBmkJycLIcPH5ZZs2ZJ9+7dJX/+/NK4cWOLU5WnfrxIJOscs9GjR8v8+fNl3bp1sm/fPjl37pzcu3dPWrVqZbOspUcCTb9wZoQWLVrIzJkzZfny5fLTTz/JyZMn5datWzJlyhSbZUuWLGnxtaioKKe0LzMNdJs9e3Z56623NOuWLFmim/fkyZOaZXs+ezzdtWvXZOzYsVKlShVNALd8+fJSqVIls/zuOkam55ArBp0GALgHgR0AyEJMvzA8YXr3iB57vpinZvoYxhN6jx9kRUop2b59uzRq1Ej3sRy9qeezwjFr1aqV9O7dW1q3bi01a9aUYsWKSUhIiHTs2NFm2apVq+qud+ZMV/YqXLiwDB48WLp06SL169eXsmXLSq5cuaRLly42B7o2vXvliWvXrpndxZJWV69e1QTCChYs6JR602Ls2LGaWfeuXr0q8+fP181rOjZV7dq1Xdq2zOTMmTPyxRdfaNaVLVvWLJ+7jlGhQoU0y45Osw7INaFJAAAgAElEQVQAyLwI7ABAFrJz507d9a1btzabOjq1hg0byrPPPuvQtjZt2qS7vkePHlYfLWjatKncv39fzp49K3v27JHVq1fL7Nmzze5wyUh58+aVLl26yOjRo2Xp0qVy6NAhuXnzpl0z2Fy5ckV3WnW9xxyywjGzdI51795dWrdubbFciRIlpFevXrqvpb7rafXq1WkaZ2TmzJm6dVetWlWTb8+ePSIi8uOPP+rmz58/v0yePNniftSuXVv+97//6b5mqc60iI+P19z9kz9/fouPf7lS27ZtzabXHj9+vMXxWbZu3apZfvXVV13WNldp1KiRTJ06VXbv3i2//PKLQ2XPnz+vWdYblN5dx6hw4cKaZdOp3AEAHkwh3WJiYpSIkEgkkttTqVKlLH5WrVixQhkMBrMyERER6uzZsxbLHT16VHdbQUFB6s6dO7plpk+frlsmICBA/fbbb2b5U1JSVIUKFXTLREdH624jf/78No/HuXPndMuWLl1ak69q1aoO7UfqVKlSJZWSkmJWdsiQIW47Zq5M5cqV091fpZRKTk5W8+bNUxUqVFABAQEqe/bsqnz58uqDDz5QMTExumWUUqpt27bpbteMGTN0665SpYrFMrt377bYpm3btqmaNWuqoKAg5e/vr8qVK6cmTJig4uPjLZZ57rnnnHqsTdtXvHhxu8r17t1bU27r1q1p2v6rr75qtr8bN25UXl5eFst4e3urK1euaMq0a9fOru35+Pioffv2qR07dqgRI0ZYPZ5xcXHG+qOjo+3ep6ZNm2ratmDBArM8kydP1uSpW7eu3fWPHz9eU7ZevXpuO0amacyYMZptDhgwwKnnK4lEIjmaGjdubKlLhWO+I7DjBAR2SCRSZkqbN2+2+Hm1ceNGVaNGDRUYGKjCw8NVt27d1D///KOUUha/sB47dszitoYPH25xW6tWrVLVq1dXQUFBKjw8XDVt2lQdOHBAN++iRYssbiMjAjsioo4cOaKbd8WKFap169Yqb968KjAwUPn4+KiwsDBVuXJl9d5776moqCizMomJiSpv3rxuO2auTkuXLrW4D446ffq08vX1TXeb0hLYqVOnjsUglaNWrFjh9OM8depUzTa6detmV7n0BnYKFSqkFi9ebLaPp06dUiEhITbLv/nmm5py9+/fV3Xq1LFaJigoSC1fvlxTbu7cuRbzuzKwU6FCBc15cfnyZVWyZEmbdRcvXlzzeXX37l3l5+fntmNkmrZs2aIp6+xAJIlEIjmaCOw4DYEdZyCwQyKRMlOqXLmySkxMdPizzPTX3CdOnDhhcVteXl5q586d6foMPXv2rNUvixkV2Kldu7ZKTk5O17488eGHH7r1mLk65cqVy+pdXvZKTExU9evXd0qb0hLYETEPnqTFiRMnVHBwsNOPc4cOHTTb+fzzz+0q50hgx8vLS+XOnVuVL19e9e3bV61Zs0YlJCSY7eP+/ftVvnz57Nq+wWBQ27dv15RPTk5WX375papXr57KlSuX8vX1VXnz5lVVqlRRY8aMURcvXtTkv3nzpoqIiLC4DVcGdkRELVmyRJPvwYMH6rPPPlMvvfSSioyMVL6+viogIEDlz59f1a5dW40fP97srrSRI0e69RiZbu/27dvGsg8fPlQ+Pj4u/6wgkUgka4nAjtMQ2HEGAjskEimzpb59+zr0OfbVV1+pwoUL67527tw5q9sKDQ01+4Jir7/++stmgCajAjsiorp165amoFhqs2fPVt7e3m49ZhmRihQpoo4ePZrm4/Tw4UPVvn17p7UnrYEdg8GgZs+eneb92L17t8W7s9KbcubMqZKSkozb+vvvv+0qZxrYSY/Hjx+r2bNnW7zzxFLKkSOH2rVrV5q2GR0drapWrWq1flcHdgIDA9XBgwfTfNzWrl1rM3Di6mOUOlWrVk1TfsOGDS79fCCRSCR7EoEdpyGw4wwEdkgkUmZMPXr00Hz50ZOSkqJmzJihvL29Vfbs2XXzXLt2zea2fHx81MiRIy2OH2Pq0aNHatq0aSowMNBm3RkZ2BER9fzzz6v9+/fbtR+pnT592qGxYlx5zDIq+fv7qzFjxmjuBLAlJSVFbdq0ye7xYuxNaQ3sPEnt2rVz6C6k69evq2HDhrn8rgfTAOCzzz5rs4wzAjvJycnq22+/VWXKlElz2/38/NTHH3+sYmNj7d7u999/rwoVKmSzblcHdkREZcuWTc2cOVP3DiZL7t+/r95//32bwd2MOEap08SJEzV19OzZ06XnLYlEItmTCOw4zXcGpVLNpYk0uXfvnl0zpwBARsufP7+8/vrr0qpVKylUqJCEhIRIVFSUXLlyRbZu3SrLli3TzOISExMjOXLk0NTx4MEDyZ49u13bCwkJkXbt2slLL70kzz//vEREREhoaKg8ePBA7ty5I3/++afs2rVLli5davcU19HR0RIeHm62vkCBAnL16lWrZc+dOyfFihUzW1+mTBk5ffq01bLPP/+8tGjRQmrUqCFFihSRyMhICQoKEm9vb4mNjZWYmBg5ffq0/PHHH7J+/Xo5cOCAXftjyhXHLKMFBQXJyy+/LC+++KJUq1ZNIiIiJCwsTHx9feXevXvG/fjtt99k9erVcuHCBae3YcaMGTJkyBCz9VWrVpXDhw/bVYeXl5c0a9ZMmjRpIjVr1pR8+fIZp/m+ffu2REVFyYEDB+Snn36SjRs3Snx8vFP3QU/v3r01U4uPHTtWPvroI4fK2PLgwQO5deuW3Lp1S44fPy47duyQnTt3Ou18i4iIkHbt2kmjRo2kQoUKkitXLgkJCTGe4ydPnpR9+/bJypUrzWaVsiQuLk6CgoJE5L/3JleuXHaVa9q0qWzZssW4vHDhQundu7fVMvny5ZMOHTpI/fr1pVSpUpI3b14JCgqSlJQUiY2NlatXrxqP29q1ayU2NtautqTmimP0hMFgkL///luKFy8uIv/NuJY3b16JiYlxuJ0A4EyNGzeWbdu2ubsZWcEqAjtOQGAHAAC4QmBgoFy+fNkY3Lx+/boUKlRIkpKS3NwyeArTYNb8+fOlb9++bmwRAPyHwI7TrPJydwsAAACg7+HDhzJ37lzjct68eaVTp05ubBE8zaBBgzTLM2bMcFNLAACuQmAHAAAgE5s+fbrmsZkPPvhAfHx83NgieIqqVatKs2bNjMsrV66UU6dOubFFAABXILADAACQid2+fVvGjh1rXC5durT06dPHjS2Cp5g6daoYDAYR+W9snffee8/NLQIAuAKBHQAAPNzbb78tSimXpnPnzrl7N59qs2bNkhMnThiXP/74Y91BxYEnOnXqJHXr1jUuf/LJJ3L58mU3tggA4CoEdgAAADK5pKQk6datmyQkJIjIf7MopR57B0gtMjJSZs+ebVw+cOCAfPLJJ25sEQDAlQjsAAAAeIDjx4/L+++/b1zu0KGDdO/e3Y0tQmZkMBhk4cKFxingY2NjpXv37vL48WM3twwA4CoEdgAA8HAzZswQg8Hg0lS8eHF37yZEZObMmbJ48WLj8rx586Ry5cpubBEym9GjR0uLFi1EROTx48fSuXNnOX/+vJtbBQBwJQI7AAAAHqRfv37y888/i4hIYGCgrFu3TiIjI93bKGQK7du3l48++si4/Pbbb8uWLVvc2CIAQEZgrkwAAAAPkpSUJPXr13d3M5AJrVmzRry8+N0WAJ42fPIDAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChCOwAAAAAAAB4KAI7AAAAAAAAHorADgAAAAAAgIcisAMAAAAAAOChfNzdgKdJcHCw5M+f393NAAAg03v06JFcvHjRap4SJUqIjw+XMgAAZFb29OdIP66GMlCTJk1k1apV7m4GAACZ3v79+6VWrVpW8+zcuVMKFCiQQS0CAACOsqc/R/rxKBYAAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA4AAAAAAICHIrADAAAAAADgoQjsAAAAAAAAeCgCOwAAAAAAAB6KwA7gITZu3CgGg8GYLl686O4mwQGNGjXSvH8Gg0F69erl7mbhKdOtWzez87B58+bubhbw1KFP91z058gM6M9hisDOU2bu3LmaD4A9e/a4u0lAlrdgwQLZsWOHZl2ePHlk2rRpmjymHfSTtG7dOru3NXXqVLPyw4cPd9q+wLqLFy9afB/tTXFxcVa3cf36dfnkk0+kYcOGUqBAAQkICJDg4GApVqyYdOnSRb755htJTk7WLTtz5kyJiIjQrNuyZYt89dVXTjsGELlz546sWrVK+vfvL9WqVZOiRYtKSEiIZMuWTfLlyyeVKlWSDh06yJw5c+TcuXPubi4AO9GfP712794tgwYNkqpVq0pERIT4+vpKSEiIFCpUSJo1aybjx493OEBLfw6nUki3mJgYJSI2U4cOHdzdVDVnzhxNm3799Vd3NynTSUpKUgEBAUpE1Jw5c9zdHKMNGzZo3rt//vnH3U2CHW7fvq3CwsLMPg+WLVumyTd//nyLnx0lSpRQiYmJdm1vypQpZuXff/99V+wadPzxxx929QfWUmxsrMX6J06cqAIDA23WUapUKfXbb7/p1rFkyRKz/OHh4eru3buuOixpsm/fPpv7efnyZXc3U+Pq1atq4MCByt/f36H3vEmTJmr//v3ubn6m7f/SKjPvD32656E/fzodOXJEValSxa7Pci8vL9WrVy8VExNjs1768/9S48aN3d28rOI77tgBTJw8eVIePXrk7mYgixgzZozcvXtXs65atWrSpUsXu+s4e/aszJo1y9lNgwvExMS4rO53331Xhg8fLg8fPrSZ98yZM9KwYUM5ePCg2WuvvvqqVKpUSbPu9u3bMm7cOKe19Wn09ddfS/HixWX27NmSkJDgUNlt27ZJzZo1pX///pKUlOSiFtqW1fq/rLY/cC/686fPli1bpHbt2nL48GG78qekpMjixYulVq1aEh0dbTEf/TlcgcAOYMLeD2/AlsuXL8vcuXPN1k+aNEkMBoNDdY0bN07u3LnjrKbBRe7du+eSeleuXClTp051qMz9+/elQ4cOcv/+fc16Ly8v+eSTT8zyz5o1S65du5audj6thg8fLj179pT4+HjjuvDwcBkwYICsX79ezp07J/fu3ZP4+Hi5fPmy/Prrr/Lhhx9KqVKlNPXMmzdPGjZsaPaeZZSs1v9ltf2B+9CfP33OnTsnHTt2TFNw+NSpU9KnTx/d1+jP4SoEdgATXAjCWaZNm2b263u1atWkXr16Dtd19+5dGTNmjHMaBpfRu2OnYcOGopSyO2XPnl1TPjk5Wd5//32zeitUqCC7du2SuLg4iY6Olrlz50pAQIAmz9WrV2X69OlmZZs1ayYVK1bUrEtMTJQZM2akZbefavPnz5dJkyYZlw0GgwwbNkzOnz8vX3zxhbRq1UqKFSsmISEh4u/vLwUKFJA6derI2LFj5eTJk7JgwQIJCQkxlt+9e7e8/vrr7tiVLNf/ZbX9gfvQnz99Bg8eLA8ePDBb/9Zbb8nZs2clPj5ezp49K59++qkEBgaa5fvhhx/k1KlTmnX053AlAjuAid9//93dTUAWEBcXJwsXLjRb/84776S5zjlz5siZM2fS0yy4mF5gJywsLF11btiwQS5duqRZFxISIj/++KPUq1dPgoKCJDw8XPr16yf/93//Z1Z+7ty5uoMv6p2LX375JY+uOODUqVMyaNAg47KPj498/fXXMmXKFMmRI4fN8t7e3vLGG2/I7t27JU+ePMb1a9askdmzZ7ukzdZktf4vq+0P3IP+/Olz7tw52bp1q9n6AQMGyOeffy7FixcXf39/KV68uAwfPlw+++wz3Xq2bdumWaY/hysR2IGZxYsXG0ffL1mypHG9Ukp++OEHadKkieTOnVt8fX0lNDRUypcvL4MHD5azZ89arHPKlCnGOosWLWpcHx0dLaNHj5Zq1arJM888I/7+/vLMM89InTp1ZPr06VYfa5g4caKxTh8fH7v2bcaMGbplUs8WdujQIeP6AQMGaGYjSM+vf4mJifLdd99Jt27dpHz58pIzZ07x9fWVgIAAyZs3r9SpU0fef/99+eOPP+yq78mtv8nJybJw4UJp0qSJFC1aVLJlyyZhYWFSrlw5GTJkiJw/f96u+h4/fiybNm2SN954QypVqiTh4eHi5+cnQUFBkj9/fmnatKlMnjxZoqKirNbjivfa1LVr12TChAnSqFEjyZ8/vwQEBEhISIgUL15cWrRoIfPmzTN7Dl5P6vPBYDDoduJptWbNGrPZjUJDQ6VNmzZ211GrVi3NcnJysgwbNswp7TO1d+9eGTlypNSsWVMKFSokgYGBkj17dilcuLDUrFlTRo4cadcsegsXLjSbxaNJkybG15VSsnLlSmnRooVERkaKr6+vRERESI0aNWTixIkSGxtrd5vv378vc+bMkY4dOxrviMiWLZsULlxY6tevL5999pnN89XZXBHYWb16tdm6bt26SWRkpNn6Xr16SVBQkGbdjRs35NdffzXL26FDB7O7g+7duyfr169PV3ufJuPGjdOMpzN69Gjp3r27w/VUrFhRVqxYIV5e//+ybNy4cZpHu0w5qw9MS/+Xmft0T+zPRejT09un05//f/Tn6bd9+3ZRSmnWeXt76z72JCLy2muvib+/v9n6K1euaJbpz+FSbhixOcvJarNiLV261Ph6njx5lFJK3b17V9WqVcvq/vn5+amlS5fqbveLL77QjNaulFL79+9XuXPntlpngQIF1N69e3Xr/PTTT435vL297dr/6dOn65YxPS6W0qFDh+zajqkDBw6o4sWL2z1DSocOHcxG1DedQePKlSvq+vXrNkfq9/PzM5uxwdSff/6pKlWqZFfbgoKC1Pz58y3W5Yr3+omkpCT13nvvKT8/P5vtDA8PV4sXL7ZaX+rzQUTUli1brOZ3RJMmTcza1KdPH4v59WbRmDlzpipYsKDZ+h07dlisx9FZNA4ePKheeOEFu8/N2rVrW529Z/ny5WZlqlevrpT6b0aRevXqWa0/X7586tixY1aPbUpKipo6daoKDg622d6QkBCr56uzDR061KwN7733XrrqzJMnj1mda9assZi/cePGZvk/+OAD3byvvvqqWd6XX345Xe11lsw+K9aFCxeUt7e3sS1ly5ZVycnJ6apzwIABmv2zNpOTs/rAtPR/mblP94T+XCn6dKWc26fTn9OfO9NXX32lWrdurWrXrq1Kly6tIiIiVJUqVayWKVasmFmb3333XU0e+nPzxKxYTsOsWDDn5+dn/Pvhw4eSmJgoDRs2lH379lktl5iYKK+//rr89ddfZq+l/vUtLi5Orl69Ks2bN7cZfb9y5Yq0bNlS/v77bwf3IvP4+++/pWHDhnLu3Dm7y6xevVratGlj9mtBagaDQZo2bWrzV8fExETp0aOH2XO+T5w9e1bq1q0rR48etattDx48kD59+siSJUt0X3fVe52cnCwtW7aUyZMnS2Jios123r59W3r16iUTJ060mdfZ4uPj5ZdffjFb37x5c4fqiY2NlQkTJpitf+eddyQlJSXN7Xvim2++kRdeeEH31x9L9u7dK3Xr1pWvv/5a93W9X6zu379vfP9+/vlnq/X/+++/0qhRI7l9+7bu6ykpKdKpUycZNmyYXb8G3r9/X/r06SMff/yxzbzO4Ow7dq5fvy43btwwW1+2bFmLZcqUKWO2ztLnhN45uXPnTrfOzOQpvv/+e3n8+LFxefDgweLt7Z2uOt9++23NQKwrV65MV32u8rT26a7qz0Xo021xV59Of671tPTnPXr0kHXr1smePXvkr7/+kqioKM0dgKbi4+N1++rUY9/Qn8PVCOzAjK+vr/Hv+Ph4mTRpkvz+++9SpkwZWbp0qVy/fl2SkpIkOjpaNm7cKBUqVDDmT0hIkJkzZ5rVmfpiNyEhQd577z25e/eu1KpVS3744Qe5ceOGJCYmyo0bN2T58uVSvHhxY/67d+/KkCFDXLS3/+nfv78opcyeRZ0zZ45mUNMqVao4XPeoUaOMt/D6+fnJiBEj5NChQ3L37l1JTk6W2NhYOXfunCxbtkxzq+7PP/8sq1atsljvlClT5NixY1KqVCn56quv5Nq1a5KYmCi3bt2S77//Xp599llj3uTkZIsj8A8cOFBzi3OLFi1kw4YN8u+//0pCQoI8ePBAjhw5IkOGDNE8JvDOO+/o3mrtqvd6xIgRmmeVS5QoIV9++aWcOnVKHjx4IHFxcXL8+HH59NNPJTw8XFNu586dFo+jK+zdu9fsEQpvb2+pX7++Q/XcvXtXunXrZnbeHT9+XPd5f0ds3rxZevbsadcFtamkpCR57bXXZPv27WavpQ4MP3H//n2ZMmWK7N+/3676o6KiZOzYsbqvvfvuu7q3MtsyZswYWbt2rcPlHGUpsHP16lUZMWKEVKpUSXLkyCHZsmWTAgUKSPPmzeWLL77QHaBRRCw+dpE/f36LbdB7zdKjsg0bNjSb0SUuLk4OHDhgsX78J/WXGoPBIJ07d053nSVLltT8vx84cMDhqdMdlZb+LzP36Z7Yn4vQp2fWPp3+XOtp6s8dMW3aNLN+PCwsTFq3bm1cpj+Hy7njPqGsJqs9ipX69mCDwaCyZcumGjdurB4+fKhbZ3R0tMqZM6exTKFChczyLF682Ox4tGnTRiUlJenWGRMTo0qWLKnJf/z4cU0eZz6K9cSjR48027R2G7w9UlJSVGBgoLG+qVOn2izTvXt3FRkZqapUqaKmTZtmXG9627a/v79q2LChevDggW49t2/fVrly5dLcEmvq/PnzZu+JNRMnTtTk17sd3BXv9YULF5SPj4/x9WbNmlk8H5VS6urVq6pw4cLG/OXKlbO6X86W+tx8kp599lmrZfRu3R44cKBSSqlffvnF7LXIyEh1//59s3rsuXX7zp07mnMjderWrZvav3+/io2NVXFxcWrfvn2qQ4cOunnz5s1rdv5t3rzZLF9gYKDKkSOH8vLyUkOHDlXnzp1T8fHx6ujRo6pVq1a6dYeHh5udMydOnFBeXl5meStXrqw2b96srl+/rmJiYtTevXtVs2bNzPIVLVpUJSQkpOUttVv9+vXNttuiRQuVLVs2q/1Dnjx51Nq1a83q++6778zy+vn5WW3DkiVLzMoEBARYzK93+/j06dPTfSzSK7M/ihUeHm5sR9myZZ1Wr+njfBnxOLJSjvV/ntCnZ+b+XCn6dE/p0+nPn97+3JrHjx+rqKgotWPHDtWlSxez9nl5eanVq1drytCf6/fjPIrlNDyKBeuUUpItWzZZunSp2bR7T4SHh0unTp2My5cuXTIbZM5U9uzZZcGCBRYHSMyRI4dMnjxZs27jxo0Ott79YmJi5OHDh8Zl0+kI9XzzzTdy48YNOXTokAwdOtRivsDAQFm+fLnuFIsiIjlz5pQuXboYl//991+z9+Xff/+VF154QUqWLCkhISHy1ltvWW3boEGDNHd02TPjiDPe6+nTpxtnAYiIiJBly5ZZPB9FRPLlyydz5841Lp84cSJDp709duyY2Tp73ntTT/a5bt268vLLL2teu3nzpnz66adpat/cuXMlOjrabP3HH38s3377rdSoUUOyZ88uQUFBUrNmTVm1apXuuXH9+nVZtmyZZp3pr0Ui/z3See/ePZk5c6ZMmzZNihUrJv7+/lKxYkVZu3at2aCSIv/ddn/69GnNugkTJpjdsl64cGH5+eefpVmzZpInTx7JkSOH1KpVSzZv3iwtWrTQ5L1w4YLLf+XT+8V706ZNVgfBFflvQMT27dvLggULNOvv3Lljltd0gER7Xn/06JHFNqS+6/IJvXMY/19ycrLm8QK92+XTqly5cprl69evO61uV3ka+nRX9uci9OmZtU+nP9d6mvpzPQcOHBCDwSDe3t6SO3duadiwoaxYsUKT55lnnpH169dL+/btNevpz+FqBHZg02uvvSa5cuWymqdSpUqaZVuzF3Ts2FFza62eFi1aaD7Q9u7da6OlmU9ISIjmNuZNmzY5re7XX3/d5vtSvnx5zbJpp/LCCy/I7t275cyZM3Lv3j156aWXrNYXGBgoBQoUMC7rXUyYcsZ7vWXLFuPf3bp1k9DQUJvbbdKkiaatGzZssFnGWfTGXyhVqlS66pw8ebLmAlzkv4tj02kz7TF//nyzdaVLl5YPPvjAYplJkyZJzpw5zdZ/8803dm2zSsYsRfUAACAASURBVJUquheT3t7eFmcGSX278ePHjzXnwRNvv/22hISEWGyzqbTc9u0IvUex7JWSkiIDBw7UzKSjd/Fmeh7Y+7qlaU/1zk17Z955WpmOGaH3v5FWpnVZGp8iM3ka+nRX9uci9Om2uKtPpz8397T0547w9vaWNm3ayOLFi+XcuXNmgSgR+nO4HoEd2GTrwkBEzC5GUv+qpceeZ5N9fHykcuXKxmVr06lnVt7e3lKvXj3j8owZM2TQoEHy77//prvuhg0b2sxj+r5Y6ggckfpXtSe/QFmT3vf6+vXrmgur1PlsqVGjhvHv48eP210uva5du2a2Lm/evOmqs2TJktK/f3/Nuvj4eBk+fLhD9Vy+fFn++ecfs/Vdu3bVjLdgKjAwUFq2bGm2/tChQ3adB6+99prF1/R+4RPRBkn++OMP3aBJtWrVLNZbtmxZs4GLd+3aZaOl6WMpsNOgQQPZu3evxMXFyd27d2XNmjVSunRps3yJiYny4YcfGpdTD877hK0Bei1dCFoaQDFfvnxm665evWp1G0870zslLN1lkRamv9DaugM2M3ga+nRX9uci9On2cEefTn9u7mnpzx3x+PFj2bZtmyxcuFAWLVqkG8ShP4erEdiBTYULF7aZx3TkfGVj9gfTX50sKVSokPHvK1eu2FUms5kyZYrmwmnWrFlSsGBBqV27tnz44Yeyc+dOm49p6ClYsKDNPKYD31l7X27evCmLFi2S119/XerUqSMlSpSQyMhICQsLk+zZs0u2bNnEx8dHTp486VA70/teX758WZOvZ8+eYjAY7EqpB6vMyFlYbt26ZbYuT5486a73o48+khw5cmjWrVixwqGB8Szdam/PQKJ6F+CPHj2ya4aY1BfkpnLlyqV7EZp60Fi9i1eR/y4iLb3/Xl5eZncP3r59W27evGmzvWl1//59s3Uvv/yybNmyRWrVqiVBQUESGhoq7dq1k3379kmRIkXM8m/evNn4ZVHvcQe9i8PULF3wWbpA1PuS4spjlBWY3mGg9wheWpnWlZ5Z1TLK09Knu6o/F6FPz6x9Ov25uaelP3fUo0ePZM+ePfLWW29JmTJl5MiRI5rX6c/hagR2YJOt5z/Twt7b1lN3eo8ePXLKlJAZrXLlyrJ9+3bNF7iUlBTZt2+fjB8/Xho2bChhYWHStGlTWbBggd1fEJz1C3FCQoIMHTpUChUqJG+88YYsXrxY9u7dK+fOnZOoqCiJiYmRBw8eSEJCgs0OSE9632u9Z5LTIj2PyDgiKSlJtyN2xvsVHh4uo0aNMlufeuwGvWfiU9O7SBX575lwWyxdzNrzHlm7EPb29ja7wE3LNuzlyFTFjkpKStLMvKOUkh9++EF3dpGwsDAZP3682XqllPGXSL3zxtbUpZZet3QO6q13xp0AWVlYWJjmf82eR1jsZXqu23rsJTN4Wvp0V/XnIvTpjsqIPp3+3LGyIlmrP9dTo0YNUUpJSkqK3L59W/744w8ZP368WQD+4sWL0qBBA81jUPTncDUCO3CLoKAgu/KZfhlKy1SOmUHt2rXl7Nmz8u2330r16tXNOuv4+HjZtm2b9OnTRwoXLiyffvpphlzwJiQkSIMGDWTGjBkum1I3ve+1pWmgHZVRjzNYOo7ZsmVzSv2DBw82u4vuwIEDsnz5chHR/0UotdjYWN311gautJXHUp2pmd7VZ8rabeMizn3/9O6qcZcWLVroXrw/+TVa70u9rWOh934EBQVZfA/03lellMun2fZkXl5emvE+Uo+LlF6mA12mvvMhs3qa+vTM2p+L0Kc7G/25Pvrz/4JuOXPmlEqVKsmoUaPk8OHDEhERoclz7949effdd43L9OdwNQI7cAt7P2BS39JsMBhsdiaZmbe3t3Tr1k0OHDgg169fl8WLF0uXLl3MOoKYmBgZOXKktGvXLk2/pjniww8/lH379hmXfX19pWfPnrJixQo5fPiwXLhwQe7cuSOxsbHy6NEjSU5OlmeffdahbaT3vQ4ODtbk27Ztm9kdEfYkZz4qkRa2Hk+0l7+/v+7sGcOHD5f4+HibF5yWBia052LbUh5bv845g+l5kB72XLhmlBw5cugOHPpkwFy95+UTExOtXgzq/Ypr7TEPZ52bT5vatWsb//7333/l4sWLTqk39aMYOXPmtPvRF3d62vr0zNifi9CnZxT68/TJiv150aJFNUGcJzZs2GAMPtGfw9UI7MAt7O2QU99qGxwcbPO2VFsyyy/1kZGR8tprr8ny5cvl5s2b8vvvv8vw4cM1X/DWrVsnc+bMcVkb4uPjNbMphIWFycGDB2XJkiXSuXNnef7556VIkSKa5/G9vb0dvjhN73tt+qU3s88QY+lXsLSOu6CnS5cuUr16dc26y5cvy7Rp02zOLmL6xeMJewbXszRIqKU6ncnSOCNHjhxx+AtBp06dXN5eR+jdav3kPCpVqpTu557pOBW2XtMbqPkJvXPTk790Z5S6detqlhcvXpzuOs+cOaMZN+PFF1+0+eu3I1zVBz7NfXpm6M9F6NNdgf7cNbJqf161alWzdcnJycZxrOjP4WoEduAWp0+ftitf6l9ATW9HT/3h+PjxY7suTpz1i6ozGQwGee655+TTTz+VkydPSokSJYyvTZ482WXb/fPPPzUXXiNHjrQ5O0ViYqLDA16m97027QhPnDjh0PYzmre3t+6gdrZminPU//3f/5mtmzhxos3/g+eee053/W+//WZzm3p5wsLCpGjRojbLpleZMmV012emAVi/+OIL6d69uzRq1EgqVqwoefLkkY4dO1otExUVpftr3ZMxDHLkyCElS5Y0e/3PP/+0WKfebDGmXxxS0zs3nTnLU1bVsWNHzXGaO3duugMNn3/+uWa5Z8+eFvNmpj6QPv0/7urPRejTXYH+3DUye38eHx8vAwcOlI4dO8qLL74oZcqUkfDwcN0p11OzFIR/8hgi/TlcjcAO3OLXX3+1mScxMVGOHj1qXC5VqpTmddNfUmz96pOSkiI//fSTA63MeM8884xmML0rV6647DbT69eva5atzXLwxPr16x1+Pj6973VoaKjm4njjxo0Obd8dcufObbYuKirKqduoXbu2tG/fXrMuNjZWZs+ebbVcwYIFdWe6W7ZsmdVpTu/cuSObN282W1+3bt10/+puj2effVb310t7zq+McvbsWVm6dKns2LFDjh8/Ljdv3pStW7daHeRz/fr1uutr1qxp/LtVq1Zmr2/fvl23XExMjOzfv99sfZs2bSy2wfSzQMQ5s75kdeHh4Zppf6OiouTtt99Oc30HDhzQ3NXx7LPPSuvWrS3mz0x9IH26uYzsz0Xo012F/tz5Mnt/ni1bNvn+++9l9erVsnv3bjl9+rTcuXNHNm3aZLWc6fhoT0RGRhr/pj+HKxHYgVssW7bM5oBha9eu1YzkXq9ePc3rpjMzpL6I0LNmzRq5dOmSQ+1M7zPxs2fPlg4dOkjhwoVl2bJldpUxnarQmbfhW6vX1gVnTEyMDB8+XLPOntuRnfFep/5yc/z4cdmyZYvN7SYkJEilSpWkY8eOsmTJkgybFUtEf0aKa9euOX07kyZNMhugMvX4Cpb07dvXbN2FCxdk3LhxuvlTUlLkzTff1P0lqF+/fna2Nn0MBoPuxczcuXMtzoqxefNmyZ49uxQtWlRq1KghrVu31sw4IiKydetW3alV9+zZ43AbX375ZbN1cXFxMmLECN38N27ckI8++shsfWRkpOYXua5du5rlWblypdy4ccNs/WeffWb2aFeVKlXMvkSnpndu6o0FAHMjRozQ9EWLFy+WsWPHOlzPqVOnpH379sZBdg0Gg0yaNMnqlyxX94GO9H+e0Kdn5f5cr276dOegP3c+T+jPW7RoYbbu119/lW+++UY3/4MHD2TWrFlm63PmzKkJZNKfw5UI7MAtoqKiZNCgQRYH+YqOjpb333/fuOzt7S0tW7bU5Clbtqxmee7cuRa3d+rUKRk4cKDNgei8vb01y+m9LfTAgQPGi89Ro0bJhQsXbJZZtWqV8e/8+fPbPQOFo1JP1yoisnr1aot5r127Jk2bNpU7d+5ItWrVjOvtuQ3eGe91v379NBetr7/+upw5c8biNhMTE+WNN96QY8eOyerVq6Vv374ZOtBi6k78CWvtTatixYrJwIEDHS43YMAAyZUrl9n6sWPHSu/eveXYsWOSkJAgMTExsn37dmnUqJGsXLnSLH+VKlWkadOmaWp7WrzzzjtmX3Tj4uKkTp06smjRIrl586YkJSXJlStXZNasWdKlSxd58OCB/PPPP3Lw4EHZsGGDS58zf/HFF3UHup07d6507txZTp06JYmJiRIdHS1Lly6V6tWr616Evffee5rZUCpXriwvvPCCJk9cXJw0a9ZM9uzZI48ePZKbN2/K5MmTdYMK77zzjtV2652bxYsXt1oG/8mfP78sWrRIs+6jj/4fe/cdHlWV/3H8O6mkEEoIoQRCU2QFlBKkicDSi6JEBCkuLlIWFVEUxIa0VUGKCwRFl6KgCChSpLooIEUQQaVIU0IWEAIkIYQQknx/f/BjNpMpmUlmMrnh/Xqe8zzcO+ece+6dYU7yyS1vyOOPP273HhY5qaosXLhQWrVqZfFZePHFF23+YpGTu+fAgsx/RXFOv53mcxHmdE9hPveMoj6fDxs2zGawPnDgQBk1apScOHFCbty4IQkJCfLFF19I48aNzU+zzKlnz54W30XM5/AoRYElJSWpiORZYmNjvT1UjYuLsxjTtm3brOqsXr3aos7vv/+eZ7+52xw+fNji9fnz51u83qtXLxURbdWqlX711Vf6559/akZGhp49e1Y//vhjjY6Otqjfr18/q23euHFDK1SoYFFvwIAB+uOPP+rVq1f1+vXreuTIEZ0wYYKWLFlSfX19deLEiea6vr6+NvclNDTUXKdChQq6Y8cOTU9P1/Pnz+upU6ecO9D/b8+ePWoymcz9lS1bVidOnKh79uzRpKQkzczM1NTUVD19+rSuXbtWH3roIYv9GTt2rMfel+zsbI2KirJ4ffjw4Xrw4EG9du2aXrp0SXfu3KkvvfSS+ZjExcXpsGHDzPVNJpMuWbJEr127pikpKR57r1VVR48ebVEvJCRE33jjDf355581NTVVU1JS9MiRIxoXF6d169a1qDts2DCbfU6fPt2i3rp161x4d+17++23rf7/33333Q7bzJs3z6rNkCFD8tzWpUuXtEyZMg6/e0aPHm3Vbt26dRafTVdLyZIl9ejRozb7tVX/woULDvcjPDzcqk1cXJxVveeffz7fY65Ro4b5c5rXeG19Nzpj69at6uvrm+8xNm/eXK9fv27V7/79+/PVb+vWrfMcc82aNa3azZgxI1/77047duzIc//i4+O9PUxVVZ0xY4b6+PhYfUcNGDBAly9frseOHdPk5GRNT0/X06dP644dO/TNN9/UevXqWe1T3759NTMzM89temIOdHb+M8qcXlTnc1XmdHfP6cznzOfuns+HDBmS7/Hd+kyfPn3aql/mc8vSoUMHbw+vuPicYMcNCHZcD3aOHj2qpUqVcuq4RUVF6blz52xud+rUqU5/IY4dO1Y3b95sXjaZTDb7bNeund0+XnjhhbwPci4vv/xyviaE+vXr69WrV+0eY3e8L7k/D45Kr169NCsrSxcuXGjz9YceekhVPfdeX79+XTt37uzycWzUqJGmpqba7NNTPwh+8803VuPw9fXVpKQku23y+4Ogquq0adMcHgNbPwiqqi5cuFADAgJcPqYRERG6fft2m316+gfBjIwM7datm8tjjoyM1F9++cXp8eb3B0FV1Q8++MDql3xnP6t//vmn3X5d+f8qInrHHXfof//7X4djTUxMtPkLgb33tzAZKdhRVf3yyy+d/q6zVXx9fXXSpEkubdPdc6Cz859R5vSiOp+rMqe7e05nPmc+d/d8npGRod27d8/X//mAgADdsGGD3b6Zz/9XCHbc5nMuxYJXVKxYUdatW5fnDb3uuusuWb9+vcWNx3IaOXKk9O/fP8/tjRo1SiZNmmRxZ3hVNd+pPqexY8e69Tr4SZMmyZQpU+w+NtOW3r17y3fffefxO9kPHTrUqVN/Bw4cKEuWLBEfHx/p2bOnS9fruuu9DggIkFWrVsmLL77o1Om3JpNJnnzySdmyZYtHT3+3pUWLFlbvd1ZWlmzZssUj2xs+fLjUrFnT5XYDBgyQbdu2SfPmzZ2qbzKZpFevXrJnzx5p0aKFy9tzB39/f/nqq69k3LhxTr+vXbp0kT179kjdunWd3k5BvgOeeuop2bx5s9OnPwcFBckLL7wg27dvt3mjzluGDh0qixYtkvDw8Dz77Nixo3z77bc27w+R06ZNm6wuqShZsqTDp27Ath49esjJkyflhRdeyPOy35x8fHykT58+cujQIRk7dqxL23T3HJjf+a+ozum303wuwpzuCcznnlPU5/Nb45s6dardR7TbEhMTI3v27JEOHTrYrcN8Do/waq5UTHDGjutn7Nz6S0dycrLOnj1bW7VqpZUrV9aAgACtWLGitmrVSufMmWP1Fy571q5dq7GxsVq1alUtUaKEBgQEaNWqVXXAgAG6f/9+c72ff/7ZYhyXLl2y2d+GDRu0ZcuWGhwcrAEBARoZGamtW7fWlStXOjUeWy5cuKDTp0/Xbt26ac2aNTU0NFR9fHw0KChIK1WqpG3bttVXX31VDx48aLO9J96XWzZu3KixsbEaFRWlAQEBWqJECa1Zs6YOGDBAt27dalX/0KFD2qFDBw0JCdHAwECtVq2aTp48WVU9/16rqsbHx+vkyZO1bdu2GhUVpUFBQRoYGKiRkZHaqlUrffXVV22eVpybp/7Cp6raqVMnq++Ap556ym79gvyFT1V1+fLlLv+FL6dvv/1WR40apTExMVqpUiUNDAzU0NBQrVatmrZt21YnTZpk97OZk6f/wpfThQsXdNq0adqtWzetVq2ahoaGakBAgEZERGhMTIyOHDlSf/zxx3yN98CBA3nua16ysrJ05cqVOmjQIK1bt66Gh4ern5+flipVSmvUqKEPPvigzpw50+FZOrZcvHhRp02bpu3atdOoqCgNDAzU0qVLa506dXTw4MG6ceNGp/vq37+/1b736NHD1V31CKOdsZPTpUuXdP78+TpgwABt0KCBhoeHq7+/vwYGBmrlypX13nvv1T59+uj8+fPz/CusM9w5Bzoz/xlpTi+K87kqc3pO7pjTmc//h/nc/fP5lStX9MMPP9S+ffvqXXfdpeXKlVM/Pz8NDg7WSpUq6f3336/PP/+8y2fHMJ9zxo4bfW5StXP3MzgtOTnZ5mP7couNjbW4kd7tZMGCBTJw4EDz8uXLl506ZjAe3uubFi1aJE888YTFutKlS8u5c+c8esM/5F90dLTEx8eLiMipU6ekatWqXh6RZ6WlpUlkZKTVE26WLl0qvXr18tKo/mfnzp15/vU5Pj5eqlSpUkgjwi18z98+eK+Zz42I+fwmI8znHTp0kA0bNhTyiIqlZVyKBQAe0LNnTwkNDbVYl5SUJCtXrvTSiODI1atXJSEhQUREgoOD8zzluThYvny51Q+BpUqVsngUMQDc7pjPjYX5/Cbm89sPwQ4AeEBISIgMGjTIav20adO8MBrkZfXq1ZKdnS0iIo0aNbJ43HhxZeuzOHjwYJfuDwMAxR3zubEwn9/EfH77IdgBAA95/vnnxd/f32LdDz/8IN9++613BgS75syZY/53jx49vDiSwrFu3To5cOCAxbqAgAB57rnnvDQiACi6mM+Ng/mc+fx2RbADAB5SpUoVGTp0qNX60aNHWz25AN6zevVq2bZtm4jcPG3bmafyGFl2drbNpy89/fTTt8Up6wDgKuZzY2A+v4n5/PZEsAMAHjRu3Dirx2T+8MMP8umnn3ppRMjp/PnzMnjwYPPyq6++KhEREV4ckectWrRI9u/fb7EuPDxcXnvtNS+NCACKPubzoo35/Cbm89sXwQ4AeFDZsmXlnXfesVr/wgsvyOXLl70wIuRUvnx5OXv2rKiqqKq8/PLL3h6SRyUmJspLL71ktf7dd9+97Z50AwCuYD4v2pjPb2I+v30R7ACAhw0aNEjatWtnse7cuXMycuRIL40It6sRI0bIhQsXLNZ16tTJ6lG+AABrzOcoKpjPkZtJuTC0wJKTk51KRmNjY2XZsmWFMCIAAIxt586d0rx5c4d14uPjpUqVKoU0IgAA4CpH83mHDh1kw4YNhTyiYmkZZ+wAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGBTBDgAAAAAAgEER7AAAAAAAABgUwQ4AAAAAAIBBEewAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGBTBDgAAAAAAgEER7AAAAAAAABgUwQ4AAAAAAIBBEewAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGBTBDgAAAAAAgEER7AAAAAAAABgUwQ4AAAAAAIBBEewAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGBTBDgAAAAAAgEER7AAAAAAAABgUwQ4AAAAAAIBBEewAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGBTBDgAAAAAAgEER7AAAAAAAABgUwQ4AAAAAAIBBEewAAAAAAAAYFMEOAAAAAACAQRHsAAAAAAAAGJSftwdwO0lJSZGDBw96exgAABR5v//+e551jh49KikpKYUwGgAAkB/OzOcoOIKdQrRx40apW7eut4cBAECx0K5dO28PAQAAwOu4FAsAAAAAAMCgCHYAAAAAAAAMimAHAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKB4KpYb+Pn5yX333eftYQAAgP+3d+9eycrKslhXvnx5qV69updGBAAAcqpTp463h1BsmFRVvT0IAAAAdypVqpSkpKRYrBs0aJDMmzfPSyMCAADwiGVcigUAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUH7eHgAAAIAzFi5cKIcPH3aq7vXr163W7dmzR8aMGeNU+169eknDhg1dGh8AAIA3mFRVvT0IAACAvLz33nsyYsQIj2/Hx8dH4uPjpXLlyh7fFgAAQAEt41IsAABgCL169RJfX1+Pb6dVq1aEOgAAwDAIdgAAgCFUqFBB2rZt6/Ht9OnTx+PbAAAAcBeCHQAAYBi9e/f2aP/+/v7Ss2dPj24DAADAnQh2AACAYcTGxkpQUJDH+u/cubOEh4d7rH8AAAB3I9gBAACGERYWJp06dfJY/1yGBQAAjIZgBwAAGIqnwpeQkBDp1q2bR/oGAADwFIIdAABgKN27d5dSpUq5vd8ePXpIaGio2/sFAADwJIIdAABgKCVKlJCHHnrI7f1yGRYAADAigh0AAGA47g5hypYtK+3bt3drnwAAAIWBYAcAABhOu3btJDIy0m39PfrooxIQEOC2/gAAAAoLwQ4AADAcPz8/iY2NdVt/XIYFAACMimAHAAAYkrvCmEqVKsn999/vlr4AAAAKG8EOAAAwpObNm0u1atUK3M/jjz8uPj78SAQAAIyJn2IAAIAhmUwmeeyxxwrcD5dhAQAAIyPYAQAAhlXQUKZ27drSsGFDN40GAACg8BHsAAAAw7rnnnvk7rvvznd7ztYBAABGR7ADAAAMrXfv3vluS7ADAACMjmAHAAAY2uOPPy4mk8nldo0bN5Y777zTAyMCAAAoPAQ7AADA0GrUqCFNmjRxuR1n6wAAgOKAYAcAABieqyGNj4+PW56oBQAA4G0EOwAAwPAee+wx8fX1dbp+q1atpHLlyh4cEQAAQOEg2AEAAIZXoUIFadOmjdP1H3/8cQ+OBgAAoPAQ7AAAgGLB2cux/P395ZFHHvHwaAAAAAoHwQ4AACgWYmNjpUSJEnnW69y5s4SHhxfCiAAAADyPYAcAABQLYWFh0rlz5zzr8TQsAABQnBDsAACAYiOv0CYkJES6detWSKMBAADwPIIdAABQbHTv3l1KlSpl9/UePXpIaGhoIY4IAADAs/y8PYDiICsrS3744QdvDwMAAIhIs2bNZP369TZfa9CggezcubOQRwQAAHIrXbq01KlTx9vDKBZMqqreHoTRJScnS+nSpb09DAAAezBPEAAAIABJREFUAAAADKFDhw6yYcMGbw+jOFjGpVgAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAREWnZsqWoqlXZv3+/t4cGIAd/f3/ZsmWL+f9ofHy8REZGentYKAJiY2MlOzvb/Nl4+umnvT0kAEAhINgBAAAwkLlz50rr1q1FRCQtLU169Oghf/75p3cHhSJh+fLlMn78ePPyjBkzpFOnTl4cEQCgMBDsAACAAmvatKlMmTJFvvvuOzlz5oykpaVJenq6nDt3Tn755RdZsGCB/P3vf5ewsDC3bjcoKEh+++03m2ebqao0btzY5T7r1Kkjr732mmzbtk1OnjwpaWlpkpaWJgkJCbJx40YZM2aMREVFuXU/nPXss8/Kk08+aV4eOnSo7Nu3z6LOoEGD7B6PnCU7O1uSk5Pl1KlTsn//flmxYoWMHj1a2rZtK0FBQYW9a3CTN998U9auXSsiIr6+vrJ06VKpUaOGl0cFAPAoRYElJSWpiFAoFIqhS8uWLW1+x+3fv9/rY6MU3dKsWTPdt2+f03NmamqqTpkyRYOCgtyy/enTpzvcXuPGjZ3uKzIyUj/77DOn9iM9PV3Hjx+vPj4+hXas69atq+np6eYxrFixwma9QYMGOf1+2HP58mV97733tG7dul7/jFFcLxUqVNDExETz+7ljxw719fX1+rgoFAolZ+nQoUOB5yuoqurnBDtuQLBDoVCKQyHYobhaRowYodnZ2fmaOw8fPqwVK1Ys0Pbvv/9+zcrKcrgdZ4Odhg0b6sWLF13ej2XLlhVKuOPv768HDhwwb/fChQtarlw5m3XdEezckp2drbNnz9aQkBCvf94orpXevXtbvJevvPKK18dEoVAoOQvBjtt8zqVYAADAZUOGDJEZM2aIyWTKV/u77rpL1q9fL35+fvlqHxISIvPnzxcfn4L/KHNrLGXLlnW5bWxsrIwePbrAY8jL8OHDpX79+ublcePGSWJiolNtN2zYICaTyar4+PhImTJlpEaNGvLXv/5VXn31Vdm8ebOoqrmtyWSSf/zjH/Lzzz9bbB9F32effSbff/+9efmVV16RKlWqeHFEAACP8Xa0VBxwxg6FQikOhTN2KM6W2rVra1pamlvm0H/84x/5GsPs2bOd6j+vM3Z8fHz0xx9/LNA+pKWlaWRkpMeOd3h4uF66dMm8vSNHjqifn5/d+rnP2Fm/fr1L26tZs6bOnj3b6mysc+fOaa1atbz++aM4X+677z6L93DJkiVeHxOFQqHcKpyx4zacsQMAAFzz8ssv27257oIFC6RRo0ZSokQJiYiIkJYtW8rKlSvt9jVgwACXt9+2bVsZNmyYxbrLly+73I+IyMCBA6Vhw4Y2X1u6dKnExMRISEiIVK1aVcaMGSPXr1+3qhcUFCTDhw/P1/adMXLkSClTpox5edKkSZKZmemx7Z04cUKGDx8uHTt2lPPnz5vXR0ZGyqZNm/J1ZhO8Y/fu3bJ+/Xrzcp8+feQvf/mLF0cEAPAIb0dLxQFn7FAolKJaQkJC9G9/+5uuX79eT548qdeuXdMLFy7oTz/9pHPnztWYmBhz3RYtWtj8jnPljJ3AwEDt06ePfvDBB3rgwAH9888/NSMjQxMTE/XXX3/Vzz//XHv37u30/TpKly5tc0xr1qyxqBceHq4vv/yyfv/993rp0iXNyMjQc+fO6a5du3Ts2LFavnx5l49dQECAPvTQQxoXF6c7duzQM2fOaGpqqmZmZmpSUpL+9ttvunLlSh0xYoRWqVIl3++Ru4+Zp0vJkiX12rVrNt+Xd9991267uXPn2myTlZXl0k1dS5YsqX/88YdFHykpKTp16lSb/ed1xs7Jkydttnv77bdt1s9935JbDh8+7JHjHRQUZHET3HPnzmlAQIDDNgU9YydnadSokaamplr0N3PmTJf6KFOmjA4fPlyXLVumx48f16SkJE1PT9fTp0/r3r17ddasWdqmTRunPwdhYWEW4/nggw8sXm/fvr1+/PHHeuzYMb169apmZGTo+fPndfv27frmm2+6fG+noKAg7dWrly5YsED37dunFy5c0PT0dM3IyNCLFy/q/v37dfHixTpgwIB8/z919zHKWbp06eLweFEoFIq3CmfsuA03T3YHgh0KhVIUS6tWrax+AbZlwYIFGhgYaHXK/i3OBDsmk0mfe+45/fPPP5363jx79qz26tUrz379/Pxstv/+++/NdWJjYzUpKcnh9i5duqSPPvqoU8fNx8dHhw0bphcuXHBqX1RVMzIy9IMPPtBSpUo5/f546ph5urRp08bm+BITEx0GDnfccYfdfYuIiHB6+/PmzbNqP3LkSJ04caLNvh0FO/Y+8wcOHHD4C/S+ffv08OHDunr1ap02bZoOGzZM27dvryaTye3HO3dIM378eJfbFCTYERHt06ePRX8ZGRl655135tnO399fJ02apFeuXLH73ue0b98+bdiwYZ795v5euHV5UXh4uK5bty7P7Vy7dk179+7t1L737t1bz5w549T4VW/+Pxg8eLDTx9ZTxyhnMZlMeuLECYv9L126tNs/qxQKheJqIdhxG4IddyDYoVAoRa106tRJb9y44fT32Nq1a/Md7ISGhurXX3+dr+/Pd955J899ycjIsGp36NAhFRF97LHHnH4qU2Zmpnbv3t3htvz9/Z1+3LUtJ06c0Ojo6Dz3ydPHzJPl/vvv10WLFunatWt1586devToUU1MTNTly5c7bBcSEmJ3n5x99HnHjh2t2u7atUt9fX112rRpNvt2FOzYO8unf//+Xv8/fKts2rTJYmzOPH7c3cGOyWTSvXv3WvT54YcfOmxTpkwZ3bZtm9333J7MzEx9+OGH8xxTzqehffXVVxoSEqL79+93ejtZWVnaokULh9t49tlnXR7/LRMmTMhzHzx9jHKWt99+26KPJ554wuufbQqFQiHYcRuCHXcg2KFQKEWpVK9e3em//ua0cOFCm+sdBTs+Pj66atWqAn2Hjho1yuH+pKSkWLU5ffq01qhRw+oSkbycOXNGS5YsaXdb48ePL9C+qKoePHhQAwMDvXrMimJp2LCh3ePlTPvSpUtrQkKCRdu0tDStXbu2iojOmDHDZv+Ogp2dO3da1c/KytIyZcp4/XiJiJYtW9YioD127JhT7dwd7IjcPDMup+TkZPX397f7Gc995kxmZqa+//772qpVKy1VqpQGBARo1apVtW/fvrpnzx6Luunp6dqsWTOH40lPTzfX37Bhg/7rX/9SVdUrV67ohAkTtH79+hocHKxBQUF655136qhRo6y+S3bv3m23/9q1a+v169fNdbOzs/Wjjz7Sdu3aaWRkpAYEBGhwcLBGR0drr1699IsvvrD6LDVt2tRu/4VxjHKW3MH96tWrvf75plAoFIIdtyHYcQeCHQqFUpTKp59+avf7auXKldqsWTMNDg7W0qVLa48ePfTnn39WVbV75oujYGfUqFE221y5ckWff/55rVatmvr7+2uFChV00KBBeu7cOau6165d0+rVq9vdRs6nAd2SmJioy5Ytc+Yr2srQoUNtbqd06dIWvyzekpCQoE899ZTWqlVLS5Qoof7+/hoZGakPP/yw7t692+Y2XnzxRa8es6JWAgICdOPGjS4fq5zFVvD4zDPPmF/PT7CTnJxsVf+XX37x+vG6VXr27GkxtlmzZjnVzhPBTlhYmNVZgPaCi9xnuiQnJzs8O8bHx8cczNyyb98+h5e25Xwq24ULFzQ7O1tPnDihNWrUsNvmgQcesPqes3dJ2TvvvGNRz5mnt/Xr18+if0dnsRXGMcpZTCaTxXdpWlqawyerUSgUSmEUgh23IdhxB4IdCoVSVEp0dLTdgOaTTz6x2SY0NNTh457tBTslS5a0uKnrLRkZGXZ/4atevbpevHjR6bGJiM1tZGdnm/dz37592qVLFw0LC9OwsDDt0qWLHjp0yO7+bNq0yeZ2Hn/8cZv177vvPrtjCwkJ0X379lm1OXLkiFePWVEoYWFhWrt2bX322Wf1119/tXls9+3b5/Dsplule/fuVm03b95s8Uutq8FOdHS0zfpffvmluU7Lli117ty5+uuvv+rly5c1LS1NT506pWvWrNHhw4draGioR4/hlClTLMbWr18/p9p5ItgREavLhoYPH25VJyAgwOrMqm7duuXZt4+Pj27fvt2iXc+ePe3Wz322XkZGht5zzz15buebb75x6phu2bLFXOfatWtOhyBLlizRU6dO6datWzUuLs5mncI6RrnL+vXrLdq6eq8eCoVCcXch2HEbgh13INihUChFpbzwwgs2v6dSU1M1PDzcbrsGDRrY/Y6zF+yMHDnSZv2PPvrI4RhtnbFy9epVu0+TsRWE3PKf//zHZjAQHh6up0+fttnm4sWLNrfzyiuv2Kzv6NItkZuBUGJioh44cEDXrl2r77//vr722ms2byRcWMfMW6Vp06Z236vctm7dquXKlcuzz7Jly+rZs2ct2iYlJVk9iczVYKdly5Y268+ZM0fLli3r1L2WLly44HTYkp/y3XffWWyvVq1aTrXzVLCzYMECi36nTp1qVadXr14WdewFqbZK7h/wly5dardu7mBn0aJFTm0j9/9zezejPnDggLlOamqqW9/XwjpGucu4ceMs2g4bNsxjn10KhUJxphDsuM3nPgIAKDbat29vc/2qVavk4sWLdtv99NNPsmvXLpe29cgjj9hc/8UXXzhs9/nnn1utCw4Oli5duri0/bS0NBkwYIBcv37d6rWLFy/KW2+9ZbNd2bJlpUyZMk5vp1+/fg5fX7JkiZQrV07uuece6dq1qwwZMkQmTJggGRkZVnW9fcyKgr1798qAAQPkgQcekMTExDzrz549WypUqGCx7tlnn5XTp08XaBwlS5a0uT4rK0u+/vpreeyxx/Lso1y5cvLxxx/L2LFjCzQWe2rXrm3+940bN+TkyZMe2Y6zcr9fZcuWtarTtm1bi+XFixc73f/mzZvl8uXL5uXOnTuLr6+vU22XLFniVL3ff//dYrlUqVI2650/f97875CQEOnevbtT/TvDW8fo6NGjFst33nmn09sFABRtBDsAUIzUrVvX5votW7bk2XbdunVOb8fPz08aN25s87XffvvNYdv4+HhJTk62Wh8TE+P09kVuhh0JCQl2X1+zZo3d12z9Mnfq1CmbdWfPni1ffvmlxMbGSrly5VwaY05F4Zh5U0pKikyfPl1efPFFWbx4sahqnm169uwpvXv3tlj35ZdfyqJFiwo8ntDQUJvrn3zySbnvvvtc6mvixInStWvXAo8ppxIlSkj58uXNywkJCZKdne3WbbgqdzgcHBxsVadVq1YWy9u3b3e6/+zsbNmxY4d5uWTJklKrVi2n2u7evdupeqmpqRbLtvZB5GaAktOSJUtk6NChEhAQ4NR2HPHWMcodakVHRzu9XQBA0UawAwDFREhIiFSuXNnma7n/UmvL/v37nd5WdHS0lChRwuZrx44dE1V1WGwFK/Xq1XN6+yIi69evd/j66dOn7f4iHBgYaLXu66+/tnn2j8lkkh49esiyZcvk/PnzcuTIEfn3v/8tAwcOlOrVqzs93qJwzLwpLCxMRo4cKVu2bJGEhAQZMWKE+Pv7260fEREhcXFxFuvOnz8vQ4YMcct4QkJCbK6/9Yv+iRMnZMCAAVKrVi0pUaKE3HHHHfLaa69JWlqaVRuTySTvvvuu+Pi478eqypUri8lkMi8X9Awld8gdgty4ccOqTs7/E6rq8rhzf1fVqVMnzzYZGRkWZ7HkVTennMc4p/fff1/++OMP83JoaKjExcXJmTNnZMGCBdK3b1+pWLGiU9vMzRvHSMQ6vK5SpYpL2wUAFF0EOwBQTDi6vOjcuXN5tnemzi25L41xB1dCEhGRw4cPO3w9Ozvb7qU+tn6Zu3TpkkyaNMlhnyaTSWrXri0DBw6Uf//733Ly5Ek5deqUxMXFSZMmTRy2LQrHrKioWLGizJgxQzZt2mT3Upi4uDiJiIiwWDd48GC5cOGCW8ZgK8S75ejRoxITEyMff/yxnDhxQq5fvy7Hjx+XiRMnSufOnSUzM9OqTe3ataVjx45uGZvIzSAsp5SUFLf1nV/h4eEWy1euXLFYDgoKsggvTSaTpKen5xla5iwjR4606NOZ8CT3ONwhKSlJunbtahWGhIeHyxNPPCGffPKJnDlzRg4fPiyzZs2STp06iZ+fX579eusYiVgfJ3uXIwIAjIdgBwCKCUc/pNs6yyA3V345CgoKcrqus1z9JcPWpUm5ufoL36RJk2TWrFkutalataoMHTpUdu/eLatWrbL7S1ZROGaetmvXLjGZTGIymaRkyZJSrVo16d69u3z66ac2L7164IEH5JNPPrFa36dPH+nZs6fFugULFshXX33ltrE6+myMHj3a7hkgW7dulY8//tjma/bucZUfuc+Oceb/sKdFRkZaLOc+06R06dJu36Y3P+OHDh2SBg0ayIwZM+we/7vuukuGDx8u69atk3Pnzsmbb75pFcrl5M1jdPXqVYtle5ehAQCMh2AHAIoJe5cUiIhT9zNx9gacItaXM7iDo1+GbMnKynL7GLKzs+WZZ56Rzp07y549e1xu3717d9mzZ4/UrFnT6rWicMwKU2pqqpw6dUrWrFkjjz/+uHTt2tXmMejWrZu0a9fOvFyhQgWrcC0+Pl5GjBjh1vE5OgNmw4YNDtvau3/TvffeW6Ax5ZT7ckFHZxgVlubNm1ss5743lCf+T9q7F1JhuXz5sowcOVIqVaokAwcOlBUrVtj97ISHh8vrr78ux44dk6ZNm9qs481jlJ2dbXG2ma1LUgEAxkSwAwDFhKMzEJz5y6wrfxl3dD+LqKgo81kbrpSidPbJ+vXrpUmTJlKvXj156aWXZOPGjU6fMVG5cmVZunSpVdBW3I9ZXtatWyfz58+3+VqfPn3M/27ZsqXV05aqVq0qycnJDi9PsRf87Nmzx6Jey5YtReRmWGTL9evX5dq1aw73xd6NtnNfOlYQuYMcb/8SXqdOHavLCXfu3GmxnPssumvXruXrc52zvP766x7fN2ckJyfLggULzDdRb926tUyePFn27t1rFZyXL19e/vOf/1gFYbf6yakwj5GPj4/F5WJFISwEALgHwQ4AFBNJSUl2X3PmHgyu3Ejz0qVLdl/LfbmGkf36668yZcoU6dixo5QqVUpiYmLkmWeekcWLF8uZM2fstmvUqJHVI41vl2PmyPfff29zfYMGDQp5JCJ//PGHzf8zgYGBeQZm9s5uc3QzaFflDhK9fdlMzvBNROTHH3+Us2fPWqy7fv26xbiDgoLc8hSpoubGjRvy3XffySuvvCIxMTESFRUlb7zxhsUTt4KCgmTu3LlWbb15jHLfMLwoXN4HAHAPgh0AKCauXLli9wbItWvXzrO9K79c//e//7V69PEtnrhJcFGQmZkpe/fulVmzZkm/fv0kKipKOnToYPdR5TkvLxIpPsfs9ddfl3nz5slXX30lO3bskOPHj0tycrJ07949z7b2Lgm094QqTztw4IDN9Xk97tzeTavtvb/5UZRudBsaGipPP/20xboFCxbYrHvw4EGLZWe+e4zuzJkzMn78eGncuLFFgFuvXj2bl+d56xjl/gx54qbTAADvINgBgGIk9y8Mt+Q+e8QWZ34xzyn3ZRi32Lr8oDhSVdm0aZO0b9/e5mPVbT16vjgcs+7du8ugQYPkwQcflGbNmknNmjUlLCxMHn300TzbxsTE2FzvridduWrdunU21w8ePNhhO3v/V06ePFngMd2SkJBgEYRVrVrVbX27avz48RZP3UtISJB58+bZrJv73lQtWrTw6NiKkt9++03mzJljse4vf/mLVT1vHaPo6GiLZVcfsw4AKLoIdgCgGPnmm29srn/wwQcd3v+jXbt2cvfdd7u0rbVr19pcP2DAAIeXFnTq1ElSUlLk2LFjsn37dlm+fLnMnj3b6gyXwlSxYkXp3bu3vP7667J48WLZs2eP/Pnnn049web06dM2H6tu6zKH4nDM7H3G+vXrJw8++KDddnfccYcMHDjQ5ms5z3pavnx5vu4zMnPmTJt9x8TEWNTbvn27+bXFixfbDOUeffRRiY2Ntdlfq1atpHfv3jZf++677+zuv6vS09Pl/Pnz5uWoqCjx8Sn8H9sefvhhq8drT5w40e79WdavX2+x3L9/f4+NzVPat28vU6dOla1bt7r8np44ccJi2dZle946RtWqVbNYtnevKACAASkKLCkpSUWEQqFQvF5q165t97vqs88+U5PJZNUmIiJCjx07Zrfd/v37bW4rJCREL126ZLPN9OnTbbYJCgrSH374wap+dna21q9f32abxMREm9uIiorK83gcP37cZtu77rrLol5MTIxL+5Gz3HvvvZqdnW3VdsSIEV47Zp4sdevWtbm/qqqZmZn6/vvva/369TUoKEhDQ0O1Xr16+uqrr2pSUpLNNqqqDz/8cIHHNWPGDJt9N27c2GG7lStX2myXkZGhEydO1Bo1aqi/v79GRUXpCy+8oFeuXLFZ/9q1a1q+fHm3HuutW7dabKNWrVpOtRs0aJBFu/Xr1+dr+/3799f09HSLvtasWaM+Pj522/j6+urp06ct2jzyyCNObc/Pz0937Nihmzdv1pdfflkbNmxot25qaqq5/8TERKf3qVOnThZj+/DDD63qvPPOOxZ1WrVq5XT/EydOtGjbunVrrx2j3GXcuHEW2xw2bJhbP68UCoXiaunQoYPNORUu+5xgxw0IdigUSlEqX3/9td3vqzVr1mjTpk01ODhYw8PDtW/fvvr777+rqlr9AnfLgQMH7G5rzJgxdre1bNkyve+++zQkJETDw8O1U6dOumvXLpt1//3vf9vdRmEEOyKi+/bts1n3s88+0wcffFArVqyowcHB6ufnp2XKlNEGDRroSy+9pOfPn7dqk5GRoRUrVvTaMfN0Wbx4sd19cNWRI0fU39+/wGPKb7BTrVo1vXr1aoH341//+pfbj/PUqVMtttG3b1+n2hU02ImOjtb58+db7eOhQ4c0LCwsz/b/+Mc/LNqlpKRoy5YtHbYJCQnRTz/91KLd3Llz7db3ZLBTv359i/AyPj5e77zzzjz7rlWrlsX31eXLlzUgIMBrxyh3WbdunUVbV0IhCoVC8UQh2HEbgh13INihUChFqTRo0EAzMjJc/i7L/dfcW3799Ve72/Lx8dFvvvmmQN+hx44dc/jLYmEFOy1atNDMzMwC7cstr732mlePmadLuXLlHJ7l5ayMjAxt06aNW8aU32BHRPSpp54q0H4cOXJES5Ys6fbjHBsba7EdZ8MjV4IdHx8fLV++vNarV08HDx6sK1as0OvXr1vt486dO7Vy5cpObd9kMummTZss2mdmZuoHH3ygrVu31nLlyqm/v79WrFhRGzdurOPGjdM//vjDov6ff/6pERERdrfhyWBHRHTBggUW9a5evarvvfee/vWvf9XIyEj19/fXoKAgjYqK0hYtWujEiROtzkobO3asV49R7u1dvHjR3DYtLU39/Pw8+j1BoVAoeRWCHbch2HEHgh0KhVLUyuDBg136Hlu4cKFWq1bN5mvHjx93uK3SpUtb/YLirMOHD+cZ0BRWsCMi2rdv33yFYjnNnj1bfX19vXrMCqNUr15d9+/fn+/jlJaWpj179nTbeAoS7IiIPv300/najyNHjjh9iZSrpWzZsnrjxg3zto4ePepUu9zBTkFkZWXp7Nmz7Z55Yq+UKlVKt2zZkq9tJiYmakxMjMP+PR3sBAcH6+7du/N93L788ss8gxNPH6OcpUmTJhbtV69e7ZHPLIVCobhSCHbchmDHHQh2KBRKUSwDBgyw+OXHluzsbJ0xY4b6+vpqaGiozTpnzpzJc1t+fn46duxYu/ePye3atWs6bdo0DQ4OzrPvwgx2REQbNWqkO3fudGo/cjpy5IhL94rx5DErrBIYGKjjxo2zOBMgL9nZ2bp27Vq3hyEFDXZERO+//36nw6rr16/rnDlzPH7mVO4A8O67786zjTuCnczMTP3kk0+0Tp06+R57QECAvvnmm3bvS2TLF198odHR0Xn27elgR0S0RIkSOnPmTJtnMNmTkpKio0ePzjPcLYxjlLO89dZbFn088cQTHv3cUigUijOFYMdtPjep5niWJvIlOTnZqSenAEBhi4qKkieffFK6d+8u0dHREhYWJufPn5fTp0/L+vXrZcmSJRZPcUlKSpJSpUpZ9HH16lUJDQ11anthYWHyyCOPyF//+ldp1KiRRERESOnSpeXq1aty6dIl+eWXX2TLli2yePFipx9xnZiYKOHh4Vbrq1SpIgkJCQ7bHj9+XGrWrGm1vk6dOnLkyBGHbRs1aiRdu3aVpk2bSvXq1SUyMlJCQkLE19dXrly5IklJSXLkyBH56aefZNWqVbJr1y6n9ic3TxyzwhYSEiIPPfSQPPDAA9KkSROJiIiQMmXKiL+/vyQnJ5v344cffpDly5e79bEa0GgvAAAgAElEQVTgt8yYMUNGjBhhtT4mJkb27t3rdD++vr7Spk0befDBB6VFixZSoUIFKVeunFy7dk0uXrwohw8flm+++UaWLVuW5+fPHQYNGmTxaPHx48fLG2+84VKbvFy9elUuXLggFy5ckJ9//lk2b94s33zzjds+bxEREfLII49I+/btpX79+lKuXDkJCwszf8YPHjwoO3bskKVLl1o9Vcqe1NRUCQkJERGRixcvSrly5Zxq16lTJ4vH3H/00UcyaNAgh20qV64ssbGx0qZNG6ldu7ZUrFhRQkJCJDs7W65cuSIJCQnm4/bll1/KlStXnBpLTp44RreYTCY5evSo1KpVS0RuPnGtYsWKkpSU5PI4AcCdOnToIBs2bPD2MIqDZQQ7bkCwAwAAPCE4OFji4+PN4ebZs2clOjpabty44eWRwShyh1nz5s2TwYMHe3FEAHATwY7bLPPx9ggAAABgW1pamsydO9e8XLFiRenVq5cXRwSjeeaZZyyWZ8yY4aWRAAA8hWAHAACgCJs+fbrFZTOvvvqq+Pn5eXFEMIqYmBjp3LmzeXnp0qVy6NAhL44IAOAJBDsAAABF2MWLF2X8+PHm5bvuukueeuopL44IRjF16lQxmUwicvPeOi+99JKXRwQA8ASCHQAADO65554TVfVoOX78uLd387Y2a9Ys+fXXX83Lb775ps2bigO39OrVS1q1amVenjx5ssTHx3txRAAATyHYAQAAKOJu3Lghffv2levXr4vIzaco5bz3DpBTZGSkzJ4927y8a9cumTx5shdHBADwJIIdAAAAA/j5559l9OjR5uXY2Fjp16+fF0eEoshkMslHH31kfgT8lStXpF+/fpKVleXlkQEAPIVgBwAAg5sxY4aYTCaPllq1anl7NyEiM2fOlPnz55uX33//fWnQoIEXR4Si5vXXX5euXbuKiEhWVpY89thjcuLECS+PCgDgSQQ7AAAABjJkyBD59ttvRUQkODhYvvrqK4mMjPTuoFAk9OzZU9544w3z8nPPPSfr1q3z4ogAAIWBZ2UCAAAYyI0bN6RNmzbeHgaKoBUrVoiPD3+3BYDbDd/8AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAZFsAMAAAAAAGBQBDsAAAAAAAAGRbADAAAAAABgUAQ7AAAAAAAABkWwAwAAAAAAYFAEOwAAAAAAAAbl5+0B3E46dOgg06ZN8/YwAAAo8g4cOCB9+/Z1WGfz5s1SoUKFQhoRAABwlTPzOQqOYKcQhYWFyd133+3tYQAAUOSlpKTkWefOO++UKlWqFMJoAABAfjgzn6PguBQLAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKAIdgAAAAAAAAyKYAcAAAAAAMCgCHYAAAAAAAAMimAHAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKAIdgAAAAAAAAyKYAcAAAAAAMCgCHYAAAAAAAAMimAHAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKAIdgAAAAAAAAyKYAcAAAAAAMCgCHYAAAAAAAAMimAHAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKAIdgAAAAAAAAyKYAcAAAAAAMCgCHYAAAAAAAAMimAHAAAAAADAoAh2AAAAAAAADIpgBwAAAAAAwKAIdgAAAAAAAAyKYAcwiDVr1ojJZDKXP/74w9tDggvat29v8f6ZTCYZOHCgt4eF20zfvn2tPoddunTx9rCA2w5zunExn6MoYD5HbgQ7t5m5c+dafAFs377d20MCir0PP/xQNm/ebLGuQoUKMm3aNIs6uSfoW+Wrr75yeltTp061aj9mzBi37Qtcs3XrVnnmmWckJiZGIiIixN/fX8LCwiQ6Olo6d+4sEydOdPkXurNnz8rkyZOlXbt2UqVKFQkKCpKSJUtKzZo1pXfv3vLxxx9LZmamzbYzZ86UiIgIi3Xr1q2ThQsX5ncXYcOlS5dk2bJlMnToUGnSpInUqFFDwsLCpESJElK5cmW59957JTY2VuLi4uT48ePeHi4AJzGf376Yz1HkKQosKSlJRSTPEhsb6+2halxcnMWYtm3b5u0hFTk3btzQoKAgFRGNi4vz9nDMVq9ebfHe/f77794eEpxw8eJFLVOmjNX3wZIlSyzqzZs3z+53xx133KEZGRlObW/KlClW7UePHu2JXYMD+/bt08aNGzs1N/j4+OjAgQM1KSkpz37feustDQ4OzrPP2rVr6w8//GCzjwULFljVDw8P18uXL7v7MBTIjh078tzP+Ph4bw/TQkJCgg4fPlwDAwOdeu9vlY4dO+rOnTu9PfwiO//lV1HeH+Z042E+vz0xnxeco/m8Q4cO3h5ecfE5Z+wAuRw8eFCuXbvm7WGgmBg3bpxcvnzZYl2TJk2kd+/eTvdx7NgxmTVrlruHBg9Zt26dtGjRQvbu3etU/ezsbJk/f740b95cEhMT7dZ78cUXZcyYMZKWlpZnn7/99pu0a9dOdu/ebfVa//795d5777VYd/HiRZkwYYJT44VtixYtklq1asns2bPl+vXrLrXdsGGDNGvWTIYOHSo3btzw0AjzVtzmv+K2P/Au5vPbD/M5jIRgB8jF2S9vIC/x8fEyd+5cq/Vvv/22mEwml/qaMGGCXLp0yV1Dg4ccP35cHn300Xz9Mnno0CF56qmnbL62dOlSmTp1qkv9paSkSGxsrKSkpFis9/HxkcmTJ1vVnzVrlpw5c8albeCmMWPGyBNPPCHp6enmdeHh4TJs2DBZtWqVHD9+XJKTkyU9PV3i4+Nl27Zt8tprr0nt2rUt+nn//felXbt2Vu9ZYSlu819x2x94D/P57Yf5HEZDsAPkwg+CcJdp06ZZ/fW9SZMm0rp1a5f7unz5sowbN849A4PHPPvss3L16lWr9U8//bQcO3ZM0tPT5dixY/LPf/5TgoODreqtXLlSDh06ZLEuMzNTRo8ebVW3fv36smXLFklNTZXExESZO3euBAUFWdRJSEiQ6dOnW7Xt3Lmz3HPPPRbrMjIyZMaMGU7tJ/5n3rx58vbbb5uXTSaTjBo1Sk6cOCFz5syR7t27S82aNSUsLEwCAwOlSpUq0rJlSxk/frwcPHhQPvzwQwkLCzO337p1qzz55JPe2JViN/8Vt/2B9zCf336Yz2E0BDtALj/++KO3h4BiIDU1VT766COr9c8//3y++4yLi5PffvutIMOCBx0/flzWr19vtX7YsGHyr3/9S2rVqiWBgYFSq1YtGTNmjLz33ns2+9mwYYPF8urVq+XUqVMW68LCwmTjxo3SunVrCQkJkfDwcBkyZIi8++67Vv3NnTvX5s0XbX0WP/jgAy5dccGhQ4fkmWeeMS/7+fnJokWLZMqUKVKqVKk82/v6+srf//532bp1q1SoUMG8fsWKFTJ79myPjNmR4jb/Fbf9gXcwn99+mM9hRAQ7sDJ//nzz3ffvvPNO83pVlZUrV0rHjh2lfPny4u/vL6VLl5Z69erJs88+K8eOHbPb55QpU8x91qhRw7w+MTFRXn/9dWnSpIlUqlRJAgMDpVKlStKyZUuZPn26JCcn2+3zrbfeMvfp5+fn1L7NmDHDZpucTwvbs2ePef2wYcMsnkZQkL/+ZWRkyOeffy59+/aVevXqSdmyZcXf31+CgoKkYsWK0rJlSxk9erT89NNPTvV369TfzMxM+eijj6Rjx45So0YNKVGihJQpU0bq1q0rI0aMkBMnTjjVX1ZWlqxdu1b+/ve/y7333ivh4eESEBAgISEhEhUVJZ06dZJ33nlHzp8/77AfT7zXuZ05c0YmTZok7du3l6ioKAkKCpKwsDCpVauWdO3aVd5//32r6+Btyfl5MJlMNifx/FqxYoWkpqZarCtdurT06NHD6T6aN29usZyZmSmjRo1yy/hy+/7772Xs2LHSrFkziY6OluDgYAkNDZVq1apJs2bNZOzYsU49Re+jjz6yeopHx44dza+rqixdulS6du0qkZGR4u/vLxEREdK0aVN566235MqVK06POSUlReLi4uTRRx81nxFRokQJqVatmrRp00bee++9PD+v7rRp0yZRVYt1vr6+Nk+TFhH529/+JoGBgVbrT58+bbG8fPlyqzp9+/aVyMhIq/UDBw6UkJAQi3Xnzp2Tbdu2WdWNjY2V0NBQi3XJycmyatUqm+OFtQkTJljcT+f111+Xfv36udzPPffcI5999pn4+Pzvx7IJEyZYXNqVm7vmwPzMf0V5TjfifC7CnF7QOZ35/H+YzwuO+RyG5NV7NxcTxe2pWIsXLza/XqFCBVVVvXz5sjZv3tzh/gUEBOjixYttbnfOnDkWd2tXVd25c6eWL1/eYZ9VqlTR77//3maf//znP831fH19ndr/6dOn22yT+7jYK3v27HFqO7nt2rVLa9Wq5fQTUmJjY63uqJ/7CRqnT5/Ws2fP5nmn/oCAAKsnNuT2yy+/6L333uvU2EJCQnTevHl2+/LEe33LjRs39KWXXtKAgIA8xxkeHq7z58932F/Oz4OI6Lp16xzWd0XHjh2txvTUU0/ZrW/rKRozZ87UqlWrWq3fvHmz3X5cfYrG7t279f7773f6s9miRQuHT+/59NNPrdrcd999qnrziSKtW7d22H/lypX1wIEDDo9tdna2Tp06VUuWLJnneMPCwhx+Xt1p4cKF+uCDD2qLFi30rrvu0oiICG3cuLHDNjVr1rQa84svvmhRp0KFClZ1VqxYYbfPDh06WNV/9dVXbdbt37+/Vd2HHnrI9Z33gKL+VKyTJ0+qr6+veSx/+ctfNDMzs0B9Dhs2zGL/HD3JyV1zYH7mv6I8pxthPldlTld175zOfM587k7M5+7FU7EKBU/FgrWAgADzv9PS0iQjI0PatWsnO3bscNguIyNDnnzySTl8+LDVazn/+paamioJCQnSpUuXPNP306dPS7du3eTo0aMu7kXR8X/s3Xl8TNf/+PH3ZCOLEEEsQexrfShpKVJVay3VUrWV8lHLR9VSXehiKW0tRVtKN1ItqrSq9qJUrVWKqlJLayciEklIIsn5/eFnvrkzdzIzyUwmN17Px+M8Hrl3zjb33sy5855z7/3777+lVatWcvLkSYfLrFixQrp06WL1a0FWJpNJ2rVrZ/dXx7S0NOnbt6/Vdb53nThxQqKiouTgwYMO9S05OVmee+45iY6O1n3dXfs6PT1dOnbsKNOmTZO0tDS7/bx27Zr0799f3n33Xbt5XS0lJUV+/vlnq/WPPfaYU/UkJibKlClTrNaPHj1aMjMzc9y/u7788ktp3ry57q8/tuzcuVOioqJk0aJFuq/r/WJ148YN8/7btm1btvVfuHBBWrduLdeuXdN9PTMzU7p37y5jxoxx6NfAGzduyHPPPScTJ060mze3+vbtK6tWrZIdO3bIX3/9JTExMZoZA5ZSUlLk8uXLVuuzXit/6dIl3Ty1a9e2WW+tWrWs1tn6nNA7Jrds2eLRJzMZxXfffScZGRnm5RdeeEG8vb1zVefIkSM1N2JdtmxZrupzl3t1THfXeC7CmG6Pp8Z0xnMtxnN9jOfIDwjswIqvr6/575SUFJk6dars379fatWqJYsXL5ZLly7J7du3JTY2VtasWSP16tUz509NTZX333/fqs6sJ7upqany8ssvy/Xr1+Whhx6S77//Xi5fvixpaWly+fJlWbp0qVStWtWc//r16zJixAg3vds7hgwZIkopq2tR582bJ0opc2rUqJHTdb/22mvmKbx+fn4yduxY2bdvn1y/fl3S09MlMTFRTp48KUuWLNFM1d22bZssX77cZr3Tp0+XQ4cOSY0aNeSLL76QixcvSlpamly9elW+++47qVOnjjlvenq6zTvwDxs2TDPFuUOHDrJ69Wq5cOGCpKamSnJyshw4cEBGjBihuUxg9OjRulOt3bWvx44dq7lWuVq1avLJJ5/I0aNHJTk5WZKSkuTw4cPyzjvvSGhoqKbcli1bbG5Hd9i5c6fVJRTe3t7yyCOPOFXP9evXpXfv3lbH3eHDh3Wv93fGunXrpF+/fg6dUFu6ffu2PPvss7Jp0yar17IGhu+6ceOGTJ8+XXbv3u1Q/TExMTJp0iTd11566SXdqcz2TJgwQVauXOl0OXeaOXOm1Y0ZQ0JCpHPnzuZlW5ddhIeH26xX7zVbl8q2atXK6okuSUlJsmfPHpv1446sX2pMJpM8/fTTua6zevXqmv/3PXv2OP3odGflZPzLz2O6EcdzEcb0/DqmM55rMZ7rYzxHvuCJeUIFTUG7FCvr9GCTyaQKFy6s2rRpo27evKlbZ2xsrCpevLi5TMWKFa3yLFy40Gp7dOnSRd2+fVu3zvj4eFW9enVN/sOHD2vyuPJSrLtu3bqlaTO7afCOyMzMVAEBAeb6ZsyYYbdMnz59VFhYmGrUqJGaOXOmeb3ltO1ChQqpVq1aqeTkZN16rl27pkqUKKGZEmvp1KlTVvskO++++64mv950cHfs69OnTysfHx/z6+3bt7d5PCql1Pnz51VERIQ5f926dbN9X66W9di8m+rUqZNtGb2p28OGDVNKKfXzzz9bvRYWFqZu3LhhVY8jU7fj4uI0x0bW1Lt3b7V7926VmJiokpKS1K5du1S3bt1085YpU8bq+Fu3bp1VvoCAAFW0aFHl5eWlRo0apU6ePKlSUlLUwYMHVadOnXTrDg0NtTpmjhw5ory8vKzyNmjQQK1bt05dunRJxcfHq507d6r27dtb5atcubJKTU3NyS51iYyMDBUTE6M2b96sevToYdU/Ly8vtWLFCk2Zb775xiqfn59ftu1ER0dblfH397eZX2/6+KxZs1zynnMjv1+KFRoaau5H7dq1XVbvqFGjNO8xLy5HVsq58c8IY3p+Hs+VYkw3ypjOeM54rofx3DlcipUnuBQL2VNKSeHChWXx4sVWj927KzQ0VLp3725ePnPmjNVN5iwFBQXJZ599ZvMGiUWLFpVp06Zp1q1Zs8bJ3ntefHy83Lx507xs+ThCPV9++aVcvnxZ9u3bJ6NGjbKZLyAgQJYuXar7iEURkeLFi0uPHj3MyxcuXLDaLxcuXJDmzZtL9erVJTg4WJ5//vls+zZ8+HDNjC5Hnjjiin09a9Ys81MASpYsKUuWLLF5PIqIlCtXTubPn29ePnLkSJ4+9vbQoUNW6xzZ95buvueoqCh5/PHHNa9duXJF3nnnnRz1b/78+RIbG2u1fuLEifLVV19J48aNJSgoSAIDA6VJkyayfPly3WPj0qVLsmTJEs06y1+LRO5c0pmQkCDvv/++zJw5U6pUqSKFChWS//znP7Jy5Uqrm0qK3Jl2f+zYMc26KVOmWE1Zj4iIkG3btkn79u2ldOnSUrRoUXnooYdk3bp10qFDB03e06dPe+RXvj179ojJZBJvb28pVaqUtGrVSr7++mtNnrJly8oPP/wgXbt21ayPi4uzqs/yBomOvH7r1i2bN+LNOuvyLr1jGP8nPT1dc3mB3nT5nKpbt65m+dKlSy6r213uhTHdneO5CGN6fh3TGc+1GM8Zz5F/EdiBXc8++6yUKFEi2zz169fXLNt7esFTTz2lmVqrp0OHDpoPtJ07d9rpaf4THBysmca8du1al9U9YMAAu/vlvvvu0yxbDirNmzeX7du3y/HjxyUhIUEeffTRbOsLCAiQ8uXLm5f1TiYsuWJfr1+/3vx37969pVixYnbbbdu2raavq1evtlvGVfTuv1CjRo1c1Tlt2jTNCbjInZNjy8dmOuLTTz+1WlezZk15/fXXbZaZOnWqFC9e3Gr9l19+6VCbjRo10j2Z9Pb2tvlkkKzTjTMyMjTHwV0jR46U4OBgm322lJNp3+7i7e0tXbp0kYULF8rJkyetTlxFRPfkzfI4cPR1W4891Ts2HX3yzr3K8p4Rev8bOWVZl637U+Qn98KY7s7xXIQx3R5PjemM59YYz60xniM/ILADu+ydGIiI1clI1l+19DhybbKPj480aNDAvJzd49TzK29vb2nRooV5efbs2TJ8+HC5cOFCrutu1aqV3TyW+8XWQOCMrL+q3f0FKju53deXLl3SnFhlzWdP48aNzX8fPnzY4XK5dfHiRat1ZcqUyVWd1atXlyFDhmjWpaSkyKuvvupUPWfPnpV//vnHan2vXr0091uwFBAQIB07drRav2/fPoeOg2effdbma3q/8Inc+YX8rt9//12zfNcDDzxgs97atWtLSEiIZt3WrVvt9DTvZGRkyMaNG+Xzzz+XBQsW6J70Zb057132btBr60TQ1g0Uy5UrZ7Xu/Pnz2bZxr7OcKWFrlkVOWP5Ca28GbH5wL4zp7hzPRRjTHeGJMZ3x3BrjuTXGc+QHBHZgV0REhN08lnfOV3ae/mD5q5MtFStWNP997tw5h8rkN9OnT9ecOM2ZM0cqVKggTZs2lTfeeEO2bNlic0pldipUqGA3j+WN77LbL1euXJEFCxbIgAEDpFmzZlKtWjUJCwuTkJAQCQoKksKFC4uPj4/8+eefTvUzt/v67Nmzmnz9+vUTk8nkUMp6s8q8fArL1atXrdaVLl061/WOHz9eihYtqln39ddfO3VjPFtT7R25kajeCfitW7ccekJM1hNySyVKlNA9Cc1601i9k1eROyeRtva/l5eX1ezBa9euyZUrV+z2N6/cunVLduzYIc8//7zUqlVLDhw4oHld73IHvZPDrGyd8Nk6QdT7kpKftlF+ZDnDQO+mszllWZfll5n86F4Z0901noswpufXMZ3x3BrjuT7Gc3gagR3YZe/6z5xwdNp61kHv1q1bLnkkZF5r0KCBbNq0SSpVqmRel5mZKbt27ZLJkydLq1atJCQkRNq1ayefffaZw18QXPULcWpqqowaNUoqVqwo//3vf2XhwoWyc+dOOXnypMTExEh8fLwkJydLamqq3QFIT273td41yTmh9+uQO9y+fVt3IHbF/goNDZXXXnvNan3WezfoXROfld5Jqsida8LtsXUy68g+yu5E2Nvb2+oENydtOMqZRxW7QuPGjUUpJZmZmXLt2jX5/fffZfLkyVZf2P/9919p2bKlZtq03nFj79Gltl63dQzqrXfFTICCLCQkRPO/5sglLI6yPNbtXfaSH9wrY7q7xnMRxnRn5cWYznjuXFkRxvO7GM/hCQR24BGBgYEO5bP8dSonj3LMD5o2bSonTpyQr776Sh588EGrwTolJUU2btwozz33nERERMg777yTJye8qamp0rJlS5k9e7bbHqmb231t+fjInMqryxlsbcfChQu7pP4XXnjBahbdnj17ZOnSpSKi/4tQVomJibrrs7txpb08turMynJWn6Xspo2LuHb/3bhxw2V1OcNkMknx4sWlfv368tprr8lvv/0mJUuW1ORJSEiQl156ybys96Xe3rbQ2x+BgYE294HeflVKuf0x20bm5eWlud/H77//7rK6LW90mXXmQ351L43p+XU8F2FMdzXGc32M54znyJ8I7MAjHP2AyTql2WQy2R1M8jNvb2/p3bu37NmzRy5duiQLFy6UHj16WA0E8fHxMm7cOHnyySdz9GuaM9544w3ZtWuXednX11f69esnX3/9tfz2229y+vRpiYuLk8TERLl165akp6dLnTp1nGojt/u6SJEimnwbN24UpZTTyZWXSuSEvcsTHVWoUCHdp2e8+uqrkpKSYveE09aNCR052baVx96vc65geRzkhiMnrnmhcuXKmpO+u1avXm0+WdW7Xj4tLS3bk0G9X3Gzu8zDVcfmvaZp06bmvy9cuCD//vuvS+rNeilG8eLFHb70xZPutTE9P47nIozpeYXxPHcYz/8P4zlcicAOPMLRATnrVNsiRYrYnZZqj6ci+5bCwsLk2WeflaVLl8qVK1dk//798uqrr2ru27Bq1SqZN2+e2/qQkpKieZpCSEiI7N27V6Kjo+Xpp5+Whg0bSqVKlTTX43t7ezt9cprbfW15L4v8/oQYW7+C5fS+C3p69OghDz74oGbd2bNnZebMmXafLmL5xeMuR26uZ+smobbqdCVb9xk5cOCA018Iunfv7vb+OioyMtJqXXp6uvm+FzVq1ND93LO8T4W912rWrGkzv96xaeQv3XklKipKs7xw4cJc13n8+HHNfTMefvhhu79+O8NdY+C9PKbnh/FchDHdHRjP3YPxXIvxHK5CYAcecezYMYfyZf0F1HI6etYPx4yMDIdOTlz1i6ormUwmuf/+++Wdd96RP//8U6pVq2Z+bdq0aW5r948//tCceI0bN87u0ynS0tKcvuFlbve15UB45MgRp9rPa97e3ro3tbP3pDhnvffee1br3n33Xbv/B/fff7/u+l9//dVum3p5QkJCpHLlynbL5latWrV01+eXG7CmpKTIsGHD5KmnnpKHH35YatWqJaGhobqPaM3K1pf2u5ctFC1aVKpXr271+h9//GGzTr2nxVh+cchK79h05VOeCqqnnnpKs53mz5+f60DDhx9+qFnu16+fzbz5aQxkTL/DUzJMAMoAACAASURBVOO5CGO6OzCeuwfjuRbjOVyFwA484pdffrGbJy0tTQ4ePGherlGjhuZ1y19S7P3qk5mZKT/99JMTvcx7ZcuW1dxM79y5c26bZnrp0iXNcnZPObjrhx9+cPr6+Nzu62LFimlOjtesWeNU+55QqlQpq3UxMTEubaNp06bStWtXzbrExESZO3dutuUqVKig+6S7JUuWZPuY07i4OFm3bp3V+qioqFz/6u6IOnXq6P566cjxlRcKFy4s3333naxYsUK2b98ux44dk7i4OFm7dm225Szvp3JXWFiY+e9OnTpZvb5p0ybdcvHx8bJ7926r9V26dLHZB8vPAhHXPPWloAsNDdU89jcmJkZGjhyZ4/r27NmjmdVRp04d6dy5s838+WkMZEy3lpfjuQhjurswnrse47kW4zlchcAOPGLJkiV2bxi2cuVKzZ3cW7RooXnd8skMWU8i9Hz77bdy5swZp/qZ22vi586dK926dZOIiAhZsmSJQ2UsH1Xoymn42dVr74QzPj5eXn31Vc06R6Yju2JfZ/1yc/jwYVm/fr3ddlNTU6V+/fry1FNPSXR0dJ49FUtE/4kUFy9edHk7U6dOtbpBZdb7K9gyaNAgq3WnT5+Wt956Szd/Zmam/O9//9P9JWjw4MEO9jZ3TCaT7snM/PnzbT4VY926dRIUFCSVK1eWxo0bS+fOnTVPHBER2bBhg+6jVXfs2OF0Hzt06GC17pdffpEvv/xSN39ycrLMmTPHan3x4sU1X3x69epllWfZsmVy+fJlq/UffPCB1VM0GjVqZPUlOiu9Y1PvXgCwNnbsWM1YtHDhQpk0aZLT9Rw9elS6du1qvsmuyWSSqVOnZvsly91joDPjnxHG9II8nuvVzZjuGoznrsd4rsV4DlchsAOPiImJkeHDh9u8yVdsbKy88sor5mVvb2/p2LGjJk/t2rU1y/Pnz7fZ3tGjR2XYsGF2b0Tn7e2tWc7ttNA9e/aYTz5fe+01OX36tN0yy5cvN/8dHh7u8BMonJX1ca0iIitWrLCZ9+LFi9KuXTuJi4uTBx54wLzekWnwrtjXgwcP1py0DhgwQI4fP26zzbS0NPnvf/8rhw4dkhUrVsigQYPy9EaLWQfxu7Lrb05VqVJFhg0b5nS5oUOHSokSJazWT5o0SQYOHCiHDh2S1NRUiY+Pl02bNknr1q1l2bJlVvkbNWok7dq1y1Hfc2L06NFWX3STkpKkWbNmsmDBArly5Yrcvn1bzp07J3PmzJEePXpIcnKy/PPPP7J3715ZvXq1W68zHzp0qO4X8f79+8uYMWPk1KlTcvv2bTl//rx899130qhRI/n777+t8nft2lXzWdSgQQNp3ry5Jk9SUpK0b99eduzYIbdu3ZIrV67ItGnTdIMKo0ePzrbfesdm1apVsy2DO8LDw2XBggWadePHj5devXrZvIdFVkop+eKLLyQqKkpzQv7SSy/pfrHIytVjYG7Gv/w4pt9L47kIY7q7MJ67B+P5/2E8h8so5Fp8fLwSEbupW7dunu6qmjdvnqZPv/zyi1We1atXa/L8888/duu1LPPXX39pXl+4cKHm9e7duysRUVFRUWrVqlXqypUrKi0tTV26dEl9+eWXqmLFipr8ffr0sWrz9u3bqnTp0pp8ffv2Vfv371fJyckqNTVVHTt2TL311luqSJEiytvbW02ePNmc19vbW/e9BAUFmfOULl1a7dq1S6WkpKiYmBh15swZxzb0/7dv3z5lMpnM9RUvXlxNnjxZ7du3T8XHx6v09HSVlJSkzp07p9auXasef/xxzfsZN26c2/ZLZmamCg8P17w+bNgw9eeff6pbt26puLg4tXv3bvXyyy+bt8m8efPU0KFDzflNJpNasmSJunXrlrpx44bb9rVSSr3yyiuafIGBgWr8+PHq8OHDKikpSd24cUMdO3ZMzZs3T9WtW1eTd+jQobp1zpo1S5Nv/fr1Tuxd26ZOnWr1/1+nTp1sy3z66adWZQYPHmy3rbi4OBUSEpLtZ88rr7xiVW79+vWaY9PZVKRIEfX333/r1quX/+rVq9m+j9DQUKsy8+bNs8o3evToHPe5cuXK5uPUXn/1PhsdMXjw4Bz37+5xfe7cOat6Dx48qLy9vZ2ur0WLFnb7XKVKFatys2fPztH7d6Vdu3bZfX9nz571dDeVUkrNnj1beXl5We3Lvn37qhUrVqgTJ06ohIQElZKSos6dO6d27dqlJk6cqO677z6r99S7d2+Vnp5ut013jIGOjn9GGdPz63iuFGO6q8d0xnPGc8ZzY47nbdq08XT3CopvCOy4AIEd5wM7f//9typatKhD2y08PFxdvnxZt90ZM2Y4/IE4btw4tXnzZvOyyWTSrbNVq1Y263jxxRftb2QLY8eOzdGAUK9ePZWcnGxzG7tiv1geD9ml7t27q4yMDPXFF1/ovv74448rpdy3r1NTU1X79u2d3o4NGzZUSUlJunW660Rwy5YtVv3w9vZW8fHxNsvk9ERQKaVmzpyZ7TbQOxFUSqkvvvhC+fn5Ob1NS5YsqXbs2KFbp7tPBNPS0lTHjh2d7nNYWJj6448/HO5vTk8E09LSVKdOnXL0P+/n56c2btxos25n/l9FRFWrVk1duHAh2/7GxsbqfiGwtX/zkpECO0optXLlSoc/6/SSt7e3mjJlilNtunoMdHT8M8qYnl/Hc6UY0109pjOeM54znhtzPCew4zLfcCkWPKJMmTKyfv16uzf0qlmzpmzYsEFz47GsRo0aJc8884zd9saMGSNTpkzR3BleKWW+U31W48aNc+l18FOmTJHp06fbfGymnh49esjPP//s9jvZDxkyxKGpv/3795clS5aIl5eXdO3a1anrdV21r/38/OSHH36Ql156yaHptyaTSQYMGCBbt2516/R3PU2bNrXa3xkZGbJ161a3tDds2DCpUqWK0+X69u0rv/zyizz00EMO5TeZTNK9e3fZt2+fNG3a1On2XMHX11dWrVolEyZMcHi/PvbYY7Jv3z6pW7euw+3k9DPgbv9mzJhh85GueiIjI2Xfvn3Spk0bm3mGDBkiixYtktDQULv1tW3bVrZt26Z7f4isNm3aZHVJRZEiRbJ96gb0denSRU6fPi0vvvii3ct+s/Ly8pKePXvK0aNHZdy4cU616eoxMKfjX34d0++l8VyEMd0dGM/dh/Gc8Rwu5tG4UgHBjB3nZ+zc/aUjISFBzZ07V0VFRaly5copPz8/VaZMGRUVFaU++ugjq1+4bFm7dq3q1q2bqlChgipcuLDy8/NTFSpUUH379lUHDx405zt8+LCmH3Fxcbr1bdy4UTVr1kwFBAQoPz8/FRYWplq0aKG+//57h/qj5+rVq2rWrFmqY8eOqkqVKiooKEh5eXkpf39/VbZsWdWyZUv1+uuvqz///FO3vDv2y10//vij6tatmwoPD1d+fn6qcOHCqkqVKqpv375q+/btVvmPHj2q2rRpowIDA1WhQoVURESEevvtt5VS7t/XSil19uxZ9fbbb6uWLVuq8PBw5e/vrwoVKqTCwsJUVFSUev3113WnFVty1y98SinVrl07q8+A5557zmb+3PzCp5RSK1ascPoXvqy2bdumxowZoyIjI1XZsmVVoUKFVFBQkIqIiFAtW7ZUU6ZMsXlsZuXuX/iyunr1qpo5c6bq2LGjioiIUEFBQcrPz0+VLFlSRUZGqlGjRqn9+/fnqL+HDh2y+17tSUxMVJ999pnq3bu3qlmzpipRooTy8fFRAQEBqmzZsqp58+Zq9OjRTv+adu3aNTVz5kzVqlUrFR4ergoVKqSKFSumatWqpQYNGqR+/PFHh+t65plnrN57ly5dnH2rbmG0GTtZxcXFqYULF6q+ffuqBg0aqNDQUOXr66sKFSqkypUrp+rXr6969uypFi5caPdXWEe4cgx0ZPwz0pieH8dzpRjTs3LFmM54/n8YzxnPjTSeM2PHZb4xKWXj7mdwWEJCgu5j+yx169ZNcyO9e0l0dLT079/fvHz9+nWHthmMh319x6JFi6Rfv36adcWKFZPLly+79YZ/yLmKFSvK2bNnRUTkzJkzUqFCBQ/3yL1u3rwpYWFhVk+4WbZsmXTv3t1Dvfo/u3fvtvvr89mzZ6V8+fJ51CPcxef8vYN9zXhuRIzndxhhPG/Tpo1s3Lgxj3tUIC3nUiwAcIOuXbtKUFCQZl18fLx8//33HuoRspOcnCznz58XEZGAgAC7U54LghUrVlidBBYtWlTzKGIAuNcxnhsL4/kdjOf3HgI7AOAGgYGBMnDgQKv1M2fO9EBvYM/q1aslMzNTREQaNmwoPj4+Hu6R++kdi4MGDXLq/jAAUNAxnhsL4/kdjOf3HgI7AOAmo0ePFl9fX826X3/9VbZt2+aZDsGmjz76yPx3ly5dPNiTvLF+/Xo5dOiQZp2fn5+MHDnSQz0CgPyL8dw4GM8Zz+9VBHYAwE3Kly8vQ4YMsVr/yiuvWD25AJ6zevVq+eWXX0TkzrRtR57KY2SZmZm6T196/vnn74kp6wDgLMZzY2A8v4Px/N5EYAcA3GjChAlWj8n89ddfZenSpR7qEbKKiYmRQYMGmZdff/11KVmypAd75H6LFi2SgwcPataFhobKG2+84aEeAUD+x3ievzGe38F4fu8isAMAblS8eHGZNm2a1foXX3xRrl+/7oEeIatSpUrJpUuXRCklSikZO3asp7vkVrGxsfLyyy9brX/vvffuuSfdAIAzGM/zN8bzOxjP710EdgDAzQYOHCitWrXSrLt8+bKMGjXKQz3CvWrEiBFy9epVzbp27dpZPcoXAGCN8Rz5BeM5LJkUF4bmWkJCgkOR0W7dusny5cvzoEcAABjb7t275aGHHso2z9mzZ6V8+fJ51CMAAOCs7MbzNm3ayMaNG/O4RwXScmbsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYFIEdAAAAAAAAgyKwAwAAAAAAYFAEdgAAAAAAAAyKwA4AAAAAAIBBEdgBAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACDIrADAAAAAABgUAR2AAAAAAAADIrADgAAAAAAgEER2AEAAAAAADAoAjsAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYlI+nO3Av2bhxo9SuXdvT3QAAIN+7deuW3TyPPvqo+PhwKgMAQH7lyHiO3ONsKA8lJibKX3/95eluAABQIJw4ccLTXQAAAPA4LsUCAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACD4qlYLhAcHCxnz571dDcAAMD/V7t2bUlKStKs69mzp0ydOtVDPQIAAFn5+/t7ugsFBoEdFzCZTFK+fHlPdwMAAPx/Xl7Wk5IDAwMZrwEAQIHDpVgAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYFIEdAAAAAAAAgyKwAwAAAAAAYFAEdgAAAAAAAAyKwA4AAAAAAIBBEdgBAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACDIrADAAAAAABgUAR2AAAAAAAADIrADgAAAAAAgEER2AEAAAAAADAoAjsAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYFIEdAAAAAAAAgyKwAwAAAAAAYFAEdgAAAAAAAAyKwA4AAAAAAIBBEdgBAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACDIrADAAAAAABgUAR2AAAAAAAADIrADgAAAAAAgEER2AEAAAAAADAoAjsAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYFIEdAAAAAAAAgyKwAwAAAAAAYFAEdgAAAAAAAAyKwA4AAAAAAIBBEdgBAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACD8vF0BwAAABxx/PhxSUpKcihvRkaG1brY2FjZv3+/Q+XLly8vpUqVcqp/AAAAnmBSSilPdwIAAMCel156SWbMmJEnbe3du1ceeOCBPGkLAAAgF5ZzKRYAADCEHj165Ek7VapUkcjIyDxpCwAAILcI7AAAAENo2LCh1KhRw+3t9OzZU0wmk9vbAQAAcAUCOwAAwDB69uzp9jbyamYQAACAKxDYAQAAhtG7d2+31l+/fn2pU6eOW9sAAABwJQI7AADAMKpWrSqNGjVyW/3M1gEAAEZDYAcAABiKu4IvJpNJnn76abfUDQAA4C4EdgAAgKH07NlTvL29XV5vs2bNJCIiwuX1AgAAuBOBHQAAYChly5aV5s2bu7zevLgxMwAAgKsR2AEAAIbj6iCMj4+PdO3a1aV1AgAA5AUCOwAAwHCeeuop8fPzc1l9bdq0kVKlSrmsPgAAgLxCYAcAABhOSEiItG3b1mX1cRkWAAAwKgI7AADAkFwVjClcuLB07tzZJXUBAADkNQI7AADAkB5//HEJCgrKdT2dO3eW4OBgF/QIAAAg7xHYAQAAhhQQEOCSmTZchgUAAIyMwA4AADCs3AZlihUrJu3bt3dRbwAAAPIegR0AAGBYbdu2ldDQ0ByX79q1qxQqVMiFPQIAAMhbBHYAAIBh+fr6SteuXXNcnsuwAACA0RHYAQAAhpbT4Ezp0qWlRYsWru0MAABAHiOwAwAADC0qKkrCw8OdLtejRw/x9vZ2Q48AAADyDoEdAABgaF5eXvL00087XY7LsAAAQEFAYAcAABies0GaKlWqSGRkpJt6AwAAkHcI7AAAAMNr2LCh1KpVy+H8vXr1EpPJ5MYeAQAA5A0COwAAoEDo3r27w3lzcukWAABAfkRgBwAAFAh9+vRxKF/9+vWlTp06bu4NAABA3iCwAwAACoSqVatKw4YN7ebjpskAAKAgIbADAAAKDHtBG5PJ5NQlWwAAAPkdgR0AAFBg9OzZU7y9vW2+3qxZM4mIiMi7DgEAALgZgR0AAFBglC1bVpo3b27zdS7DAgAABY1JKaU83Yl7Ta1atSQxMdHT3QAAoEBKTk6W+Ph43dfKlCkjXl78rgUAgDv07NlTpk+f7ulu3GuW+3i6B/eiCxcuENgBAMADLl265OkuAABQYMXFxXm6C/ckfrICAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACDIrADAAAAAABgUAR2AAAAAAAADIrADgAAAAAAgEER2AEAAAAAADAoAjsAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAAAAAAAAMisAOAAAAAACAQRHYAQAAAAAAMCgCOwAAAAAAAAZFYAcAAAAAAMCgCOwAAAAAAAAYFIEdAAAAAAAAgyKwAwAAAAAAYFAEdgAAAAAAAAyKwA4AAAAAAIBBEdgBAAAAAAAwKAI7AAAAAAAABkVgBwAAAAAAwKAI7AAAAAAAABgUgR0AAAAAAACDIrADAAAAAABgUAR2AAAAAAAADIrADgAAAAAAgEER2AEAAAAAADAoAjsAAAAAAAAGRWAHAAAAAADAoAjsAAAAAAAAGBSBHQAAAAAAAIMisAMAAAAAAGBQBHYAACIi0qxZM1FKWaWDBw96umsAsvD19ZWtW7ea/0fPnj0rYWFhnu4W8oFu3bpJZmam+dh4/vnnPd0lAEAeILADAABgIPPnz5cWLVqIiMjNmzelS5cucuXKFc92CvnCihUrZNKkSebl2bNnS7t27TzYIwBAXiCwAwAAcq1x48Yyffp0+fnnn+XixYty8+ZNSUlJkcuXL8sff/wh0dHR8t///leCg4Nd2q6/v78cP35cd7aZUkoaNWqkWy48PNxmmZymd99916XvTc8LL7wgAwYMMC8PGTJEDhw4oMkzcOBAh/qbmZkpCQkJcubMGTl48KB8++238sorr0jLli3F39/f7e8F7jFx4kRZu3atiIh4e3vLsmXLpHLlyh7uFQDArRTyXJEiRZSIkEgkUr5KzZo10/3MOnjwoMf7Rsq/qUmTJurAgQMOj4FJSUlq+vTpyt/f3yXtz5o1K9v2GjVqpFsuPDzcqbHbEe+++65bt3XdunVVSkqKub1vv/1WN9/AgQNz/V6uX7+uPvjgA1W3bl2PH2Mk51Pp0qVVbGyseX/u2rVLeXt7e7xfJBKp4KcBAwbkegyC075hxg4AAMiRESNGyM6dO6VBgwYOlwkMDJQxY8bIgQMHpEyZMrlqv3nz5vLCCy/kqg6j8PX1lcWLF0uhQoVERCQ2NlYGDx7stvaKFSsmw4cPl8OHD8vcuXMlMDDQbW3B9S5fvqy5v06TJk3k1Vdf9WCPAADuRGAHAAA4bfDgwTJ79mwxmUw5Kl+zZk3ZsGGD+Pj45Kh8YGCgLFy4ULy87o1TmWHDhkm9evXMyxMmTJDY2FiHym7cuFFMJpNV8vLykpCQEKlcubI8+uij8vrrr8vmzZtFKWUuazKZ5H//+58cPnxY0z7yv6+//lp27txpXn7ttdekfPnyHuwRAMBd7o2zIQAA4DI1atSQWbNm5bqeevXqyaBBg3JUdtq0aVKlSpVc98GVMjIy3FJvaGiovPnmm+bl48ePy8cff5zrepVSEh8fL//884/89NNPMmXKFGndurVUq1ZNPvroI02Ap3LlyvLjjz9K1apVc90u8s6LL75o/tvf31+mTp3qwd4AANyFwA4AAHDK2LFjbd5cNzo6Who2bCiFCxeWkiVLSrNmzeT777+3WVffvn2dbr9ly5YydOhQzbrr1687Vcf58+d1Z7E4koYMGWJVX0pKiixcuNDp9+KIUaNGSUhIiHl5ypQpkp6e7pa2REROnTolw4YNk7Zt20pMTIx5fVhYmGzatEmKFy/utrbhWnv37pUNGzaYl3v27Cm1a9f2YI8AAO5AYAcACrDAwEB59tlnZcOGDXL69Gm5deuWXL16VX7//XeZP3++REZGmvNm/XU+pwoVKiQ9e/aUTz75RA4dOiRXrlyRtLQ0iY2NlSNHjsg333wjPXr0cPh+HcWKFdN9ms+aNWs0+UJDQ2Xs2LGyc+dOiYuLk7S0NLl8+bLs2bNHxo0bJ6VKlXL6vfj5+cnjjz8u8+bNk127dsnFixclKSlJ0tPTJT4+Xo4fPy7ff/+9jBgxIleXN7h6m7lbkSJF5Omnn9Z9bebMmdK/f385cOCApKamSmxsrOzcuVOeeOIJmzNMIiMjxdvb26n2FyxYoLkELDExURYsWODcG8mhiIgImTFjhtX6KVOmyMmTJ13enr+/vyaQdOXKFVm2bJnL29GzadMmeeyxxyQ5Odm8LiIiQsaPH+9UPSEhITJs2DBZvny5nDx5UuLj4yUlJUXOnTsnv/32m8yZM0ceeeQRh4+D4OBgzefBJ598onm9devW8uWXX8qJEyckOTlZ0tLSJCYmRnbs2CETJ050+t5O/v7+0r17d4mOjpYDBw7I1atXJSUlRdLS0uTatWty8OBBWbx4sfTt2zfH/6eu3kZZffjhh5rlkSNH5qiPAIB8zDM3bb638VQsEomUFykqKkr9+++/dj+ToqOjVaFChdSDDz6o+7ojT8UymUxq5MiR6sqVKw59Dl66dEl1797dbr0+Pj665Xfu3GnO061bNxUfH59te3Fxceqpp55yaLt5eXmpoUOHqqtXrzr0XpRSKi0tTX3yySeqaNGiDu8fd20zd6dHHnlEt3+xsbHKz8/PZrlq1arZfG8lS5Z0uP1PP/3UqvyoUaPU5MmTdeu29VSsnCSTyaS2bt1q1cbRo0ezfe+5SZZPuJo0aZLTZTZs2JCrPvTs2VNTX1pamqpevbrdcr6+vmrKlCkqMTHR5r7P6sCBA+r++++3W6/l58KSJUuUiKjQ0FC1fv16u+3cunVL9ejRw6H33qNHD3Xx4kWH+q/Unf+DQYMGObxt3bWNLI/bU6dOad5/sWLF3HK8kkgkEk/F8ohvCOx4AIEdEonk7tSuXTt1+/Zthz+X1q5dm+PATlBQkFq3bl2OPg+nTZtm972kpaVZlTt69KgSEfX000+rzMxMh9pKT09XnTp1yrYtX19f9fXXX+fovSil1KlTp1TFihXtvid3bzN3pubNm6tFixaptWvXqt27d6u///5bxcbGqhUrVmRbLjAw0OZ7cvTR523btrUqu2fPHuXt7a1mzpypW7crAzsjRoywqj8zM1NFRUW5bXtv2rRJ054jjx93dWDHZDKp3377TVPnZ599lm2ZkJAQ9csvv9jc57akp6erJ554wm6fMjIyzGVWrVqlAgMD1cGDBx1uJyMjQzVt2jTbNl544QWn+3/XW2+9Zfc9uHsbZU1Tp07V1NGvXz+3HbMkEuneTgR2PILAjicQ2CGRSO5MlSpVcvjX36y++OIL3fXZBXa8vLzUDz/8kKvPnB8OCgAAIABJREFUxDFjxmT7fm7cuGFV5ty5c6py5coqKSnJqbYuXryY7WfwpEmTcvVelFLqzz//VIUKFfLoNsuP6f7777e5vRwpX6xYMXX+/HlN2Zs3b6oaNWooEVGzZ8/Wrd9VgZ1q1aqpmzdvWtX/+eefu22bFS9eXBOgPXHihEPlXB3YEbkzMy6rhIQE5evra/MYt5w5k56erj7++GMVFRWlihYtqvz8/FSFChVU79691b59+zR5U1JSVJMmTbLtT0pKijn/xo0b1YcffqiUUioxMVG99dZbql69eiogIED5+/ur6tWrqzFjxlh9luzdu9dm/TVq1FCpqanmvJmZmerzzz9XrVq1UmFhYcrPz08FBASoihUrqu7du6vvvvvO6tho3LixzfrzYhtlTZaB+9WrV7vtuCWRSPd2IrDjEQR2PIHADolEcmdaunSpzc+f77//XjVp0kQFBASoYsWKqS5duqjDhw8rpZTNmS/ZBXbGjBmjWyYxMVGNHj1aRUREKF9fX1W6dGk1cOBAdfnyZau8t27dUpUqVbLZRlxcnFWZ2NhYtXz5ckc+cq0MGTJEt51ixYppvizedf78efXcc8+pqlWrqsKFCytfX18VFhamnnjiCbV3717dNl566SWPbrP8lvz8/NSPP/7o9LbKmvQCj8OHDze/7s7AjpeXl9q1a5dV3VevXlWhoaFu225du3bVtDdnzhyHyrkjsBMcHGw1C9BW4MJypktCQkK2s2O8vLzMgZm7Dhw4oEwmk80yWYNsV69eVZmZmerUqVOqcuXKNss8/PDDVp9zti4pmzZtmibf//73P7vbqE+fPpr6s5vFlhfbKGsymUyaz9KbN28qHx8ftx27JBLp3k0EdjyCwI4nENghkUjuShUrVrQZoPnqq690ywQFBan9+/fb/MyyFdgpUqSIio2NtcqflpZm8wtfpUqV1LVr1xzum4jotpGZmWl+nwcOHFCPPfaYCg4OVsHBweqxxx5TR48etfl+Nm3apNtOr169dPM/+OCDNvsWGBioDhw4YFXm2LFjHt1m+SEFBwerGjVqqBdeeEEdOXJEd9seOHAg29lNd1OnTp2sym7evFnzpdadgR1bl+Q899xzbt2G06dP17TXp08fh8q5I7AjIlaXDQ0bNswqj5+fn9XMqo4dO9qt28vLS+3YsUNTrmvXrjbzW87WS0tLU//5z3/strNlyxaHtmnWeyndunXL4SDIkiVL1JkzZ9T27dvVvHnzdPPk1TayTBs2bNCUdfZePSQSieRIIrDjEQR2PIHADolEcld68cUXdT93kpKSsp1Z0KBBA5ufWbYCO6NGjdLNb+/SFL0ZK8nJySowMFA3v14g5K6ffvpJNzAQGhqqzp07p1vm2rVruu289tpruvntfWb36tVLxcbGqkOHDqm1a9eqjz/+WL3xxhu6N9PNq23mqdS4cWOb+8rS9u3bVYkSJezWWbx4cXXp0iVN2fj4eFW+fHlNPncFdsqUKaMSEhKs6j106JDy8vJy6/b8+eefNW1WrVrVoXLuCuxER0dr6p0xY4ZVnu7du2vy2Aqk6qU2bdpoyi5btsxmXsvAzqJFixxqw/L/3NbNqA8dOmTOk5SU5NL9mlfbyDJNmDBBU3bo0KFuPX5JJNK9mQjseMQ3PO4cAAqQ1q1b667/4Ycf5Nq1azbL/f7777Jnzx6n2nryySd113/33XfZlvvmm2+s1gUEBMhjjz3mVPs3b96Uvn37SmpqqtVr165dk3fffVe3XPHixSUkJMThdvr06ZPt60uWLJESJUrIf/7zH+nQoYMMHjxY3nrrLUlLS7PK6+ltlh/89ttv0rdvX3n44YclNjbWbv65c+dK6dKlNeteeOEFOXfunLu6qPHee+9JcHCw1frRo0dLZmamW9uuUaOG+e/bt2/L6dOn3dqePZb7q3jx4lZ5WrZsqVlevHixw/Vv3rxZrl+/bl5u3769w4/3XrJkiUP5/vnnH81y0aJFdfPFxMSY/w4MDJROnTo5VL8jPLWN/v77b81y9erVHW4XAJC/EdgBgAKkbt26uuu3bt1qt+z69esdbsfHx0caNWqk+9rx48ezLXv27FlJSEiwWh8ZGelw+yJ3gh3nz5+3+fqaNWtsvqb3Ze7MmTO6eefOnSsrV66Ubt26SYkSJZzqY1b5YZt50o0bN2TWrFny0ksvyeLFi0UpZbdM165dpUePHpp1K1eulEWLFrmrmxoPPvig9OzZ02r95s2bZcuWLW5tu3DhwlKqVCnz8vnz590eSLLHMjgcEBBglScqKkqzvGPHDofrz8zMlF27dpmXixQpIlWrVnWo7N69ex3Kl5SUpFnWew8id/ZxVkuWLJEhQ4aIn5+fQ+1kx1PbyDKoVbFiRYfbBQDkbwR2AKCACAwMlHLlyum+ZvlLrZ6DBw863FbFihWlcOHCuq+dOHFClFLZJr3Ayn333edw+yIiGzZsyPb1c+fO2fwiXKhQIat169at0539YzKZpEuXLrJ8+XKJiYmRY8eOyYIFC6R///5SqVIlh/ubH7aZJwUHB8uoUaNk69atcv78eRkxYoT4+vrazF+yZEmZN2+eZl1MTIwMHjzY3V01e+edd3TXv/XWW25vu1y5cmIymczLeTVDKTuWQZDbt29b5cn6P6GUcrrflp9VtWrVslsmLS1NM4vFXt6ssm7jrD7++GP5999/zctBQUEyb948uXjxokRHR0vv3r2lTJkyDrVpyRPbSMQ6eF2+fHmn2gUA5F8EdgCggMju8qLLly/bLe9InrssL41xBWeCJCIif/31V7avZ2Zm2rzUR+/LXFxcnEyZMiXbOk0mk9SoUUP69+8vCxYskNOnT8uZM2dk3rx58sADD2RbNj9ss/yiTJkyMnv2bNm0aZPNS2HmzZsnJUuW1KwbNGiQXL16NS+6KK1bt5ZHHnnEav327dtl+/btbm/f8vKvGzduuL1Ne0JDQzXLiYmJmmV/f39N8NJkMklKSordoGXWNGrUKE2djgRPLPvhCvHx8dKhQwerYEhoaKj069dPvvrqK7l48aL89ddfMmfOHGnXrp34+PjYrddT20jEejsVKVLEoXIAgPyPwA4AFBDZnaTfvHnTbnlnvhz5+/s7nNdRzn7J0Ls0yZKzX/imTJkic+bMcapMhQoVZMiQIbJ371754YcfbH7Jyg/bzN327NkjJpNJTCaTFClSRCIiIqRTp06ydOlS3UuvHn74Yfnqq6+s1vfs2VO6du2qWRcdHS2rVq1yW98tjRs3Tnf9rFmz8qR9y9kxjvwPu1tYWJhm2XKmSbFixVzepieP8aNHj0qDBg1k9uzZNrd/zZo1ZdiwYbJ+/Xq5fPmyTJw4UfeeTHd5chslJydrlm1dhgYAMB4COwBQQNi6pEBEHLqfiaM34BSxvpzBFbL7MqQnIyPD5X3IzMyU4cOHS/v27WXfvn1Ol+/UqZPs27dPqlSpYvVafthmeSkpKUnOnDkja9askV69ekmHDh10t0HHjh2lVatW5uXSpUtbBdfOnj0rI0aMcHuf76pbt660aNHCav3ly5ezvXeTK1leLqh3mWBee+ihhzTLlveGcsf/ZFBQkMvrdMb169dl1KhRUrZsWenfv798++23NmdPhYaGyptvviknTpyQxo0b6+bx5DbKzMyU9PR087LeJakAAGMisAMABUR2s1Mc+WXWmV/Gs7ufRXh4uHnWhjMpP80+2bBhgzzwwANy3333ycsvvyw//vijwzMmypUrJ8uWLbMKtBX0bWbP+vXrZeHChbqvZb1BcbNmzayetlShQgVJSEjI9vIUW4Gfffv2afI1a9bMbl+ff/553fXR0dGaL8buZBnI8fSX8Fq1alldTrh7927NsuUsulu3buXouM6a3nzzTbe/N0ckJCRIdHS0+SbqLVq0kLffflt+++03q8B5qVKl5KeffrIKhN2tJ6u83EZeXl6ay8XyQ7AQAOAaBHYAoICIj4+3+Zoj92Bw5kaacXFxNl+zvFzDyI4cOSLTp0+Xtm3bStGiRSUyMlKGDx8uixcvlosXL9os17BhQ6tHGt8r2yw7O3fu1F3foEGDPO6JbYUKFZJevXrpvuboI7VdwTKQ6OnLZiyfDrZ//365dOmSZl1qaqqm3/7+/i55ilR+c/v2bfn555/ltddek8jISAkPD5fx48drnrjl7+8v8+fPtyrryW0UGBioWc4Pl/cBAFyDwA4AFBCJiYk2b4Bco0YNu+Wd+XJ94cIFq0cf3+WOmwTnB+np6fLbb7/JnDlzpE+fPhIeHi5t2rSx+ajyrJcXiRScbfbmm2/Kp59+KqtWrZJdu3bJyZMnJSEhQTp16mS3rK1LAi2/cHpS69atdWdCnTt3Tv74448860d+utFtUFCQ1Sym6Oho3bx//vmnZtmRzx6ju3jxokyaNEkaNWqkCeDed999Ur9+fav8ntpGlseQO246DQDwDAI7AFCAWH5huMty9ogeR76YZ2V5GcZdepcfFERKKdm0aZO0bt1a97Hqeo+eLwjbrFOnTjJw4EDp3LmzNGnSRKpUqSLBwcHy1FNP2S0bGRmpuz6vnnTliCeffFJ3/dq1a/O0H+fPn9cEwipUqJCn7Wc1adIkzVP3zp8/L59++qluXst7UzVt2tStfctPjh8/Lh999JFmXe3ata3yeWobVaxYUbPs7GPWAQD5F4EdAChAtmzZoru+c+fOVo+OzqpVq1ZSp04dp9qy9UW3b9++2V5a0K5dO7lx44acOHFCduzYIStWrJC5c+dazXDJS2XKlJEePXrIm2++KYsXL5Z9+/bJlStXHHqCzblz53Qfq653mUNB2Ga2jrE+ffpI586dbZarVq2a9O/fX/e1rLOeVqxYkaP7jLz//vu6dUdGRmry7dixI9v3165dO931P/30U7blXC0lJUViYmLMy+Hh4eLllfenbU888YTV47UnT55s8/4sGzZs0Cw/88wzbuubu7Ru3VpmzJgh27dvl59//tmpsqdOndIs692U3lPbKCIiQrNs+Sh3AICBKeS5IkWKKBEhkUgkl6caNWrY/Oz5+uuvlclksipTsmRJdeLECZvlDh48qNtWYGCgiouL0y0za9Ys3TL+/v7q119/tcqfmZmp6tWrp1smNjZWt43w8HC72+PkyZO6ZWvWrKnJFxkZ6dT7yJrq16+vMjMzrcqOGDHCY9vMnalu3bq671cppdLT09XHH3+s6tWrp/z9/VVQUJC677771Ouvv67i4+N1yyil1BNPPJHrfs2ePVu37kaNGjlcR5kyZWz2sXr16nm+rbdv367pQ9WqVR0qN3DgQE25DRs25Kj9Z555RqWkpGjqWrNmjfLy8rJZxtvbW507d05T5sknn3SoPR8fH7Vr1y61efNmNXbsWHX//ffbzJuUlGSuPzY21uH31K5dO03fPvvsM6s806ZN0+SJiopyuP7JkydryrZo0cJj28gyTZgwQdPm0KFD8/yYJpFIBT8NGDDA1lAK9/mGwI4HENghkUjuTOvWrbP5+bNmzRrVuHFjFRAQoEJDQ1Xv3r3VP//8o5RSVl/g7jp06JDNtl599VWbbS1fvlw9+OCDKjAwUIWGhqp27dqpPXv26OZdsGCBzTbyIrAjIurAgQO6eb/++mvVuXNnVaZMGRUQEKB8fHxUSEiIatCggXr55ZdVTEyMVZm0tDRVpkwZj20zd6fFixfbfA/OOnbsmPL19c11n1wR2OnQoYNuHTdv3sw2mOGuNGPGDE0/evfu7VC53AZ2KlasqBYuXGi1HY4ePaqCg4Ptlv/f//6nKXfjxg3VrFmzbMsEBgaqpUuXasrNnz/fZn53Bnbq1aunCV6ePXvWocBe1apVNZ9X169fV35+fh7bRpZp/fr1mrLOBIVIJBLJ0URgxyMI7HgCgR0SieTO1KBBA5WWlub0Z5Plr7l3HTlyxGZbXl5easuWLbn6TDxx4kS2XxbzKrDTtGlTlZ6enqv3ctcbb7zh0W3m7lSiRIlsZ3k5Ki0tTT3yyCMu6ZMrAju2gm4HDhzwyHbu1q2bph8ffvihQ+WcCex4eXmpUqVKqfvuu08NGjRIffvttyo1NdVqG+zevVuVK1fOofZNJpPatGmTpnx6err65JNPVIsWLVSJEiWUr6+vKlOmjGrUqJGaMGGC+vfffzX5r1y5okqWLGmzDXcGdkRERUdHa/IlJyerDz74QD366KMqLCxM+fr6Kn9/fxUeHq6aNm2qJk+ebDUrbdy4cR7dRpbtXbt2zVz25s2bysfHxyPHNYlEKtiJwI5HENjxBAI7JBLJ3WnQoEFOfS598cUXKiIiQve1kydPZttWsWLFrL6gOOqvv/6yG6DJq8COiKjevXvnKCiW1dy5c5W3t7dHt1lepEqVKqmDBw/meDvdvHlTde3a1WX9cUVg57333tOtY9OmTR7ZxsWLF1e3b9829+Pvv/92qJxlYCc3MjIy1Ny5c23OPLGVihYtqrZu3ZqjNmNjY1VkZGS29bs7sBMQEKD27t2b4+22cuVKu4ETd2+jrOmBBx7QlF+9erVHjmkSiVTwE4Edj/iGmycDQAH0ySefSL9+/SQ5OTnbfEopef/992XAgAG6NwAWEQkICMi2jvj4eGnfvr289tprcv36dYf6l5KSIrNmzZKGDRvK+fPnHSqTFxYvXixNmjSRPXv2OF32+PHj8uSTT8qwYcMkIyMj27wFYZv9888/8uCDD8rEiRM1j3i2Rykl69atk3r16sm3337rxh46z9bNsm/cuJHHPbkjLi5Otm3bZl6uVq2a0zc5z6mMjAxZvHix1K1bV4YNGyZpaWlOlU9ISJC2bdvKpEmTJCkpyeFyK1eulIYNG1o9OSqv3bx5Ux5++GH54IMPnHrviYmJ8uqrr0q3bt0kPT0927x5uY0sn/a2YsUKh8sCAPI/H093AADgHosWLZKffvpJBgwYIJ06dZKKFStKcHCwxMTEyLlz52TDhg2yZMkS81NckpKSJCEhQYoWLaqpJzg42G5b6enp8vbbb8ucOXPkySeflEcffVQaNmwoJUuWlGLFiklycrLExcXJH3/8IVu3bpXFixfnq0dcZ7V//35p0qSJNGzYUDp06CCNGzeWSpUqSVhYmAQGBoq3t7ckJiZKfHy8HDt2TH7//Xf54YcfnA4GFYRtlpqaKhMmTJDp06fL448/Lg8//LA88MADUrJkSQkJCRFfX19JSEgwv49ff/1VVqxYIadPn/Z013VZHvt3eSqwIyKybNkyzdPPunfvLuPHj3dpG8nJyXL16lW5evWqHD58WDZv3ixbtmzJ9fGWlpYm48ePNx/jrVu3lnr16kmJEiUkODjYfIz/+eefsmvXLlm2bJnVU6U8KSUlRUaMGCHTpk2Tbt26ySOPPCI1atSQMmXKSGBgoGRmZkpiYqKcP3/evN1WrlwpiYmJDreRF9vIZDJJ165dNe9r1apVTtUBAMjfTEop5elO3GuCg4OdGvQBAMC9KSAgQM6ePSuhoaEiInLp0iWpWLGi3L5928M9g1G0a9dO1q9fb17+9NNPZdCgQR7sEYCCbMCAAfL55597uhv3muVcigUAAJBP3bx5U+bPn29eLlOmjHTv3t2DPYLRDB8+XLM8e/ZsD/UEAOAuBHYAAADysVmzZkl8fLx5+fXXXxcfH66mh32RkZHSvn178/KyZcvk6NGjHuwRAMAdCOwAAADkY9euXZNJkyaZl2vWrCnPPfecB3sEo5gxY4aYTCYRuXNvnZdfftnDPQIAuAOBHQAADG7kyJGilHJrOnnypKff5j1tzpw5cuTIEfPyxIkTzffdAfR0795doqKizMtvv/22nD171oM9AgC4C4EdAACAfO727dvSu3dvSU1NFRGRkiVLau69A2QVFhYmc+fONS/v2bNH3n77bQ/2CADgTgR2AAAADODw4cPyyiuvmJe7desmffr08WCPkB+ZTCb5/PPPpUSJEiIikpiYKH369JGMjAwP9wwA4C4EdgAAMLjZs2eLyWRya6pataqn3yZE5P3335eFCxealz/++GNp0KCBB3uE/ObNN9+UDh06iIhIRkaGPP3003Lq1CkP9woA4E4EdgAAAAxk8ODBsm3bNhERCQgIkFWrVklYWJhnO4V8oWvXrjJ+/Hjz8siRI2X9+vUe7BEAIC/wrEwAAAADuX37tjzyyCOe7gbyoW+//Va8vPjdFgDuNXzyAwAAAAAAGBSBHQAAAAAAAIMisPP/2rvv8Ciq/fHjn81CAkkIJUAQQrn0qnClSBW5UarK86XIFaUEUbiIShOkXFBEqgG9YPBSQhEwFBWQJvoVKQGNKEVQiqgJEEAIISSQhJDz+8Mf+81kZrO7yW6yQ96v58nzsGfOnD27M+xn5jMz5wAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkypW2B2AsSpVqsgLL7xQ2N0AAMDrJScny/z583OtM2TIEAkNDS2gHgEAcP86ceKEbNy4sbC7gWxI7Hip0NBQmTZtWmF3AwAArxcfH+9UYqd169YF1CMAAO5f69evJ7HjZXgUCwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2gPvQ559/LhaLxfb3+++/F3aX4ILHH39cs/0sFosMHjy4sLuFIqZ///66/bBbt26F3S2gyCGmmxfxHK4i9iKvSOzArsWLF2t+VPbv31/YXQLue0uXLpUvv/xSU1apUiWJiIjQ1MkZ9O/9bd682en3mjdvnm79CRMmuO2zwDV79+6VkSNHSosWLaRChQpSvHhxCQoKkurVq0vXrl3l7bffdvmELiEhQd555x0JCwuTqlWrSsmSJaVUqVJSq1Yt6devn6xevVoyMzMN133vvfekQoUKmrIdO3bIypUr8/oRYSAxMVE2bNggw4YNk5YtW0rNmjUlKChISpQoIVWqVJGmTZtK7969JTIyUs6ePVvY3QXgJOI5PvroIwkKCtJtm3nz5tldh9iLvCKxA+RDZmam+Pv7i8VikcWLFxd2d2ByiYmJ8vrrr+vKIyIipGzZsk61MW7cOLlz5467uwYP+vHHH6VFixby6KOPysKFC+X777+Xq1evSmZmpty8eVPi4uJk586dMmXKFKlVq5aEh4fLjRs3HLY7e/ZsqV27tkyaNEm++uorOX/+vKSlpUlKSoqcO3dOoqOjZcCAAdK4cWOJjY3VrV++fHmZO3eurnzMmDGSlJTkls9elF24cEFefvllqVy5svTt21c+/PBDiY2Nld9++01u3rwp6enpcvHiRTl69Khs2rRJ/vWvf0mdOnWkS5cucujQocLu/n0Z/+7Hz4TCQTwv2m7cuCHPPvusPP/883Lz5k2X1iX2Iq9I7AD5cOLECbl9+3ZhdwP3iWnTpsn169c1ZS1btpR+/fo53caZM2dk4cKF7u4aPGTHjh3Stm1b+f77752qn5WVJVFRUdKmTRu5evWq3Xrjxo2TCRMmyK1btxy2eerUKQkLC5Nvv/1Wt+z555+Xpk2basquXbsm06dPd6q/MLZq1SqpXbu2LFq0SNLT011ad9euXdK6dWsZNmxYoZ703Y/x7378TCgcxPOia//+/fLQQw/JunXr8twGsRd5QWIHyAdnT8YAR+Li4gyvEM+ePVssFotLbU2fPl0SExPd1TV4yNmzZ6VPnz55OpE8efKkDB061HBZdHR0rrd5G0lOTpbevXtLcnKyptzHx0feeecdXf2FCxfKxYsXXXoP/GXChAkycOBASUtLs5UFBwfL8OHDZcuWLXL27Fm5ceOGpKWlSVxcnOzbt0+mTJki9erV07Tz4YcfSlhYmG6bFZT7Mf7dj58JBY94XjRlZmbK1KlTpWPHjvLHH3/kqy1iL/KCxA6QDxwEwl0iIiJ0V99btmwpHTt2dLmt69evy7Rp09zTMXjMK6+8Iqmpqbryl19+Wc6cOSNpaWly5swZmTlzpvj7++vqffbZZ3Ly5ElNWWZmpowfP15X98EHH5Svv/5aUlJS5OrVq7J48WIpWbKkps758+dl/vz5unW7du0qDz30kKYsIyNDFixY4NTnxP9ZsmSJzJ492/baYrHI2LFj5ddff5UPPvhAnnzySalVq5YEBQWJn5+fVK1aVdq1aydvvfWWnDhxQpYuXSpBQUERzFVZAAAgAElEQVS29ffu3Svh4eGF8VHuy/h3P34mFDziedFz8eJFad++vbz11lty9+5dW3nlypUlICAgT20Se+EqEjtAPhw+fLiwu4D7QEpKiixbtkxXPnr06Dy3GRkZKadOncpPt+BBZ8+elZ07d+rKhw8fLv/5z3+kdu3a4ufnJ7Vr15YJEybI+++/b9jOrl27NK+3bt2qu1IYFBQkX3zxhXTs2FECAgIkODhYXnrpJXn33Xd17S1evNhwMGWjffG///0vj6244OTJkzJy5Ejb62LFismqVatk7ty5Urp0aYfrW61WGTJkiOzdu1cqVapkK9+0aZMsWrTII33Ozf0Y/+7Hz4SCRTwvmmJiYnRjn/Xt21eOHz8uZcqUyXO7xF64gsQO8iUqKso2wnvdunVt5Uop+eyzz6Rz585SsWJFKV68uJQpU0aaNGkir7zyipw5c8Zum3PnzrW1WbNmTVv51atX5d///re0bNlSKleuLH5+flK5cmVp166dzJ8/P9fBRGfNmmVrs1ixYk59tgULFhiuk322sOwDjg4fPlwz4n1+rvxlZGTI+vXrpX///tKkSRMpV66cFC9eXEqWLCkPPPCAtGvXTsaPHy8//vijU+3du/U3MzNTli1bJp07d5aaNWtKiRIlpGzZstK4cWN59dVX5ddff3Wqvbt378q2bdtkyJAh0rRpUwkODhZfX18JCAiQ0NBQ6dKli8yZM0euXLmSazue2NY5Xbx4UWbMmCGPP/64hIaGSsmSJSUoKEhq164t3bt3lw8//FD3HLyR7PuDxWIxPCnPq02bNklKSoqmrEyZMtKzZ0+n22jTpo3mdWZmpowdO9Yt/cvpwIEDMnHiRGndurVUr15d/P39JTAwUGrUqCGtW7eWiRMnOjWL3rJly3QzRXTu3Nm2XCkl0dHR0r17dwkJCZHixYtLhQoV5JFHHpFZs2a5NCBhcnKyREZGSp8+fWx3RJQoUUJq1Kghjz32mLz//vsO91d32r17tyilNGVWq9Xw1msRkUGDBomfn5+uPD4+XvN648aNujr9+/eXkJAQXfngwYN1VxIvXbok+/bt09Xt3bu3BAYGaspu3LghW7ZsMewv9KZPn64ZT+ff//63PPfccy6389BDD8nHH38sPj7/dwg3ffp0zaNdObkrBuYl/hX1mO7ueC5CTM9vTCee/x/iufuVKVNG1qxZI9HR0VKuXLl8tUXshUsUClypUqWUiOT616pVq8LupoqMjNT0ad++fbo6a9assS2vVKmSUkqp69evqzZt2uT6+Xx9fdWaNWsM3/eDDz6w1QsODlZKKXXw4EFVsWLFXNusWrWqOnDggGGbM2fOtNWzWq1Off758+cbrpPze7H3Fxsb69T75HTo0CFVu3Ztp95DRFTv3r1VUlKSpo2tW7dq6sTHx6uEhATVvHlzh9tl7dq1ufbv+PHjqmnTpk71LSAgQC1ZssRuW57Y1vfcuXNHvf7668rX19dhP4ODg1VUVFSu7WXfH0RE7dixI9f6rujcubOuT0OHDrVbf8mSJbr67733nqpWrZqu/Msvv7Tbzty5c3X1x48fb7f+t99+q9q3b+/0vtm2bVt18OBBu+2tW7fO7m/ftWvXVMeOHXNtv0qVKuro0aO5frdZWVlq3rx5Tv3uBgUF5bq/utPKlSvVU089pdq2bavq16+vKlSooJo3b57rOrVq1dL1edy4cZo6lSpV0tXZtGmT3TafeOIJXf3Jkycb1n3++ed1dZ9++mnXP7wHxMXFOdy+MTExhda/c+fOKavVautLw4YNVWZmZr7aHD58uObzRUZG2q3rrhiYl/hXlGO6O+K5UsR0pdwb04nnxHN327BhgxIRFRYWpuLj4zXLqlSpouvf3LlznW7bW2NvdHS03e8/PDy8sLtXFK3njh3ki6+vr+3ft27dkoyMDAkLC5OYmJhc18vIyJDw8HD5+eefdcuyX0lLSUmR8+fPS7du3Rxm3+Pj46VHjx5y+vRpFz+F9zh9+rSEhYXJ2bNnnV5n48aN0rNnT93V/+wsFot06dLF4RXHjIwMGTBggG7cjnvOnDkjHTp0kCNHjjjVt9TUVBk6dKisWLHCcLmntnVmZqb06NFD5syZIxkZGQ77ee3aNRk8eLDMmjXLYV13S0tLk2+++UZX3q1bN5fauXnzpsyYMUNXPnr0aMnKyspz/+5ZvXq1tG/f3vBuDnsOHDggHTp0kFWrVhkuN7oDJTk52bb99uzZk2v7Fy5ckMcff1yuXbtmuDwrK0v69u0rY8eOdepqYHJysgwdOlTefPNNh3Xza8CAAbJ582bZv3+//Pzzz3LlyhXDKcfvSUtLk0uXLunKsz9/n5CQYFinYcOGdttt0KCBrsze74TRPvnVV18xHa8TPvnkE824C6+88opYrdZ8tfnaa69pBmKNjo7OV3ueUlRjuqfiuQgx3ZHCiunEc62iEs9FRPz9/eX999+XL774QkJDQ93aNrEXziKxg3wpXry47d9paWkye/ZsOXz4sDRo0EDWrFkjCQkJcufOHbl69ap8/vnn8uCDD9rqp6eny3vvvadrM/vBbnp6urz++uty/fp1adOmjXz22Wdy6dIlycjIkEuXLsm6deukdu3atvrXr1+XV1991UOf9i/Dhg0TpZTu+dbIyEhRStn+mjdv7nLbkyZNst3C6+vrK2+88YbExsbK9evXJTMzU27evClnz56VtWvXam7V3bNnj2zYsMFuu3PnzpWjR49KvXr1ZOXKlXLx4kXJyMiQP//8Uz755BNp1KiRrW5mZqbdGXVGjBihucW5e/fusnXrVrlw4YKkp6dLamqq/PDDD/Lqq69qHhMYPXq04a3WntrWb7zxhmbskTp16sh///tfOXnypKSmpkpKSoocO3ZMZs6cKcHBwZr1vvrqK7vfoyccOHBA9wiF1WqVxx57zKV2rl+/Lv3799ftd8eOHTN83t8V27dvl4EDBzp1QJ3TnTt3ZNCgQbJ7927dsuyJ4XuSk5Nl7ty5cvDgQafav3Llirz11luGy8aNG2f4aJIj06ZNk08//dTl9TwpIiJCN9By2bJl5amnnrK9tvfYRW4HmUbL7D0qGxYWppvRJSUlRTeuAPSyn9RYLBZ55pln8t1m3bp1Nf/fDx065PLU6a7KS/wrqjHdU/FchJjurTGdeK5VlOJ5t27dZOTIkS7PeuYMYi+cVhj3CRV199OjWNlvD7ZYLKpEiRLqiSeeULdu3TJs8+rVq6pcuXK2dapXr66rExUVpfs+evbsqe7cuWPYZlJSkqpbt66m/rFjxzR13Hnb9j23b9/WvGdut8E7IysrS/n7+9vamzdvnsN1nnvuORUSEqKaN2+uIiIibOU5b9v28/NTYWFhKjU11bCda9euqfLly2tuic3p119/1W2T3MyaNUtT3+h2cE9s63PnzqlixYrZlnft2tXu/qiUUufPn1c1atSw1W/cuHGun8vdsu+b9/4aNWqU6zpGt26PGDFCKaXUN998o1sWEhKikpOTde04c+t2YmKiZt/I/te/f3918OBBdfPmTZWSkqJiYmJU7969Des+8MADuv1v+/btunr+/v6qdOnSysfHR40aNUqdPXtWpaWlqSNHjqgnn3zSsO3g4GDdPvPTTz8pHx8fXd1mzZqp7du3q4SEBJWUlKQOHDigunbtqqtXs2ZNlZ6enpdN6hZ3795VV65cUV9++aXq16+frn8+Pj5q48aNmnXWr1+vq+fr65vr+6xYsUK3TsmSJe3WN3ocbP78+W75zPnh7Y9iBQcH2/rRsGFDt7U7atQozWcsiEeXlHIt/hXFmO7OeK4UMd0sMZ14Tjw3kt9HsZTyztjLo1heh0ex4D5KKSlRooSsWbNGN43uPcHBwdK3b1/b6z/++EM3yFxOgYGBsnTpUrsDJJYuXVrmzJmjKfv8889d7H3hS0pKklu3btle55zi0Mjq1avl0qVLEhsbK6NGjbJbz9/fX9atW2c4ZbKISLly5aRfv3621xcuXNBtlwsXLkj79u2lbt26EhQUJC+//HKufRs5cqTmji5nZhtxx7aeP3++bVafChUqyNq1a+3ujyIiVapUkcWLF9te//TTTwU65e3Ro0d1Zc5s+5zufeYOHTrI008/rVl2+fJlmTlzZp76t3jxYrl69aqu/M0335SPPvpIHnnkEQkMDJSAgABp3bq1bNiwwXDfSEhIkLVr12rKjK5s3bp1S27cuCHvvfeeRERESK1atcTPz08eeugh+fTTT3WDSor8ddv9L7/8oimbMWOG7pb1GjVqyJ49e6Rr165SqVIlKV26tLRp00a2b98u3bt319Q9d+5cody1c+jQIbFYLGK1WqVixYoSFhYmH3/8saZO5cqVZcuWLdKrVy9NeWJioq69nIMuOrP89u3bdgfizX7X5T1G+zD+T2ZmpubxAqPH3/KqcePGmtcJCQlua9tTikJM92Q8FyGme2tMJ55rFfV47k7EXjiDxA7catCgQVK+fPlc6zRt2lTz2tHsBX369NHcWmuke/fumhOUAwcOOOip9wkKCtLcxrxt2za3tR0eHu5wuzRp0kTzOudJYvv27WXv3r1y6tQpuXHjhvzjH//ItT1/f3+pWrWq7bXRwURO7tjWO3bssP27f//+Tk0z2blzZ01ft27d6nAddzEaf6FevXr5anPOnDmaA3CRvw6Oc06D7YwlS5boyurXry+TJ0+2u87s2bMNZ4JYvXq1U+/ZvHlzw4NJq9Vqd2aQ7I8P3b17V7Mf3PPaa69JUFCQ3T7nlJfbvj3FarVKz549JSoqSs6ePas7cBURw2RMzv3A2eX2plI12jednXmnqMo5ZkR+Z0nJrS1741N4k6IQ0z0Zz0WI6Y4UVkwnnusRz92D2AtnkNiBWzk6MBAR3cFI9qtaRpx5NrlYsWLSrFkz2+vcplP3VlarVTp27Gh7vWDBAhk5cqRcuHAh322HhYU5rJNzu9g7sXNF9qtq965A5Sa/2zohIUFzYJW9niOPPPKI7d/Hjh1zer38unjxoq7sgQceyFebdevWlWHDhmnK0tLSZMKECS61ExcXJ7/99puu/Nlnn9WMt5CTv7+/9OjRQ1ceGxvr1H4waNAgu8uMrvCJ/HWF/J4ff/xR8/qeli1b2m23YcOGUrZsWU3Z119/7aCnBefu3buya9cuWbZsmSxfvtwwiZN9cN57HA3Qay+xY29QxipVqujKzp8/n+t7FHU575Swd5dFXuS848rRHbDeoCjEdE/GcxFiujMKI6YTz/WI5+5B7IUzSOzArWrUqOGwTs6R85WD2R9yXnWyp3r16rZ/x8fHO7WOt5k7d67mwGnhwoVSrVo1adu2rUyZMkW++uoru49I5KZatWoO6+Qc+C637XL58mVZvny5hIeHS7t27aROnToSEhIiZcuWlcDAQClRooQUK1ZMTpw44VI/87ut4+LiNPUGDhwoFovFqb/sg1UW5Cwsf/75p66sUqVK+W536tSpUrp0aU3Zxx9/7NJge/ZutXdmEFGjA/Dbt287NUNM9gPynMqXL294EJp90Fijg1eRvw4i7W1/Hx8f3d2D165dk8uXLzvsb0G5ffu27N+/X15++WVp0KCB/PDDD5rlRo87GCV7srOXwLGX8DE6SfGm78gb5bzDwGjQ2bzK2VbOkxlvVFRiuqfiuQgx3VtjOvFcj3juHsReOIPEDtzK0XgOeeHsbevZg97t27fdMiVkQWvWrJns3r1b/va3v9nKsrKyJCYmRt5++20JCwuTsmXLSpcuXWTp0qVOnyC46wpxenq6jBo1SqpXry5DhgyRqKgoOXDggJw9e1auXLkiSUlJkpqaKunp6Q5PKI3kd1sbjTGSF0ZXhzzhzp07hifW7thewcHBMmnSJF159rEbHM3eYHSQKvLXGC+O2DuYdWYb5XYgbLVadQe4eXkPZ7kyVbE7PPLII6KUkqysLLl27Zr8+OOP8vbbb+tO2H///Xfp1KmT5lZso/3G0XSo9pbb2weNyt1xJ8D9rGzZspr/a848wuKsnPu6o8devEFRiemeiucixHRXFURMJ567tq7I/R/P3YnYC2eQ2IHXCwgIcKpezqtTeZnK0Ru0bdtWzpw5Ix999JG0atVKF6zT0tJk165dMnToUKlRo4bMnDmzQA5409PTpVOnTrJgwQKPTamb322dczrovCqoxxnsfY8lSpRwS/uvvPKK7i66Q4cOybp160TE+A6P7G7evGlYntvAlY7q2Gszu5x39eWU223jIu7dfsnJyW5ryxUWi0XKlSsnTZs2lUmTJsn3338vFSpU0NS5ceOGjBs3zvba6KTe0XdhtD0CAgLsbgOj7aqU8vg022bm4+OjGe/jxx9/dFvbOQfPzH7ng7cqSjHdW+O5CDHd3Yjnxojn7kHshTNI7MDrOfujlf2WZovF4jCYeDOr1Sr9+/eXQ4cOSUJCgkRFRUm/fv10J3ZJSUkyceJE+Z//+Z88XU1zxZQpUyQmJsb2unjx4jJw4ED5+OOP5fvvv5dz585JYmKi3Lx5U27fvi2ZmZnSqFEjl94jv9u6VKlSmnq7du0SpZTLf+58VCIvHD2e6Cw/Pz/D2TMmTJggaWlpDg847Q1M6MzBtr06jq7OuUPO/SA/nDlwLQg1a9bUJHHu2bp1q+1g1egZ/IyMjFwPjI2u4ub2mIe79s2ipm3btrZ/X7hwQX7//Xe3tJv9UYxy5co5/ehLYSpqMd0b47kIMb2gEM/z536M53lB7IUzSOzA6zkbkLPfaluqVCmHt6U64i2Z/ZCQEBk0aJCsW7dOLl++LIcPH5YJEyZoxm3YvHmzREZGeqwPaWlpmtkUypYtK99++62sWLFCnnnmGXn44Yflb3/7m+Z5fKvV6vLBaX63dc6xLLx9hhh7V8HyOu6CkX79+kmrVq00ZXFxcRIREeFwdpGcJx73ODNgn71BQu216U72xhn54YcfXD4h6Nu3r8f766wWLVroyjIzM23jXtSrV8/wdy/nOBWOltWvX99ufaN908wn3QWlQ4cOmtdRUVH5bvPUqVOacTMeffRRh1e/XeGpGFiUY7o3xHMRYronEM89436N564i9sIZJHbg9X755Ren6mW/AprzdvTsB4R379516uDEXVdU3cliscjf//53mTlzppw4cULq1KljWzZnzhyPve/x48c1B14TJ050ODtFRkaGywNe5ndb5zyx/emnn1x6/4JmtVoNB6l1NFOcq959911d2axZsxz+P/j73/9uWP7dd985fE+jOmXLlpWaNWs6XDe/GjRoYFjuLQOwpqWlyYgRI6RPnz7y6KOPSoMGDSQ4ONhwitbs7J2033tsoXTp0lK3bl3d8uPHj9tt02i2mJwnDtkZ7ZvunOXpftWnTx/N97R48eJ8Jxr+85//aF4PHDjQbl1vioHE9L8UVjwXIaZ7AvHcM7w9nhcUYi+cQWIHXm/fvn0O62RkZMiRI0dsr+vVq6dZnvNKiqOrPllZWfK///u/LvSy4FWuXFkzmF58fLzHbjNNSEjQvM5tloN7tmzZ4vLz8fnd1mXKlNEcHH/++ecuvX9hqFixoq7sypUrbn2Ptm3bSq9evTRlN2/elEWLFuW6XrVq1Qxnulu7dm2u05wmJibK9u3bdeUdOnTI91V3ZzRq1Mjw6qUz+1dBKFGihHzyySeyceNG2bt3r/zyyy+SmJgo27Zty3W9nOOp3BMSEmL795NPPqlbvnv3bsP1kpKS5ODBg7rynj172u1Dzt8CEffM+nK/Cw4O1kz7e+XKFXnttdfy3N6hQ4c0d3U0atRInnrqKbv1vSkGEtP1CjKeixDTPYV47n7eHs8LCrEXziCxA6+3du1ah4Onffrpp5rR4Tt27KhZnnNmhuwHEUY2bdokf/zxh0v9zO8z8YsWLZLevXtLjRo1ZO3atU6tk3P6Q3fehp9bu44OOJOSkmTChAmaMmduR3bHts5+cnPs2DHZsWOHw/dNT0+Xpk2bSp8+fWTFihUFNiuWiPGMFBcvXnT7+8yePVs3QGX28RXsefHFF3Vl586dk+nTpxvWz8rKkn/961+GV5deeuklJ3ubPxaLxTA5sXjxYruzYmzfvl0CAwOlZs2a8sgjj8hTTz2lmXFERGTnzp2GU6vu37/f5T52795dV7Zv3z5ZvXq1Yf3U1FRZuHChrrxcuXKaE59nn31WVyc6OlouXbqkK3///fd1s7g0b95cdxKdndG+aTS2D/TeeOMNTSyKioqSt956y+V2Tp48Kb169bINsmuxWGT27Nm5nmR5Oga6Ev+KQkz35nhu1DYx3T2I5+5nhnheEIi9cAaJHXi9K1euyMiRI+0OHHb16lUZP3687bXVapUePXpo6jRs2FDzevHixXbf7+TJkzJixAiHA9FZrVbN6/zeFnro0CHbweekSZPk3LlzDtfZsGGD7d+hoaFOz0DhquzTtYqIbNy40W7dixcvSpcuXSQxMVFatmxpK3fmNnh3bOuXXnpJc9AaHh4up06dsvueGRkZMmTIEDl69Khs3LhRXnzxxQIdaDH7Sfk9ufU3r2rVqiUjRoxweb3hw4dL+fLldeVvvfWWvPDCC3L06FFJT0+XpKQk2b17tzz++OMSHR2tq9+8eXPp0qVLnvqeF6NHj9ad6KakpEi7du1k+fLlcvnyZblz547Ex8fLwoULpV+/fpKamiq//fabfPvtt7J161aPPrs+fPhwwxPxwYMHy9ixY+XXX3+VO3fuyPnz5+WTTz6R5s2by+nTp3X1e/XqpfktatasmbRv315TJyUlRbp27Sr79++X27dvy+XLl2XOnDmGSYXRo0fn2m+jfbN27dq5roO/hIaGyvLlyzVlU6dOlWeffdbuGBbZKaVk5cqV0qFDB81B/rhx4wwThdm5OwbmJ/4VhZjuzfFchJjuKcRzz/D2eF4QiL1wikKBK1WqlBKRXP9atWpV2N1UkZGRmj7t27dPV2fr1q2aOr/99pvDdnOu8/PPP2uWR0VFaZb37dtXiYjq0KGD2rx5s7p8+bLKyMhQCQkJavXq1ap69eqa+s8995zuPe/cuaMqVaqkqTdgwAB1+PBhlZqaqtLT09Uvv/yipk+frkqVKqWsVqt6++23bXWtVqvhZwkMDLTVqVSpkoqJiVFpaWnqypUr6o8//nDui/7/YmNjlcVisbVXrlw59fbbb6vY2FiVlJSkMjMzVUpKioqPj1fbtm1TTz/9tObzTJw40WPbJSsrS4WGhmqWjxgxQp04cULdvn1bJSYmqoMHD6rXX3/d9p1ERkaq4cOH2+pbLBa1du1adfv2bZWcnOyxba2UUuPHj9fUCwgIUFOnTlXHjh1TKSkpKjk5Wf3yyy8qMjJSNW7cWFN3+PDhhm3Onz9fU2/Hjh0ubF37Zs+erfv/36hRo1zXWbJkiW6dl156yeF7JSYmqrJly+b62zN+/Hjdejt27NDsm67+lSpVSp0+fdqwXaP6f/75Z66fIzg4WLdOZGSkrt7o0aPz3OeaNWva9lNH/TX6bXTGSy+9lOf+3duv4+Pjde0eOXJEWa1Wl9vr2LGjwz7XqlVLt96CBQvy9PndKS4uzuHni4mJKexuKqWUWrBggfLx8dFtywEDBqiNGzeqM2fOqBs3bqi0tDQVHx+vYmJi1JtvvqmaNGmi+0z9+/dXmZmZDt/TEzHQ2fhXFGO6O+O5UsR0d8d04jnx3N3xfMyYMXnuX/a/IUOGGLbvjbE3Ojra7ucIDw8v1L4VUetJ7BQCEjuuJXZOnz6tSpcu7dQPYmhoqLp06ZLh+86bN8/pH9aJEyeqL7/80vbaYrEYthkWFma3jTFjxjj+knN444038hQIHnzwQZWammr3O3bHdsm5P+T217dvX3X37l21cuVKw+VPP/20Uspz2zo9PV117drV5e/x4YcfVikpKYZteupA8KuvvtL1w2q1qqSkJLvr5PVAUCmlIiIicv0OjA4ElVJq5cqVytfX1+XvtEKFCmr//v2GbXr6QDAjI0P16NHD5T6HhISo48ePO93fvB4IZmRkqCeffDJP/+d9fX3Vrl277Lbtyv9XEVF16tRRFy5cyLW/V69eNTwhsLd9C5KZEjtKKfXpp586/Vtn9Ge1WtWMGTNcek93x0Bn419RjenuiudKEdPdHdOJ58RzMyV2vDX2ktjxOut5FAte74EHHpAdO3Y4HCSsfv36snPnTs1AotmNGjVKnn/+eYfvN3bsWJkxY4ZmtHmllG3mmewmTpzo1ufgZ8yYIXPnzrU7baaRfv36yTfffOPx0fGHDRvm1K2/gwcPlrVr14qPj4/06tXLpWeA3bWtfX19ZcuWLTJu3Dinbr+1WCwSHh4uX3/9tUdvfzfStm1b3fa+e/eufP311x55vxEjRkitWrVcXm/AgAGyb98+adOmjVP1LRaL9O3bV2JjY6Vt27Yuv587FC9eXDZv3izTpk1zert269ZNYmNjpXHjxk6/T15/A+71b968eXandDXSokULiY2NlSeeeMJunWHDhsmqVaskODjYYXudO3eWPXv2GI4Pkd3u3bt1j1SUKlUq11m0YKxnz55y7tw5GTNmjMNHhLLz8fGRf/7zn3Ly5EmZOHGiS+/p7hiY1/hXVGK6N8dzEWK6JxDPPcfb47knEXvhLO/be4Ec7t69K61bt5ZTp07JokWLpEOHDlKlShXx9fWVBx54QDp06CAffPCBHD58WBo1amS3HR8fH1m1apVs27ZNevfuLdWqVZMSJUqIr6+vVKtWTQYMGCBHjhyRuXPniohIYGCgZn2j2SAee+wx2bFjh7Rr1078/f3F19dXQkJCpGPHjrpxLpxhsVhk7NixEhcXJ/Pnz5cePXpIrVq1JDAwUHx8fKRkyZJSuXJl6dSpk0yePFlOnDgh69atM5wxwBMWLlwoX3zxhfTu3VtCQ0PF19dXSpQoIbVq1ZIBAwbI3r17Zfny5baxCiuBg2YAAAbNSURBVAICAmT37t3yxBNPSEBAgPj5+UmNGjXsBiN3bWsRkWLFismcOXPkzJkz8s4770inTp0kNDRUSpYsKX5+fhISEiIdOnSQyZMny6lTp2TZsmVSqlQpt39njvj5+cmjjz6qKzeahcIdfH19HU6rbU/Lli3lwIEDsmfPHhk7dqy0aNFCKleuLH5+fhIYGCg1atSQTp06yYwZM+Snn36S6Oho3TTFBc3Hx0emTp0qv//+u0REREiPHj2kRo0aEhgYKL6+vlKhQgVp0aKFjBo1Sg4fPizbtm2TqlWruvQeOX8rXGGxWGTMmDESFxcnS5culf79+0v9+vWlfPnyUqxYMfH395fKlStL+/btZfTo0bJ//3757rvv5MEHH3TY9vPPPy+nT5+WiIgICQsLk9DQUPHz85MyZcpIgwYN5MUXX5QvvvhCdu7c6TCpI2K8T/7jH/+QYsWK5emzF3XlypWTefPmycWLFyUqKkoGDBggzZo1k+DgYClevLj4+flJlSpVpGnTpvLPf/5ToqKiJD4+XtauXWs4rb0j7o6BeY1/RSWme3s8FyGmuxvx3LO8PZ57CrEXzrKonClAeFxQUJDDGQhatWolhw4dKqAeeZcVK1bI4MGDba+vX79eoAc6KDhs67+sWrVKBg4cqCkrU6aMXLp0yfQD/t2vqlevLnFxcSIi8scff0i1atUKuUeedevWLQkJCdHNcBMdHS19+/YtpF79n/j4eIfbICYmRlq3bl1APcI9/M4XHWxr4rkZeXM89+bYu379ennmmWcMl4WHh8uyZcsKuEdF3gbu2AGAQtarVy/dVaKkpCT57LPPCqlHyE1qaqqcP39eRMR2R839buPGjboDy9KlS2umIgaAoo54bi7eHs+JvXAFiR0AKGQBAQHywgsv6MojIiIKoTdwZOvWrZKVlSUiIg8//HCRuB3aaF988cUXXRofBgDud8Rzc/H2eE7shStI7ACAFxg9erQUL15cU/bdd9/Jnj17CqdDsOuDDz6w/btnz56F2JOCsWPHDjl69KimzNfXV1577bVC6hEAeC/iuXl4czwn9sJVJHYAwAtUrVpVhg0bpisfP368bjYEFJ6tW7fKvn37ROSv27admZXHzLKysgxnX3r55Ze97pZ1APAGxHNz8OZ4TuxFXpDYAQAvMW3aNN201999952sW7eukHqE7K5cuSIvvvii7fXkyZOlQoUKhdgjz1u1apUcOXJEUxYcHCxTpkwppB4BgPcjnns3b4/nxF7kBYkdAPAS5cqVkzlz5ujKx4wZI9evXy+EHiG7ihUrSkJCgiilRCklb7zxRmF3yaOuXr0qr7/+uq783XffLXIz3QCAK4jn3s2b4zmxF3lFYgcAvMgLL7wgYWFhmrJLly7JqFGjCqlHKKpeffVV+fPPPzVlXbp00U3lCwDQI54jL4i9yCuL4mHPAhcUFCQ3b97MtU6rVq3k0KFDBdQjAADMKz4+XqpVq5ZrnZiYGGndunUB9QgAgPvX+vXr5ZlnnjFcFh4eLsuWLSvgHhV5G7hjBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApEjsAAAAAAAAmBSJHQAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKxA4AAAAAAIBJkdgBAAAAAAAwKRI7AAAAAAAAJkViBwAAAAAAwKRI7AAAAAAAAJgUiR0AAAAAAACTIrEDAAAAAABgUiR2AAAAAAAATIrEDgAAAAAAgEmR2AEAAAAAADApEjsAAAAAAAAmRWIHAAAAAADApIoVdgdg7Pz58zJt2rTC7gYAAF4vOTnZYZ1ly5bJrl27CqA3AADc306cOFHYXUAOJHa81IULF+TNN98s7G4AAHBfWLZsWWF3AQAAwCN4FAsAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyKxAwAAAAAAYFIkdgAAAAAAAEyKWbEKwcyZMyU9Pb2wuwEAAAAAgNs0adKksLtQJFmUUqqwOwEAAAAAAACXbeBRLAAAAAAAAJMisQMAAAAAAGBSJHYAAAAAAABMisQOAAAAAACASZHYAQAAAAAAMCkSOwAAAAAAACZFYgcAAAAAAMCkSOwAAAAAAACYFIkdAAAAAAAAkyomIrMLuxMAAAAAAABw2fH/B82C4i9+6UQ+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main training loop"
      ],
      "metadata": {
        "id": "bZYIn3OF1p7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def training_loop(df, window_sizes, batch_sizes):\n",
        "\n",
        "  # Extracting features and target column\n",
        "  feature_cols = [col for col in df.columns if col != \"target\"]\n",
        "  target_col = \"target\"\n",
        "\n",
        "  # Creating df to store results for each dataset\n",
        "  result = pd.DataFrame(columns=[\"model\", \"window_size\", \"batch_size\", \"train_accuracy\", \"val_accuracy\", \"X_test\", \"y_test\"])\n",
        "\n",
        "  # Split dataframe into train and test\n",
        "  train_data, test_data = split(df)\n",
        "\n",
        "  for window_size in window_sizes:\n",
        "    for batch_size in batch_sizes:\n",
        "\n",
        "      # Creation of the sequences according to window size\n",
        "      X_train, y_train = create_sequences(\n",
        "          data=train_data,\n",
        "          feature_cols=feature_cols,\n",
        "          target_col=target_col,\n",
        "          window_size=window_size\n",
        "      )\n",
        "      X_test, y_test = create_sequences(\n",
        "          data=test_data,\n",
        "          feature_cols=feature_cols,\n",
        "          target_col=target_col,\n",
        "          window_size=window_size\n",
        "      )\n",
        "\n",
        "      # Early stopping in case if validation loss doesn't change in 15 epochs\n",
        "      early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=15,\n",
        "        restore_best_weights=True  # Restore model weights from the best epoch\n",
        "      )\n",
        "\n",
        "\n",
        "      # Model creation with different split data\n",
        "      model = create_model(X_train)\n",
        "\n",
        "      # Training configuration with different batch sizes\n",
        "      history = model.fit(\n",
        "          X_train, y_train,\n",
        "          epochs=30,\n",
        "          batch_size=batch_size,\n",
        "          shuffle=False,\n",
        "          validation_split=0.1,\n",
        "          callbacks=[early_stop]\n",
        "      )\n",
        "\n",
        "      # Saving results\n",
        "      train_acc = max(history.history[\"accuracy\"])\n",
        "      val_acc   = max(history.history[\"val_accuracy\"])\n",
        "\n",
        "      row_dict = {\n",
        "              \"model\": model,\n",
        "              \"window_size\": window_size,\n",
        "              \"batch_size\": batch_size,\n",
        "              \"train_accuracy\": train_acc,\n",
        "              \"val_accuracy\": val_acc,\n",
        "              \"X_test\" : X_test,\n",
        "              \"y_test\" : y_test\n",
        "          }\n",
        "\n",
        "      # Creating row dataframe\n",
        "      temp_df = pd.DataFrame([row_dict])\n",
        "\n",
        "      # Concatenate with the main results DataFrame\n",
        "      result = pd.concat([result, temp_df], ignore_index=True)\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "kBuhvj1Y1pbd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intial set up\n",
        "window_sizes = list(range(10, 101, 10))\n",
        "batch_sizes = [64, 128]"
      ],
      "metadata": {
        "id": "5r1iECzgNvYg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\"macd\", \"signal\", \"histogram\"]\n",
        "dfs_to_drop = [\"log_transformed\", \"log_normalized\"]\n",
        "\n",
        "for df in dfs_to_drop:\n",
        "  dfs[df].drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "Qlspm-DTOvMm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs[\"log_normalized\"].dropna(inplace=True)\n",
        "dfs[\"log_transformed\"].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "OilHQao0PpbU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalutaion function"
      ],
      "metadata": {
        "id": "srfWtrAoTk9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_accuracy(model, X_test, y_test):\n",
        "\n",
        "    # Predicts probability\n",
        "    y_prob = model.predict(X_test)  # shape: (num_samples, 1)\n",
        "\n",
        "    # If you need actual class labels (0 or 1):\n",
        "    y_pred = (y_prob >= 0.5).astype(int)\n",
        "    # Calculate accuracy\n",
        "    return accuracy_score(y_test, y_pred)\n",
        "\n",
        "def compute_best_results(results):\n",
        "\n",
        "  results[\"final_accuracy\"] = None\n",
        "  for idx, row in results.iterrows():\n",
        "      # Grab the trained model from the row\n",
        "      model = row['model']\n",
        "\n",
        "      X_test = results[\"X_test\"][idx]\n",
        "      y_test = results[\"y_test\"][idx]\n",
        "      # Compute accuracy\n",
        "      acc = compute_accuracy(model, X_test, y_test)\n",
        "\n",
        "      # Save to 'final_accuracy' column\n",
        "      results.at[idx, 'final_accuracy'] = acc\n",
        "\n",
        "  results_highest = results.sort_values(by=\"final_accuracy\", ascending=False)\n",
        "  return results_highest.iloc[0]"
      ],
      "metadata": {
        "id": "ktDAfh5YTmO7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log transformed data"
      ],
      "metadata": {
        "id": "g8IZPh8RN26Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_log = training_loop(dfs[\"log_transformed\"], window_sizes, batch_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2tpoP-wOhpH",
        "outputId": "c53157d7-1dc3-47ef-88ef-8d3ae4297017"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4937 - loss: 0.6957 - val_accuracy: 0.4939 - val_loss: 0.6934\n",
            "Epoch 2/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4881 - loss: 0.6960 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 3/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4869 - loss: 0.6939 - val_accuracy: 0.4939 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6933 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 5/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6929 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 6/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 7/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 8/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6955\n",
            "Epoch 9/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 10/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 11/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 12/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 13/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 14/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 15/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 16/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-ba779eb1a478>:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, temp_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.5006 - loss: 0.6940 - val_accuracy: 0.4939 - val_loss: 0.6959\n",
            "Epoch 2/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5201 - loss: 0.6933 - val_accuracy: 0.4939 - val_loss: 0.6932\n",
            "Epoch 3/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4904 - loss: 0.6947 - val_accuracy: 0.4939 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5201 - loss: 0.6934 - val_accuracy: 0.4939 - val_loss: 0.6963\n",
            "Epoch 5/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6931 - val_accuracy: 0.4939 - val_loss: 0.6958\n",
            "Epoch 6/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6929 - val_accuracy: 0.4939 - val_loss: 0.6956\n",
            "Epoch 7/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5201 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6955\n",
            "Epoch 8/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6929 - val_accuracy: 0.4939 - val_loss: 0.6970\n",
            "Epoch 9/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6935 - val_accuracy: 0.4939 - val_loss: 0.6955\n",
            "Epoch 10/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 11/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 12/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 13/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 14/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5201 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6930 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 16/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 17/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5215 - loss: 0.6939 - val_accuracy: 0.4939 - val_loss: 0.6965\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6965\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5215 - loss: 0.6927 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6954\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.5224 - loss: 0.6937 - val_accuracy: 0.4939 - val_loss: 0.6956\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6950\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6947\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6948\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6945\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.4939 - val_loss: 0.6950\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6948\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6945\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.4939 - val_loss: 0.6946\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6955\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6944\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.4939 - val_loss: 0.6944\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6921 - val_accuracy: 0.4939 - val_loss: 0.6948\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5224 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5224 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6939\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5224 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6947\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5218 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6936\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5224 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6945\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5224 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6938\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6942\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6943\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5012 - loss: 0.6946 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 2/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5169 - loss: 0.6938 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 3/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6951\n",
            "Epoch 4/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5169 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 5/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5169 - loss: 0.6933 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 6/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6933 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 7/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 8/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 9/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 10/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 11/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 12/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 13/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6934 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 14/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5169 - loss: 0.6931 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 15/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4963 - loss: 0.6938 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 16/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5131 - loss: 0.6948 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 17/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 18/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 19/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 20/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 21/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 22/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 23/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 24/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 25/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 26/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 27/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 28/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 29/30\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5169 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.5193 - loss: 0.6951 - val_accuracy: 0.4969 - val_loss: 0.6975\n",
            "Epoch 2/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5193 - loss: 0.6937 - val_accuracy: 0.4969 - val_loss: 0.6954\n",
            "Epoch 3/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 5/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 6/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 7/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 8/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 10/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 11/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 13/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 14/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 15/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 16/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 17/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 18/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 19/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 21/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5193 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 22/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 23/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 24/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 25/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 26/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 27/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5193 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.4957 - loss: 0.6960 - val_accuracy: 0.4969 - val_loss: 0.6977\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5189 - loss: 0.6940 - val_accuracy: 0.4969 - val_loss: 0.6957\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5189 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5189 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5189 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5189 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.4834 - loss: 0.6961 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5187 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5187 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.5222 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 2/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5093 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 3/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
            "Epoch 4/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
            "Epoch 5/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 7/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 8/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 9/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 10/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 12/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 13/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 14/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 15/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 16/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5151 - loss: 0.6944 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 2/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 3/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
            "Epoch 4/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 5/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 6/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 7/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 9/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 10/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 12/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 13/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 14/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 15/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 16/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.4994 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5242 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6950\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.5061 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5182 - loss: 0.6945 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 2/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6934 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 3/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 5/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 7/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 8/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 9/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 10/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 13/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 14/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 15/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 16/30\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.5257 - loss: 0.6931 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 3/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 4/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5081 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 7/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 8/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 10/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 11/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 12/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 13/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 14/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 15/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 16/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 17/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 18/30\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.5258 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6953\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.5245 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6959\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5245 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5245 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4918 - loss: 0.6948 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4959 - loss: 0.6936 - val_accuracy: 0.4938 - val_loss: 0.6960\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6956\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5246 - loss: 0.6924 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5246 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6959\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6924 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6957\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.5121 - loss: 0.6948 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 2/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6933 - val_accuracy: 0.4938 - val_loss: 0.6966\n",
            "Epoch 3/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6927 - val_accuracy: 0.4938 - val_loss: 0.6966\n",
            "Epoch 4/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6959\n",
            "Epoch 5/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5249 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6957\n",
            "Epoch 6/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6956\n",
            "Epoch 7/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5249 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 8/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6956\n",
            "Epoch 9/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5249 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6955\n",
            "Epoch 10/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6954\n",
            "Epoch 11/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 12/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6927 - val_accuracy: 0.4938 - val_loss: 0.6959\n",
            "Epoch 13/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5249 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6955\n",
            "Epoch 14/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 16/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5249 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.4909 - loss: 0.6939 - val_accuracy: 0.4938 - val_loss: 0.6976\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5257 - loss: 0.6924 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6968\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6954\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5243 - loss: 0.6930 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5243 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5243 - loss: 0.6924 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6947\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6943\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6943\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6943\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6948\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6938\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6938\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5243 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5012 - loss: 0.6955 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 2/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5194 - loss: 0.6934 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 3/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5235 - loss: 0.6927 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 4/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6929 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 5/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6926 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 6/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5235 - loss: 0.6926 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 7/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6925 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 8/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6925 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 9/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6960\n",
            "Epoch 10/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 11/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5202 - loss: 0.6932 - val_accuracy: 0.4906 - val_loss: 0.6940\n",
            "Epoch 12/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5235 - loss: 0.6933 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 13/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6925 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 14/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 15/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 16/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 17/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 18/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 19/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6964\n",
            "Epoch 20/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 21/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 22/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 23/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 24/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 25/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 26/30\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5235 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.4893 - loss: 0.6949 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 2/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6932 - val_accuracy: 0.4906 - val_loss: 0.6977\n",
            "Epoch 3/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5241 - loss: 0.6928 - val_accuracy: 0.4906 - val_loss: 0.6966\n",
            "Epoch 4/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6926 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 5/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 6/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6923 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 7/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6960\n",
            "Epoch 8/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6923 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 9/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 10/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 11/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 12/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 13/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 14/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 15/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 16/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 17/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 18/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 19/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 20/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 21/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5120 - loss: 0.6950 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6966\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6967\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5109 - loss: 0.6941 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6953\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6946 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5245 - loss: 0.6932 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 3/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6927 - val_accuracy: 0.4937 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6925 - val_accuracy: 0.4937 - val_loss: 0.6953\n",
            "Epoch 5/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6924 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 6/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6924 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 7/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 8/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 10/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 11/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 12/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 13/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 14/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 15/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 16/30\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.4979 - loss: 0.6944 - val_accuracy: 0.4937 - val_loss: 0.6934\n",
            "Epoch 2/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4955 - loss: 0.6939 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 3/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5046 - loss: 0.6932 - val_accuracy: 0.4937 - val_loss: 0.6962\n",
            "Epoch 4/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6953\n",
            "Epoch 5/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 6/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 7/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 8/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 9/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 10/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 11/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 12/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5250 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 13/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 14/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 15/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 16/30\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 0.4820 - loss: 0.6949 - val_accuracy: 0.4937 - val_loss: 0.6961\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5266 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6948\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5132 - loss: 0.6929 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6944\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6947\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6948\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.5265 - loss: 0.6939 - val_accuracy: 0.4937 - val_loss: 0.6941\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4807 - loss: 0.6929 - val_accuracy: 0.4937 - val_loss: 0.6938\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5265 - loss: 0.6924 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5265 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5265 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6941\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6941\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6939\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5265 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5265 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.4973 - loss: 0.6969 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 2/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6931 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 3/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.4904 - val_loss: 0.6961\n",
            "Epoch 4/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 5/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 0.6927 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 6/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 7/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 8/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6959\n",
            "Epoch 9/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6927 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 10/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 11/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 12/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 13/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 14/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 16/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.4715 - loss: 0.6945 - val_accuracy: 0.4904 - val_loss: 0.6938\n",
            "Epoch 2/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5238 - loss: 0.6935 - val_accuracy: 0.4904 - val_loss: 0.6973\n",
            "Epoch 3/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6929 - val_accuracy: 0.4904 - val_loss: 0.6968\n",
            "Epoch 4/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6926 - val_accuracy: 0.4904 - val_loss: 0.6961\n",
            "Epoch 5/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6960\n",
            "Epoch 6/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5238 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 7/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5238 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 8/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5238 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 9/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5238 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 10/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5238 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 11/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 12/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6927 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 13/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 14/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5238 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 15/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5238 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 16/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5238 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4873 - loss: 0.6942 - val_accuracy: 0.4904 - val_loss: 0.6977\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5229 - loss: 0.6928 - val_accuracy: 0.4904 - val_loss: 0.6959\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6959\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5229 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6959\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.4911 - loss: 0.6938 - val_accuracy: 0.4904 - val_loss: 0.6983\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5257 - loss: 0.6926 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6947\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6944\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6944\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6960\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6952\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6952\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 27/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.5170 - loss: 0.6948 - val_accuracy: 0.4872 - val_loss: 0.6936\n",
            "Epoch 2/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6940 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 3/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5314 - loss: 0.6922 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 4/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6938\n",
            "Epoch 5/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5240 - loss: 0.6929 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 6/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5314 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 7/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5314 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 8/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 9/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 10/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 11/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5314 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 12/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5314 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 13/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5314 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 14/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5314 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 15/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5314 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 16/30\n",
            "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5314 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.4837 - loss: 0.6951 - val_accuracy: 0.4872 - val_loss: 0.6971\n",
            "Epoch 2/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5311 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6968\n",
            "Epoch 3/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 4/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6969\n",
            "Epoch 5/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6953\n",
            "Epoch 6/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6968\n",
            "Epoch 7/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 8/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6948\n",
            "Epoch 9/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5208 - loss: 0.6928 - val_accuracy: 0.4872 - val_loss: 0.6974\n",
            "Epoch 10/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 11/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.5311 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 12/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 13/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 14/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 15/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 16/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 17/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 18/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 19/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 20/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 21/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 22/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 23/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5311 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4944 - loss: 0.6935 - val_accuracy: 0.4872 - val_loss: 0.6968\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.4872 - val_loss: 0.6972\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6921 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5284 - loss: 0.6926 - val_accuracy: 0.4872 - val_loss: 0.6995\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5284 - loss: 0.6923 - val_accuracy: 0.4872 - val_loss: 0.6954\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.4773 - loss: 0.6941 - val_accuracy: 0.4872 - val_loss: 0.6978\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5288 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6958\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6959\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.4859 - loss: 0.6986 - val_accuracy: 0.4839 - val_loss: 0.6946\n",
            "Epoch 2/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6947 - val_accuracy: 0.4839 - val_loss: 0.6934\n",
            "Epoch 3/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6944 - val_accuracy: 0.4839 - val_loss: 0.6974\n",
            "Epoch 4/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 5/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 6/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 7/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5324 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 8/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 9/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 10/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
            "Epoch 11/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 12/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
            "Epoch 13/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
            "Epoch 14/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.5324 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 15/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
            "Epoch 16/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6970\n",
            "Epoch 17/30\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5324 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6978\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.4932 - loss: 0.6970 - val_accuracy: 0.4839 - val_loss: 0.6948\n",
            "Epoch 2/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6928 - val_accuracy: 0.4839 - val_loss: 0.6972\n",
            "Epoch 3/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 4/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6924 - val_accuracy: 0.4839 - val_loss: 0.6989\n",
            "Epoch 5/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6971\n",
            "Epoch 6/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5305 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6970\n",
            "Epoch 7/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6970\n",
            "Epoch 8/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 9/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 10/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 11/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 12/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 13/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 14/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 15/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 16/30\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5305 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.5138 - loss: 0.6940 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.4701 - loss: 0.6957 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4914 - loss: 0.6934 - val_accuracy: 0.4839 - val_loss: 0.6939\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6952\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6967\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6966\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5299 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_log_test = compute_best_results(result_log)\n",
        "result_log_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZMkpPcdoOo8j",
        "outputId": "c155e9b9-4409-4c5a-8766-e5d1a459a37a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model                   <Sequential name=sequential_41, built=True>\n",
              "window_size                                                     100\n",
              "batch_size                                                      128\n",
              "train_accuracy                                             0.528438\n",
              "val_accuracy                                               0.516129\n",
              "X_test            [[[2.1972245773362196, 1.3862943611198906, 0.6...\n",
              "y_test            [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...\n",
              "final_accuracy                                             0.525641\n",
              "Name: 39, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>&lt;Sequential name=sequential_41, built=True&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window_size</th>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_accuracy</th>\n",
              "      <td>0.528438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_accuracy</th>\n",
              "      <td>0.516129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_test</th>\n",
              "      <td>[[[2.1972245773362196, 1.3862943611198906, 0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_test</th>\n",
              "      <td>[1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>final_accuracy</th>\n",
              "      <td>0.525641</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Log transform with normalization"
      ],
      "metadata": {
        "id": "HdHI3eqbWGmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_log_normalized = training_loop(dfs[\"log_normalized\"], window_sizes, batch_sizes)\n",
        "result_log_normalized_test = compute_best_results(result_log_normalized)\n",
        "result_log_normalized_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZyWjJmt9Tgg-",
        "outputId": "e6935a07-52be-45e4-9813-e64fd0ef41f9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4883 - loss: 0.6937 - val_accuracy: 0.4939 - val_loss: 0.6942\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6947\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5215 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5179 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6944\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5206 - loss: 0.6915 - val_accuracy: 0.4939 - val_loss: 0.6935\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6938\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 0.6923 - val_accuracy: 0.4939 - val_loss: 0.6946\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6935\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5204 - loss: 0.6911 - val_accuracy: 0.4939 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5196 - loss: 0.6913 - val_accuracy: 0.4939 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5215 - loss: 0.6915 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5206 - loss: 0.6903 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5413 - loss: 0.6900 - val_accuracy: 0.5061 - val_loss: 0.6930\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5188 - loss: 0.6905 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5140 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5279 - loss: 0.6910 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5123 - loss: 0.6910 - val_accuracy: 0.5183 - val_loss: 0.6931\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5219 - loss: 0.6908 - val_accuracy: 0.5061 - val_loss: 0.6935\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5170 - loss: 0.6896 - val_accuracy: 0.4939 - val_loss: 0.6931\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5260 - loss: 0.6889 - val_accuracy: 0.5061 - val_loss: 0.6934\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5000 - loss: 0.6901 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5597 - loss: 0.6887 - val_accuracy: 0.5122 - val_loss: 0.6931\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5483 - loss: 0.6886 - val_accuracy: 0.5061 - val_loss: 0.6935\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4964 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6935\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5206 - loss: 0.6958 - val_accuracy: 0.5061 - val_loss: 0.6933\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5157 - loss: 0.6907 - val_accuracy: 0.5244 - val_loss: 0.6931\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5223 - loss: 0.6889 - val_accuracy: 0.4878 - val_loss: 0.6930\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5598 - loss: 0.6880 - val_accuracy: 0.5061 - val_loss: 0.6939\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5236 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-ba779eb1a478>:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, temp_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5216 - loss: 0.6931 - val_accuracy: 0.4939 - val_loss: 0.6953\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5200 - loss: 0.6919 - val_accuracy: 0.4939 - val_loss: 0.6948\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5223 - loss: 0.6920 - val_accuracy: 0.4878 - val_loss: 0.6931\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5241 - loss: 0.6911 - val_accuracy: 0.5366 - val_loss: 0.6931\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5228 - loss: 0.6913 - val_accuracy: 0.5061 - val_loss: 0.6930\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5390 - loss: 0.6906 - val_accuracy: 0.5122 - val_loss: 0.6927\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5366 - loss: 0.6903 - val_accuracy: 0.4939 - val_loss: 0.6927\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5508 - loss: 0.6893 - val_accuracy: 0.5122 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5453 - loss: 0.6906 - val_accuracy: 0.5122 - val_loss: 0.6929\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5200 - loss: 0.6923 - val_accuracy: 0.5122 - val_loss: 0.6929\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5250 - loss: 0.6912 - val_accuracy: 0.5122 - val_loss: 0.6931\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5373 - loss: 0.6897 - val_accuracy: 0.5183 - val_loss: 0.6931\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5215 - loss: 0.6890 - val_accuracy: 0.5061 - val_loss: 0.6936\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5251 - loss: 0.6898 - val_accuracy: 0.5061 - val_loss: 0.6938\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5482 - loss: 0.6870 - val_accuracy: 0.5061 - val_loss: 0.6979\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 0.6964 - val_accuracy: 0.4939 - val_loss: 0.6942\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5224 - loss: 0.6917 - val_accuracy: 0.4939 - val_loss: 0.6939\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5224 - loss: 0.6908 - val_accuracy: 0.4939 - val_loss: 0.6934\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5193 - loss: 0.6893 - val_accuracy: 0.4878 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5184 - loss: 0.6885 - val_accuracy: 0.5061 - val_loss: 0.6935\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5068 - loss: 0.6919 - val_accuracy: 0.5061 - val_loss: 0.6930\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 35ms/step - accuracy: 0.4869 - loss: 0.6948 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5033 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6959\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6931 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5189 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6918 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5180 - loss: 0.6912 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5135 - loss: 0.6916 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6916 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5176 - loss: 0.6910 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5189 - loss: 0.6910 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5142 - loss: 0.6909 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6901 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5186 - loss: 0.6901 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5189 - loss: 0.6899 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5171 - loss: 0.6913 - val_accuracy: 0.4847 - val_loss: 0.6931\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5503 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6911 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5184 - loss: 0.6907 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5189 - loss: 0.6898 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5191 - loss: 0.6901 - val_accuracy: 0.4847 - val_loss: 0.6930\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5284 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6931\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5172 - loss: 0.6913 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5156 - loss: 0.6893 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5189 - loss: 0.6915 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5189 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.5187 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6957\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5179 - loss: 0.6933 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5187 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5159 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5176 - loss: 0.6914 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5141 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5124 - loss: 0.6912 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5161 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5269 - loss: 0.6898 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5327 - loss: 0.6907 - val_accuracy: 0.5031 - val_loss: 0.6930\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5128 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6930\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5174 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5175 - loss: 0.6911 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5175 - loss: 0.6907 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5450 - loss: 0.6898 - val_accuracy: 0.5215 - val_loss: 0.6911\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5271 - loss: 0.6895 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5381 - loss: 0.6877 - val_accuracy: 0.5031 - val_loss: 0.6950\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5317 - loss: 0.6900 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5610 - loss: 0.6901 - val_accuracy: 0.5031 - val_loss: 0.6904\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5592 - loss: 0.6891 - val_accuracy: 0.5031 - val_loss: 0.6964\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5386 - loss: 0.6886 - val_accuracy: 0.4969 - val_loss: 0.6960\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5192 - loss: 0.6982 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5218 - loss: 0.6897 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5301 - loss: 0.6876 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5284 - loss: 0.6898 - val_accuracy: 0.5276 - val_loss: 0.6907\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5503 - loss: 0.6879 - val_accuracy: 0.5031 - val_loss: 0.6925\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5636 - loss: 0.6863 - val_accuracy: 0.5031 - val_loss: 0.6945\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5089 - loss: 0.6968 - val_accuracy: 0.4969 - val_loss: 0.6953\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5187 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5187 - loss: 0.6915 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.5340 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5242 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5242 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5213 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6955\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6944\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.5255 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6913 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5264 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5255 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5260 - loss: 0.6907 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5075 - loss: 0.6909 - val_accuracy: 0.5000 - val_loss: 0.6925\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5211 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5089 - loss: 0.6919 - val_accuracy: 0.5370 - val_loss: 0.6919\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5202 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5313 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5144 - loss: 0.6898 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5316 - loss: 0.6892 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5547 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.7011\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5255 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5316 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4986 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5237 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5290 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5321 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6958\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5082 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5358 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6925\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5389 - loss: 0.6886 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.5258 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6958\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6952\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6958\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5258 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.5286 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5079 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6918 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6918 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6917 - val_accuracy: 0.4969 - val_loss: 0.6935\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6918 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5245 - loss: 0.6914 - val_accuracy: 0.4969 - val_loss: 0.6935\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5223 - loss: 0.6908 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5048 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6946\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6942\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5245 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5245 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6950\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5245 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5110 - loss: 0.6936 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6957\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6950\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6951\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6904 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5168 - loss: 0.6970 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6981\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5257 - loss: 0.6915 - val_accuracy: 0.4938 - val_loss: 0.6967\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5211 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6960\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6947\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6916 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6913 - val_accuracy: 0.4938 - val_loss: 0.6938\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6906 - val_accuracy: 0.4938 - val_loss: 0.6958\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6976 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6947\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6916 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5260 - loss: 0.6915 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5242 - loss: 0.6914 - val_accuracy: 0.4875 - val_loss: 0.6932\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5255 - loss: 0.6912 - val_accuracy: 0.5188 - val_loss: 0.6933\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5211 - loss: 0.6912 - val_accuracy: 0.4875 - val_loss: 0.6932\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5257 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5257 - loss: 0.6911 - val_accuracy: 0.4938 - val_loss: 0.6935\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5243 - loss: 0.6933 - val_accuracy: 0.4938 - val_loss: 0.6952\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5243 - loss: 0.6926 - val_accuracy: 0.4938 - val_loss: 0.6941\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5178 - loss: 0.6918 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5229 - loss: 0.6912 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5185 - loss: 0.6928 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6930 - val_accuracy: 0.4938 - val_loss: 0.6940\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6940\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5227 - loss: 0.6917 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5221 - loss: 0.6913 - val_accuracy: 0.5063 - val_loss: 0.6930\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5227 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5226 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5135 - loss: 0.6901 - val_accuracy: 0.5063 - val_loss: 0.6936\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5162 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5243 - loss: 0.6904 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5161 - loss: 0.6920 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5101 - loss: 0.6908 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6908 - val_accuracy: 0.4938 - val_loss: 0.6932\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5186 - loss: 0.6903 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5236 - loss: 0.6898 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5152 - loss: 0.6930 - val_accuracy: 0.4938 - val_loss: 0.6963\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5243 - loss: 0.6928 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6923 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5237 - loss: 0.6921 - val_accuracy: 0.4875 - val_loss: 0.6932\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5170 - loss: 0.6932 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5228 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6963\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6914 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6905 - val_accuracy: 0.4906 - val_loss: 0.6949\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6900 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6900 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6905 - val_accuracy: 0.4906 - val_loss: 0.6946\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6905 - val_accuracy: 0.4906 - val_loss: 0.6945\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6901 - val_accuracy: 0.4906 - val_loss: 0.6945\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6900 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5268 - loss: 0.6910 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5268 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5268 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6955\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.5244 - loss: 0.6930 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5263 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5273 - loss: 0.6915 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5263 - loss: 0.6914 - val_accuracy: 0.5472 - val_loss: 0.6928\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5205 - loss: 0.6917 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5234 - loss: 0.6910 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5238 - loss: 0.6926 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6979\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5271 - loss: 0.6906 - val_accuracy: 0.5094 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4909 - loss: 0.6949 - val_accuracy: 0.5094 - val_loss: 0.6931\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5263 - loss: 0.6907 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5263 - loss: 0.6907 - val_accuracy: 0.4906 - val_loss: 0.6934\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5263 - loss: 0.6906 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5274 - loss: 0.6901 - val_accuracy: 0.4906 - val_loss: 0.6931\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5219 - loss: 0.6948 - val_accuracy: 0.4906 - val_loss: 0.6949\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5069 - loss: 0.6942 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4937 - val_loss: 0.6967\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5156 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6938\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5216 - loss: 0.6927 - val_accuracy: 0.4937 - val_loss: 0.6938\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5239 - loss: 0.6918 - val_accuracy: 0.4937 - val_loss: 0.6937\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5213 - loss: 0.6913 - val_accuracy: 0.4937 - val_loss: 0.6935\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6909 - val_accuracy: 0.4937 - val_loss: 0.6937\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5252 - loss: 0.6915 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5251 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5242 - loss: 0.6905 - val_accuracy: 0.4937 - val_loss: 0.6998\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5212 - loss: 0.6927 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6923 - val_accuracy: 0.4937 - val_loss: 0.6944\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6944\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6944\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6945\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6946\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6948\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6952\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6942\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6943\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.5072 - loss: 0.6933 - val_accuracy: 0.4937 - val_loss: 0.6942\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5119 - loss: 0.6924 - val_accuracy: 0.4937 - val_loss: 0.6935\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5148 - loss: 0.6925 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5243 - loss: 0.6917 - val_accuracy: 0.4937 - val_loss: 0.6942\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6913 - val_accuracy: 0.4684 - val_loss: 0.6938\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5260 - loss: 0.6912 - val_accuracy: 0.5063 - val_loss: 0.6935\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5251 - loss: 0.6903 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5175 - loss: 0.6936 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4863 - loss: 0.6930 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5191 - loss: 0.6921 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5268 - loss: 0.6910 - val_accuracy: 0.4937 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5206 - loss: 0.6907 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5257 - loss: 0.6902 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5202 - loss: 0.6917 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5238 - loss: 0.6908 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5248 - loss: 0.6902 - val_accuracy: 0.5063 - val_loss: 0.6937\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5257 - loss: 0.6903 - val_accuracy: 0.5063 - val_loss: 0.6941\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5264 - loss: 0.6898 - val_accuracy: 0.4873 - val_loss: 0.6943\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5202 - loss: 0.6916 - val_accuracy: 0.5063 - val_loss: 0.6940\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5260 - loss: 0.6923 - val_accuracy: 0.5063 - val_loss: 0.6935\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5245 - loss: 0.6917 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5257 - loss: 0.6913 - val_accuracy: 0.5063 - val_loss: 0.6936\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5251 - loss: 0.6905 - val_accuracy: 0.5063 - val_loss: 0.6940\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4637 - loss: 0.6949 - val_accuracy: 0.4841 - val_loss: 0.6932\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6931 - val_accuracy: 0.4904 - val_loss: 0.6950\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6941\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5059 - loss: 0.6927 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5111 - loss: 0.6931 - val_accuracy: 0.4904 - val_loss: 0.7024\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5086 - loss: 0.6935 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6974\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5233 - loss: 0.6932 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5199 - loss: 0.6916 - val_accuracy: 0.4904 - val_loss: 0.6964\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6938 - val_accuracy: 0.4904 - val_loss: 0.6935\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5226 - loss: 0.6915 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5218 - loss: 0.6905 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5230 - loss: 0.6906 - val_accuracy: 0.4904 - val_loss: 0.6933\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6913 - val_accuracy: 0.4904 - val_loss: 0.6935\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5227 - loss: 0.6901 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5240 - loss: 0.6897 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5184 - loss: 0.6942 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6926 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5229 - loss: 0.6912 - val_accuracy: 0.4904 - val_loss: 0.6940\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5226 - loss: 0.6912 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5148 - loss: 0.6910 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5214 - loss: 0.6891 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5006 - loss: 0.6910 - val_accuracy: 0.4904 - val_loss: 0.6944\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5229 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5229 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5229 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.5257 - loss: 0.6939 - val_accuracy: 0.4904 - val_loss: 0.6972\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6917 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5127 - loss: 0.6919 - val_accuracy: 0.5159 - val_loss: 0.6931\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5151 - loss: 0.6914 - val_accuracy: 0.4904 - val_loss: 0.6937\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.4904 - val_loss: 0.6940\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6953\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6917 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6916 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6914 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6942\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6910 - val_accuracy: 0.4904 - val_loss: 0.6941\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6917 - val_accuracy: 0.4904 - val_loss: 0.6939\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6948\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6956\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6916 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 45ms/step - accuracy: 0.5071 - loss: 0.6938 - val_accuracy: 0.4872 - val_loss: 0.6954\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6924 - val_accuracy: 0.4872 - val_loss: 0.6959\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6969\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6921 - val_accuracy: 0.4872 - val_loss: 0.6975\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6957\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6958\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6913 - val_accuracy: 0.4872 - val_loss: 0.6950\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6973\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5064 - loss: 0.6910 - val_accuracy: 0.4872 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6932 - val_accuracy: 0.4872 - val_loss: 0.6946\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5205 - loss: 0.6911 - val_accuracy: 0.4872 - val_loss: 0.6958\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6892 - val_accuracy: 0.4872 - val_loss: 0.7048\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5067 - loss: 0.6935 - val_accuracy: 0.4872 - val_loss: 0.6971\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.4926 - loss: 0.6932 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5288 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6953\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6948\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5274 - loss: 0.6910 - val_accuracy: 0.4872 - val_loss: 0.6943\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5288 - loss: 0.6910 - val_accuracy: 0.4872 - val_loss: 0.6944\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5288 - loss: 0.6908 - val_accuracy: 0.4872 - val_loss: 0.6942\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5278 - loss: 0.6903 - val_accuracy: 0.5321 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5288 - loss: 0.6891 - val_accuracy: 0.4872 - val_loss: 0.6933\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5430 - loss: 0.6902 - val_accuracy: 0.4808 - val_loss: 0.6935\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5382 - loss: 0.6870 - val_accuracy: 0.5128 - val_loss: 0.6928\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5144 - loss: 0.6885 - val_accuracy: 0.5128 - val_loss: 0.6930\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5049 - loss: 0.6903 - val_accuracy: 0.5128 - val_loss: 0.6931\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5085 - loss: 0.6928 - val_accuracy: 0.4872 - val_loss: 0.6974\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6957\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6957\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6957\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6951\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6950\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6914 - val_accuracy: 0.4872 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - accuracy: 0.4770 - loss: 0.6952 - val_accuracy: 0.4839 - val_loss: 0.6936\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5287 - loss: 0.6924 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6960\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5304 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5123 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6970\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6928 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5268 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6955\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5261 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6999\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.5299 - loss: 0.6938 - val_accuracy: 0.4839 - val_loss: 0.6979\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6961\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6911 - val_accuracy: 0.4839 - val_loss: 0.6973\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6943\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5299 - loss: 0.6904 - val_accuracy: 0.4839 - val_loss: 0.6942\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6897 - val_accuracy: 0.4839 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5299 - loss: 0.6904 - val_accuracy: 0.4839 - val_loss: 0.6935\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6892 - val_accuracy: 0.4839 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5309 - loss: 0.6903 - val_accuracy: 0.4903 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5124 - loss: 0.6929 - val_accuracy: 0.4839 - val_loss: 0.6936\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6901 - val_accuracy: 0.4839 - val_loss: 0.6946\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5283 - loss: 0.6894 - val_accuracy: 0.4839 - val_loss: 0.6932\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5232 - loss: 0.6913 - val_accuracy: 0.5161 - val_loss: 0.6930\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4856 - loss: 0.6920 - val_accuracy: 0.4839 - val_loss: 0.6937\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6959 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6963\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6910 - val_accuracy: 0.5032 - val_loss: 0.6932\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5253 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5299 - loss: 0.6933 - val_accuracy: 0.4839 - val_loss: 0.6942\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6948\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5299 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6948\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.5299 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6940\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5299 - loss: 0.6904 - val_accuracy: 0.4839 - val_loss: 0.6937\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5295 - loss: 0.6901 - val_accuracy: 0.4839 - val_loss: 0.6932\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5299 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6941\n",
            "Epoch 27/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6895 - val_accuracy: 0.4839 - val_loss: 0.6934\n",
            "Epoch 28/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6945\n",
            "Epoch 29/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6894 - val_accuracy: 0.4839 - val_loss: 0.6941\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model                   <Sequential name=sequential_48, built=True>\n",
              "window_size                                                      20\n",
              "batch_size                                                       64\n",
              "train_accuracy                                             0.534565\n",
              "val_accuracy                                               0.496933\n",
              "X_test            [[[0.4824953835245129, 0.29787412371765665, 0....\n",
              "y_test            [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "final_accuracy                                             0.535714\n",
              "Name: 2, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>&lt;Sequential name=sequential_48, built=True&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window_size</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_accuracy</th>\n",
              "      <td>0.534565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_accuracy</th>\n",
              "      <td>0.496933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_test</th>\n",
              "      <td>[[[0.4824953835245129, 0.29787412371765665, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_test</th>\n",
              "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>final_accuracy</th>\n",
              "      <td>0.535714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Min max normalization"
      ],
      "metadata": {
        "id": "LymcQ677YNAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_normalized = training_loop(dfs[\"normalized\"], window_sizes, batch_sizes)\n",
        "result_normalized_test = compute_best_results(result_normalized)\n",
        "result_normalized_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "247UFdQ8YWwb",
        "outputId": "b55fd2cd-fe35-4204-c683-9c03bdb4f138"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.4917 - loss: 0.6932 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6951\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5212 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6950\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5218 - loss: 0.6926 - val_accuracy: 0.4939 - val_loss: 0.6957\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5211 - loss: 0.6925 - val_accuracy: 0.4939 - val_loss: 0.6947\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5195 - loss: 0.6922 - val_accuracy: 0.4939 - val_loss: 0.6934\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5210 - loss: 0.6918 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5213 - loss: 0.6918 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5211 - loss: 0.6918 - val_accuracy: 0.4939 - val_loss: 0.6938\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5212 - loss: 0.6917 - val_accuracy: 0.4939 - val_loss: 0.6945\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5194 - loss: 0.6915 - val_accuracy: 0.4695 - val_loss: 0.6946\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5224 - loss: 0.6916 - val_accuracy: 0.5244 - val_loss: 0.6930\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5154 - loss: 0.6918 - val_accuracy: 0.4695 - val_loss: 0.6942\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5222 - loss: 0.6915 - val_accuracy: 0.4817 - val_loss: 0.6965\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5207 - loss: 0.6926 - val_accuracy: 0.4878 - val_loss: 0.6933\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 0.6917 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 0.6916 - val_accuracy: 0.4939 - val_loss: 0.6949\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5219 - loss: 0.6935 - val_accuracy: 0.5122 - val_loss: 0.6934\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5041 - loss: 0.6928 - val_accuracy: 0.4878 - val_loss: 0.6937\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5222 - loss: 0.6918 - val_accuracy: 0.5366 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5146 - loss: 0.6916 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 0.6917 - val_accuracy: 0.4939 - val_loss: 0.6941\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5225 - loss: 0.6923 - val_accuracy: 0.4695 - val_loss: 0.6936\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5231 - loss: 0.6911 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5216 - loss: 0.6913 - val_accuracy: 0.4817 - val_loss: 0.6936\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5211 - loss: 0.6916 - val_accuracy: 0.4939 - val_loss: 0.6936\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5233 - loss: 0.6910 - val_accuracy: 0.5366 - val_loss: 0.6950\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-ba779eb1a478>:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, temp_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.5163 - loss: 0.6928 - val_accuracy: 0.4939 - val_loss: 0.6952\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5220 - loss: 0.6924 - val_accuracy: 0.4939 - val_loss: 0.6942\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5234 - loss: 0.6918 - val_accuracy: 0.4939 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5231 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6943\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5243 - loss: 0.6913 - val_accuracy: 0.4268 - val_loss: 0.6942\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5230 - loss: 0.6913 - val_accuracy: 0.5061 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5220 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5336 - loss: 0.6913 - val_accuracy: 0.4939 - val_loss: 0.6943\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5235 - loss: 0.6911 - val_accuracy: 0.5061 - val_loss: 0.6940\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5230 - loss: 0.6902 - val_accuracy: 0.4939 - val_loss: 0.6959\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5309 - loss: 0.6914 - val_accuracy: 0.5061 - val_loss: 0.6954\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5243 - loss: 0.6926 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5408 - loss: 0.6903 - val_accuracy: 0.4939 - val_loss: 0.6939\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4691 - loss: 0.6940 - val_accuracy: 0.4939 - val_loss: 0.6938\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5220 - loss: 0.6920 - val_accuracy: 0.4939 - val_loss: 0.6939\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5216 - loss: 0.6919 - val_accuracy: 0.5122 - val_loss: 0.6934\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5204 - loss: 0.6919 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5220 - loss: 0.6913 - val_accuracy: 0.4939 - val_loss: 0.6935\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5219 - loss: 0.6912 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5219 - loss: 0.6909 - val_accuracy: 0.5061 - val_loss: 0.6933\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5258 - loss: 0.6908 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5201 - loss: 0.6904 - val_accuracy: 0.5122 - val_loss: 0.6933\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5216 - loss: 0.6900 - val_accuracy: 0.5061 - val_loss: 0.6943\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5290 - loss: 0.6905 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5324 - loss: 0.6910 - val_accuracy: 0.4939 - val_loss: 0.6940\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5216 - loss: 0.6914 - val_accuracy: 0.5061 - val_loss: 0.6951\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5154 - loss: 0.6902 - val_accuracy: 0.4939 - val_loss: 0.6937\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.5003 - loss: 0.6941 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5184 - loss: 0.6934 - val_accuracy: 0.4969 - val_loss: 0.6963\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5175 - loss: 0.6934 - val_accuracy: 0.4969 - val_loss: 0.6960\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5208 - loss: 0.6928 - val_accuracy: 0.4663 - val_loss: 0.6958\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5183 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5186 - loss: 0.6926 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5195 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6944\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6946\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5184 - loss: 0.6922 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5186 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5187 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 0.6931 - val_accuracy: 0.4847 - val_loss: 0.6935\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5201 - loss: 0.6924 - val_accuracy: 0.4785 - val_loss: 0.6937\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5196 - loss: 0.6925 - val_accuracy: 0.5092 - val_loss: 0.6937\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5190 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5183 - loss: 0.6923 - val_accuracy: 0.4847 - val_loss: 0.6936\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5186 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5186 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5186 - loss: 0.6917 - val_accuracy: 0.4969 - val_loss: 0.6937\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5180 - loss: 0.6925 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5194 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6945\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5192 - loss: 0.6928 - val_accuracy: 0.5031 - val_loss: 0.6944\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.5186 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5186 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5186 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5151 - loss: 0.6928 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5257 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5186 - loss: 0.6925 - val_accuracy: 0.5031 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5183 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5185 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5200 - loss: 0.6916 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5185 - loss: 0.6914 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5186 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4831 - loss: 0.6929 - val_accuracy: 0.5276 - val_loss: 0.6919\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5430 - loss: 0.6927 - val_accuracy: 0.5031 - val_loss: 0.6940\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5282 - loss: 0.6926 - val_accuracy: 0.5031 - val_loss: 0.6943\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4954 - loss: 0.6928 - val_accuracy: 0.5092 - val_loss: 0.6934\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5183 - loss: 0.6905 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5122 - loss: 0.6927 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5171 - loss: 0.6921 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5180 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5334 - loss: 0.6905 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4963 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6936\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5246 - loss: 0.6923 - val_accuracy: 0.4724 - val_loss: 0.6932\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5174 - loss: 0.6909 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5224 - loss: 0.6914 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5185 - loss: 0.6944 - val_accuracy: 0.5031 - val_loss: 0.6938\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5183 - loss: 0.6927 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5179 - loss: 0.6896 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5250 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5093 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5240 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6953\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5240 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5240 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5237 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5246 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5239 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5240 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5262 - loss: 0.6917 - val_accuracy: 0.5000 - val_loss: 0.6956\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5240 - loss: 0.6921 - val_accuracy: 0.4753 - val_loss: 0.6934\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5252 - loss: 0.6918 - val_accuracy: 0.4815 - val_loss: 0.6965\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5238 - loss: 0.6913 - val_accuracy: 0.4383 - val_loss: 0.6936\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5254 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5244 - loss: 0.6913 - val_accuracy: 0.4753 - val_loss: 0.6939\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5238 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5260 - loss: 0.6913 - val_accuracy: 0.5370 - val_loss: 0.6933\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5233 - loss: 0.6916 - val_accuracy: 0.4877 - val_loss: 0.6931\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5240 - loss: 0.6917 - val_accuracy: 0.5000 - val_loss: 0.6941\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5227 - loss: 0.6914 - val_accuracy: 0.4877 - val_loss: 0.6933\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5068 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5240 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5244 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5247 - loss: 0.6892 - val_accuracy: 0.5247 - val_loss: 0.6934\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5170 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5555 - loss: 0.6894 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5261 - loss: 0.6961 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5224 - loss: 0.6912 - val_accuracy: 0.5309 - val_loss: 0.6933\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5246 - loss: 0.6896 - val_accuracy: 0.5123 - val_loss: 0.6957\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.5139 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5254 - loss: 0.6922 - val_accuracy: 0.4568 - val_loss: 0.6938\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5066 - loss: 0.6931 - val_accuracy: 0.4506 - val_loss: 0.6938\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4568 - val_loss: 0.6951\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5242 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5267 - loss: 0.6918 - val_accuracy: 0.4568 - val_loss: 0.6969\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5251 - loss: 0.6920 - val_accuracy: 0.4259 - val_loss: 0.6991\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5254 - loss: 0.6920 - val_accuracy: 0.5000 - val_loss: 0.6952\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5254 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5254 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5273 - loss: 0.6917 - val_accuracy: 0.4877 - val_loss: 0.6949\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5248 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6960\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5281 - loss: 0.6916 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5242 - loss: 0.6913 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5245 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5251 - loss: 0.6905 - val_accuracy: 0.4630 - val_loss: 0.6950\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.5038 - loss: 0.6932 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5255 - loss: 0.6924 - val_accuracy: 0.4969 - val_loss: 0.6952\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5250 - loss: 0.6922 - val_accuracy: 0.4783 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5210 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6960\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6963\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6961\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5248 - loss: 0.6921 - val_accuracy: 0.4907 - val_loss: 0.6940\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4472 - val_loss: 0.6975\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5265 - loss: 0.6920 - val_accuracy: 0.4907 - val_loss: 0.6957\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5248 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6966\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5262 - loss: 0.6920 - val_accuracy: 0.4534 - val_loss: 0.6975\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5270 - loss: 0.6919 - val_accuracy: 0.5031 - val_loss: 0.6950\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5246 - loss: 0.6922 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5233 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5239 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5253 - loss: 0.6920 - val_accuracy: 0.4845 - val_loss: 0.6943\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5265 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6951\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5250 - loss: 0.6920 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5262 - loss: 0.6918 - val_accuracy: 0.4845 - val_loss: 0.6962\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5255 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6954\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5244 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5257 - loss: 0.6919 - val_accuracy: 0.4596 - val_loss: 0.6937\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5244 - loss: 0.6922 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5238 - loss: 0.6916 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5252 - loss: 0.6920 - val_accuracy: 0.4907 - val_loss: 0.6932\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5244 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5244 - loss: 0.6911 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5207 - loss: 0.6909 - val_accuracy: 0.4969 - val_loss: 0.6933\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6928 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.5242 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6943\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5137 - loss: 0.6929 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5242 - loss: 0.6920 - val_accuracy: 0.4969 - val_loss: 0.6941\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5241 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5254 - loss: 0.6925 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5256 - loss: 0.6923 - val_accuracy: 0.4969 - val_loss: 0.6948\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5252 - loss: 0.6924 - val_accuracy: 0.5093 - val_loss: 0.6944\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5221 - loss: 0.6918 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5227 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5224 - loss: 0.6907 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5239 - loss: 0.6920 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5219 - loss: 0.6926 - val_accuracy: 0.4907 - val_loss: 0.6932\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5241 - loss: 0.6919 - val_accuracy: 0.4845 - val_loss: 0.6936\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5247 - loss: 0.6914 - val_accuracy: 0.5031 - val_loss: 0.6953\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5101 - loss: 0.6931 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5223 - loss: 0.6910 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6905 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5227 - loss: 0.6897 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5518 - loss: 0.6893 - val_accuracy: 0.5031 - val_loss: 0.6941\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5124 - loss: 0.6938 - val_accuracy: 0.5093 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.4946 - loss: 0.6934 - val_accuracy: 0.5031 - val_loss: 0.6938\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5140 - loss: 0.6921 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5256 - loss: 0.6912 - val_accuracy: 0.4534 - val_loss: 0.6934\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5249 - loss: 0.6909 - val_accuracy: 0.5217 - val_loss: 0.6938\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6962\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5400 - loss: 0.6904 - val_accuracy: 0.5031 - val_loss: 0.6960\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6895 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5130 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6932\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5224 - loss: 0.6924 - val_accuracy: 0.5031 - val_loss: 0.6935\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5180 - loss: 0.6904 - val_accuracy: 0.5031 - val_loss: 0.6940\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.4716 - loss: 0.6950 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6928 - val_accuracy: 0.4938 - val_loss: 0.6941\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6954\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5256 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5256 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5256 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5258 - loss: 0.6918 - val_accuracy: 0.4938 - val_loss: 0.6958\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5249 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6972\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6954\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5256 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6959\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6948\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6920 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.5205 - loss: 0.6931 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5136 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5113 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5154 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5242 - loss: 0.6913 - val_accuracy: 0.4938 - val_loss: 0.6934\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5242 - loss: 0.6915 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5242 - loss: 0.6922 - val_accuracy: 0.4938 - val_loss: 0.6940\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5242 - loss: 0.6921 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6927 - val_accuracy: 0.4938 - val_loss: 0.6940\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4750 - val_loss: 0.6940\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5260 - loss: 0.6918 - val_accuracy: 0.5063 - val_loss: 0.6957\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5197 - loss: 0.6928 - val_accuracy: 0.5063 - val_loss: 0.6935\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5066 - loss: 0.6941 - val_accuracy: 0.4812 - val_loss: 0.6933\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5253 - loss: 0.6921 - val_accuracy: 0.4875 - val_loss: 0.6945\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5249 - loss: 0.6920 - val_accuracy: 0.4812 - val_loss: 0.6952\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5248 - loss: 0.6919 - val_accuracy: 0.4625 - val_loss: 0.6975\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5225 - loss: 0.6930 - val_accuracy: 0.5063 - val_loss: 0.6940\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5242 - loss: 0.6919 - val_accuracy: 0.4938 - val_loss: 0.6936\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.5266 - loss: 0.6928 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5266 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6967\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5266 - loss: 0.6925 - val_accuracy: 0.4906 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6941\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6938\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5279 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5263 - loss: 0.6914 - val_accuracy: 0.4906 - val_loss: 0.6946\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5264 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5266 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6945\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5102 - loss: 0.6928 - val_accuracy: 0.4906 - val_loss: 0.6980\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6951\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5258 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6977\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.5261 - loss: 0.6927 - val_accuracy: 0.4906 - val_loss: 0.6953\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5261 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6986\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5261 - loss: 0.6923 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5261 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.6968\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6954\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5279 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6946\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5274 - loss: 0.6915 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6924 - val_accuracy: 0.4906 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5261 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6968\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5270 - loss: 0.6913 - val_accuracy: 0.4906 - val_loss: 0.6960\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5275 - loss: 0.6913 - val_accuracy: 0.4906 - val_loss: 0.6944\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5286 - loss: 0.6907 - val_accuracy: 0.4906 - val_loss: 0.7023\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 0.6931 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5270 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6960\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4969 - val_loss: 0.6932\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5275 - loss: 0.6915 - val_accuracy: 0.4906 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5264 - loss: 0.6909 - val_accuracy: 0.4906 - val_loss: 0.6974\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5265 - loss: 0.6925 - val_accuracy: 0.5094 - val_loss: 0.6932\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 0.6915 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5261 - loss: 0.6915 - val_accuracy: 0.4906 - val_loss: 0.6942\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5249 - loss: 0.6940 - val_accuracy: 0.4906 - val_loss: 0.6941\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5260 - loss: 0.6908 - val_accuracy: 0.5157 - val_loss: 0.6931\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5278 - loss: 0.6911 - val_accuracy: 0.4906 - val_loss: 0.6934\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5261 - loss: 0.6909 - val_accuracy: 0.4906 - val_loss: 0.6934\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5261 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6930\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5288 - loss: 0.6906 - val_accuracy: 0.5220 - val_loss: 0.6930\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5274 - loss: 0.6906 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5288 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6933\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.5087 - loss: 0.6934 - val_accuracy: 0.4937 - val_loss: 0.6937\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5052 - loss: 0.6927 - val_accuracy: 0.4937 - val_loss: 0.6953\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5250 - loss: 0.6926 - val_accuracy: 0.4620 - val_loss: 0.6952\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5101 - loss: 0.6940 - val_accuracy: 0.4937 - val_loss: 0.6950\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6922 - val_accuracy: 0.4937 - val_loss: 0.6966\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5250 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6932\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6935\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5263 - loss: 0.6915 - val_accuracy: 0.4937 - val_loss: 0.6935\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5246 - loss: 0.6918 - val_accuracy: 0.4937 - val_loss: 0.6933\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5264 - loss: 0.6912 - val_accuracy: 0.5190 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5269 - loss: 0.6913 - val_accuracy: 0.5127 - val_loss: 0.6946\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5230 - loss: 0.6909 - val_accuracy: 0.4937 - val_loss: 0.7074\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6955 - val_accuracy: 0.4937 - val_loss: 0.6951\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5263 - loss: 0.6920 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6948\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6949\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.4841 - loss: 0.6938 - val_accuracy: 0.4937 - val_loss: 0.6940\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.4747 - val_loss: 0.6944\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5243 - loss: 0.6920 - val_accuracy: 0.4747 - val_loss: 0.6945\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5259 - loss: 0.6921 - val_accuracy: 0.4557 - val_loss: 0.6965\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5288 - loss: 0.6918 - val_accuracy: 0.5127 - val_loss: 0.6972\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5258 - loss: 0.6924 - val_accuracy: 0.5063 - val_loss: 0.6950\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5255 - loss: 0.6918 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5258 - loss: 0.6918 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5266 - loss: 0.6915 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5292 - loss: 0.6914 - val_accuracy: 0.5063 - val_loss: 0.6938\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5258 - loss: 0.6915 - val_accuracy: 0.5063 - val_loss: 0.6941\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5258 - loss: 0.6914 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5261 - loss: 0.6906 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5306 - loss: 0.6910 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4996 - loss: 0.6933 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5264 - loss: 0.6901 - val_accuracy: 0.4937 - val_loss: 0.6977\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5261 - loss: 0.7024 - val_accuracy: 0.4937 - val_loss: 0.6936\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5261 - loss: 0.6928 - val_accuracy: 0.4937 - val_loss: 0.6939\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5261 - loss: 0.6921 - val_accuracy: 0.4937 - val_loss: 0.6945\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5261 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6945\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5261 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6945\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5261 - loss: 0.6919 - val_accuracy: 0.4937 - val_loss: 0.6944\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4897 - loss: 0.6953 - val_accuracy: 0.4904 - val_loss: 0.6950\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6929 - val_accuracy: 0.4904 - val_loss: 0.6964\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5227 - loss: 0.6931 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5231 - loss: 0.6930 - val_accuracy: 0.4777 - val_loss: 0.6969\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6933 - val_accuracy: 0.4904 - val_loss: 0.6979\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5227 - loss: 0.6933 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5228 - loss: 0.6923 - val_accuracy: 0.4650 - val_loss: 0.6943\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5201 - loss: 0.6927 - val_accuracy: 0.4904 - val_loss: 0.6984\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5227 - loss: 0.6929 - val_accuracy: 0.4904 - val_loss: 0.6961\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5227 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6954\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5227 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5227 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6950\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5238 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6943\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6948\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5227 - loss: 0.6921 - val_accuracy: 0.4713 - val_loss: 0.6940\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5235 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6974\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5242 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6938\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5235 - loss: 0.6920 - val_accuracy: 0.5096 - val_loss: 0.6936\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5223 - loss: 0.6918 - val_accuracy: 0.4904 - val_loss: 0.6949\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5227 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6947\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5226 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5236 - loss: 0.6930 - val_accuracy: 0.5223 - val_loss: 0.6930\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6918 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5238 - loss: 0.6917 - val_accuracy: 0.4968 - val_loss: 0.6933\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5239 - loss: 0.6915 - val_accuracy: 0.4904 - val_loss: 0.6950\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5227 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6939\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5248 - loss: 0.6920 - val_accuracy: 0.4968 - val_loss: 0.6938\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5226 - loss: 0.6912 - val_accuracy: 0.5478 - val_loss: 0.6925\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5398 - loss: 0.6915 - val_accuracy: 0.5032 - val_loss: 0.6935\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5244 - loss: 0.6913 - val_accuracy: 0.4841 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5255 - loss: 0.6934 - val_accuracy: 0.4904 - val_loss: 0.6966\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6946\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5255 - loss: 0.6918 - val_accuracy: 0.4968 - val_loss: 0.6932\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5282 - loss: 0.6914 - val_accuracy: 0.4904 - val_loss: 0.6935\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5255 - loss: 0.6914 - val_accuracy: 0.4904 - val_loss: 0.6937\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5255 - loss: 0.6911 - val_accuracy: 0.4904 - val_loss: 0.6937\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5274 - loss: 0.6910 - val_accuracy: 0.4395 - val_loss: 0.6937\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5265 - loss: 0.6908 - val_accuracy: 0.5096 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5240 - loss: 0.6898 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5255 - loss: 0.6921 - val_accuracy: 0.4904 - val_loss: 0.6935\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5267 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5261 - loss: 0.6907 - val_accuracy: 0.4904 - val_loss: 0.6936\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5261 - loss: 0.6900 - val_accuracy: 0.5096 - val_loss: 0.6934\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5281 - loss: 0.6903 - val_accuracy: 0.5096 - val_loss: 0.6934\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5442 - loss: 0.6893 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5260 - loss: 0.6893 - val_accuracy: 0.4841 - val_loss: 0.6931\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5319 - loss: 0.6949 - val_accuracy: 0.5096 - val_loss: 0.6929\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4873 - loss: 0.6935 - val_accuracy: 0.4904 - val_loss: 0.6933\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5255 - loss: 0.6907 - val_accuracy: 0.4904 - val_loss: 0.6938\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5255 - loss: 0.6884 - val_accuracy: 0.4904 - val_loss: 0.6934\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5240 - loss: 0.6874 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5364 - loss: 0.6879 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5092 - loss: 0.6917 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5255 - loss: 0.6900 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5250 - loss: 0.6891 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 27/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5388 - loss: 0.6926 - val_accuracy: 0.5096 - val_loss: 0.6930\n",
            "Epoch 28/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5108 - loss: 0.6918 - val_accuracy: 0.5096 - val_loss: 0.6931\n",
            "Epoch 29/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5277 - loss: 0.6904 - val_accuracy: 0.4904 - val_loss: 0.6932\n",
            "Epoch 30/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5482 - loss: 0.6898 - val_accuracy: 0.5096 - val_loss: 0.6931\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - accuracy: 0.5181 - loss: 0.6930 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5282 - loss: 0.6927 - val_accuracy: 0.4872 - val_loss: 0.6974\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6926 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5290 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6976\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5276 - loss: 0.6923 - val_accuracy: 0.4744 - val_loss: 0.6951\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5282 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6972\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5275 - loss: 0.6920 - val_accuracy: 0.4615 - val_loss: 0.6947\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5301 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6981\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6920 - val_accuracy: 0.4872 - val_loss: 0.6949\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5278 - loss: 0.6917 - val_accuracy: 0.4679 - val_loss: 0.6935\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5308 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5286 - loss: 0.6924 - val_accuracy: 0.5128 - val_loss: 0.6933\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5273 - loss: 0.6916 - val_accuracy: 0.4679 - val_loss: 0.6933\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6941\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6913 - val_accuracy: 0.4872 - val_loss: 0.6950\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5300 - loss: 0.6913 - val_accuracy: 0.4872 - val_loss: 0.6953\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5300 - loss: 0.6913 - val_accuracy: 0.5128 - val_loss: 0.6931\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5293 - loss: 0.6907 - val_accuracy: 0.4872 - val_loss: 0.7078\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5282 - loss: 0.6935 - val_accuracy: 0.4872 - val_loss: 0.6954\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5282 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5282 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6958\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5282 - loss: 0.6919 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5282 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6961\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6962\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6963\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5282 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.5287 - loss: 0.6929 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5287 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6947\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5287 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6949\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5290 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6947\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5286 - loss: 0.6917 - val_accuracy: 0.4744 - val_loss: 0.6936\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5287 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6941\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5283 - loss: 0.6912 - val_accuracy: 0.4808 - val_loss: 0.6932\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5287 - loss: 0.6907 - val_accuracy: 0.4872 - val_loss: 0.6934\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5305 - loss: 0.6906 - val_accuracy: 0.4872 - val_loss: 0.6936\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5303 - loss: 0.6901 - val_accuracy: 0.4872 - val_loss: 0.6945\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5299 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6945\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5297 - loss: 0.6908 - val_accuracy: 0.4872 - val_loss: 0.6941\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5287 - loss: 0.6921 - val_accuracy: 0.4872 - val_loss: 0.6965\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6964\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6955\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6953\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5287 - loss: 0.6915 - val_accuracy: 0.4872 - val_loss: 0.6958\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5287 - loss: 0.6916 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5277 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6952\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5287 - loss: 0.6918 - val_accuracy: 0.4872 - val_loss: 0.6970\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5287 - loss: 0.6917 - val_accuracy: 0.4872 - val_loss: 0.6960\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.5284 - loss: 0.6934 - val_accuracy: 0.4839 - val_loss: 0.6974\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5284 - loss: 0.6921 - val_accuracy: 0.4839 - val_loss: 0.6956\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5220 - loss: 0.6926 - val_accuracy: 0.4839 - val_loss: 0.6973\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5284 - loss: 0.6923 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6978\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6925 - val_accuracy: 0.4839 - val_loss: 0.6983\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6957\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6964\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6956\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6925 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5284 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6957\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6958\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6940\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6981\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6919 - val_accuracy: 0.4839 - val_loss: 0.6958\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6953\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6957\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5270 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6983\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5284 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6960\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5300 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5291 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6957\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5281 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6953\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5263 - loss: 0.6916 - val_accuracy: 0.5161 - val_loss: 0.6928\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5276 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6938\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5293 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6973\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5284 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6969\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5288 - loss: 0.6910 - val_accuracy: 0.4839 - val_loss: 0.6962\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5478 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6978\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5283 - loss: 0.6911 - val_accuracy: 0.5032 - val_loss: 0.6936\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.4561 - loss: 0.6946 - val_accuracy: 0.4839 - val_loss: 0.6944\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5310 - loss: 0.6921 - val_accuracy: 0.4839 - val_loss: 0.6988\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5296 - loss: 0.6917 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5293 - loss: 0.6916 - val_accuracy: 0.4710 - val_loss: 0.6941\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5296 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6981\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5314 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6974\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5300 - loss: 0.6913 - val_accuracy: 0.4839 - val_loss: 0.6975\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5310 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6985\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5288 - loss: 0.6918 - val_accuracy: 0.4839 - val_loss: 0.6979\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.5296 - loss: 0.6916 - val_accuracy: 0.4839 - val_loss: 0.6973\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.5296 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6954\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5296 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6965\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5296 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6943\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5296 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6945\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5304 - loss: 0.6911 - val_accuracy: 0.4581 - val_loss: 0.6952\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5296 - loss: 0.6922 - val_accuracy: 0.4839 - val_loss: 0.6968\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5309 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6940\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5304 - loss: 0.6912 - val_accuracy: 0.4839 - val_loss: 0.6954\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.5315 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5303 - loss: 0.6906 - val_accuracy: 0.4903 - val_loss: 0.6944\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5296 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6942\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.5259 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6942\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5303 - loss: 0.6901 - val_accuracy: 0.5032 - val_loss: 0.6936\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5308 - loss: 0.6893 - val_accuracy: 0.5290 - val_loss: 0.6941\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5336 - loss: 0.6894 - val_accuracy: 0.4968 - val_loss: 0.6966\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5375 - loss: 0.6900 - val_accuracy: 0.5032 - val_loss: 0.6932\n",
            "Epoch 27/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5164 - loss: 0.6914 - val_accuracy: 0.4839 - val_loss: 0.6946\n",
            "Epoch 28/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5296 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6959\n",
            "Epoch 29/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5296 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 30/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5296 - loss: 0.6897 - val_accuracy: 0.4839 - val_loss: 0.6952\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 99ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 141ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model                   <Sequential name=sequential_69, built=True>\n",
              "window_size                                                      20\n",
              "batch_size                                                      128\n",
              "train_accuracy                                             0.538988\n",
              "val_accuracy                                               0.527607\n",
              "X_test            [[[0.0851063829787234, 0.028846153846153848, 0...\n",
              "y_test            [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "final_accuracy                                             0.535714\n",
              "Name: 3, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>&lt;Sequential name=sequential_69, built=True&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window_size</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_accuracy</th>\n",
              "      <td>0.538988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_accuracy</th>\n",
              "      <td>0.527607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_test</th>\n",
              "      <td>[[[0.0851063829787234, 0.028846153846153848, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_test</th>\n",
              "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>final_accuracy</th>\n",
              "      <td>0.535714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standard scaling"
      ],
      "metadata": {
        "id": "YhXR0yXraS5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_scaled = training_loop(dfs[\"scaled\"], window_sizes, batch_sizes)\n",
        "result_scaled_test = compute_best_results(result_scaled)\n",
        "result_scaled_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dywcQCI8aVhZ",
        "outputId": "8a4af76f-ffb2-49b5-941b-b59be63f94fd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step - accuracy: 0.5224 - loss: 0.6938 - val_accuracy: 0.5366 - val_loss: 0.6928\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5237 - loss: 0.6926 - val_accuracy: 0.4878 - val_loss: 0.6940\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5246 - loss: 0.6911 - val_accuracy: 0.5000 - val_loss: 0.6976\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5238 - loss: 0.6902 - val_accuracy: 0.5671 - val_loss: 0.6977\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5231 - loss: 0.6902 - val_accuracy: 0.4878 - val_loss: 0.6958\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5403 - loss: 0.6893 - val_accuracy: 0.4939 - val_loss: 0.6986\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5240 - loss: 0.6947 - val_accuracy: 0.4146 - val_loss: 0.6981\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5256 - loss: 0.6895 - val_accuracy: 0.4939 - val_loss: 0.6939\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5200 - loss: 0.6907 - val_accuracy: 0.4512 - val_loss: 0.6967\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5172 - loss: 0.6994 - val_accuracy: 0.4695 - val_loss: 0.6990\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5327 - loss: 0.6898 - val_accuracy: 0.4512 - val_loss: 0.7050\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5495 - loss: 0.6887 - val_accuracy: 0.4695 - val_loss: 0.7001\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5417 - loss: 0.6886 - val_accuracy: 0.5122 - val_loss: 0.6976\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5326 - loss: 0.6935 - val_accuracy: 0.4756 - val_loss: 0.6985\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5376 - loss: 0.6876 - val_accuracy: 0.4634 - val_loss: 0.7033\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5688 - loss: 0.6850 - val_accuracy: 0.4451 - val_loss: 0.7140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-ba779eb1a478>:71: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat([result, temp_df], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5162 - loss: 0.6926 - val_accuracy: 0.5183 - val_loss: 0.6933\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5216 - loss: 0.6916 - val_accuracy: 0.5061 - val_loss: 0.6931\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5230 - loss: 0.6907 - val_accuracy: 0.5305 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5223 - loss: 0.6901 - val_accuracy: 0.4634 - val_loss: 0.6941\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5301 - loss: 0.6894 - val_accuracy: 0.4756 - val_loss: 0.6945\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5466 - loss: 0.6879 - val_accuracy: 0.5305 - val_loss: 0.6951\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5485 - loss: 0.6873 - val_accuracy: 0.5183 - val_loss: 0.6942\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5048 - loss: 0.6931 - val_accuracy: 0.4634 - val_loss: 0.6980\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5284 - loss: 0.6949 - val_accuracy: 0.4756 - val_loss: 0.6965\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4896 - loss: 0.6917 - val_accuracy: 0.4878 - val_loss: 0.6979\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5226 - loss: 0.6917 - val_accuracy: 0.5061 - val_loss: 0.6949\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5281 - loss: 0.6908 - val_accuracy: 0.5000 - val_loss: 0.6991\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5481 - loss: 0.6895 - val_accuracy: 0.4207 - val_loss: 0.6985\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5460 - loss: 0.6858 - val_accuracy: 0.4939 - val_loss: 0.6973\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5543 - loss: 0.6852 - val_accuracy: 0.4695 - val_loss: 0.7028\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5337 - loss: 0.6930 - val_accuracy: 0.4573 - val_loss: 0.6969\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5537 - loss: 0.6863 - val_accuracy: 0.5122 - val_loss: 0.6959\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5096 - loss: 0.6939 - val_accuracy: 0.5583 - val_loss: 0.6932\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5189 - loss: 0.6936 - val_accuracy: 0.4969 - val_loss: 0.6934\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5196 - loss: 0.6926 - val_accuracy: 0.4908 - val_loss: 0.6932\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5203 - loss: 0.6918 - val_accuracy: 0.5276 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5208 - loss: 0.6911 - val_accuracy: 0.5215 - val_loss: 0.6946\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5188 - loss: 0.6919 - val_accuracy: 0.5031 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5337 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6962\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5132 - loss: 0.6942 - val_accuracy: 0.5153 - val_loss: 0.6928\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5186 - loss: 0.6929 - val_accuracy: 0.4847 - val_loss: 0.6944\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5202 - loss: 0.6914 - val_accuracy: 0.5092 - val_loss: 0.6945\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5238 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6977\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5342 - loss: 0.6924 - val_accuracy: 0.5031 - val_loss: 0.6939\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5352 - loss: 0.6913 - val_accuracy: 0.4969 - val_loss: 0.6939\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5311 - loss: 0.6903 - val_accuracy: 0.4969 - val_loss: 0.6930\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5226 - loss: 0.6917 - val_accuracy: 0.4969 - val_loss: 0.6935\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5297 - loss: 0.6924 - val_accuracy: 0.5460 - val_loss: 0.6934\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5508 - loss: 0.6869 - val_accuracy: 0.5092 - val_loss: 0.6949\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5342 - loss: 0.6916 - val_accuracy: 0.5092 - val_loss: 0.6950\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5584 - loss: 0.6897 - val_accuracy: 0.4969 - val_loss: 0.6966\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5207 - loss: 0.6968 - val_accuracy: 0.5153 - val_loss: 0.6926\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5355 - loss: 0.6892 - val_accuracy: 0.4847 - val_loss: 0.7009\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5260 - loss: 0.6909 - val_accuracy: 0.5031 - val_loss: 0.6954\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5359 - loss: 0.6905 - val_accuracy: 0.4847 - val_loss: 0.6971\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5276 - loss: 0.6895 - val_accuracy: 0.4969 - val_loss: 0.6949\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5289 - loss: 0.6894 - val_accuracy: 0.5031 - val_loss: 0.6942\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5328 - loss: 0.6888 - val_accuracy: 0.5031 - val_loss: 0.6931\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5252 - loss: 0.6914 - val_accuracy: 0.5276 - val_loss: 0.6925\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5210 - loss: 0.6918 - val_accuracy: 0.4847 - val_loss: 0.6927\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5211 - loss: 0.6921 - val_accuracy: 0.4356 - val_loss: 0.6941\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 0.6921 - val_accuracy: 0.4356 - val_loss: 0.6961\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.4822 - loss: 0.6936 - val_accuracy: 0.5337 - val_loss: 0.6927\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5202 - loss: 0.6924 - val_accuracy: 0.5031 - val_loss: 0.6939\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5218 - loss: 0.6923 - val_accuracy: 0.5031 - val_loss: 0.6936\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5210 - loss: 0.6906 - val_accuracy: 0.5031 - val_loss: 0.6941\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5196 - loss: 0.6914 - val_accuracy: 0.4908 - val_loss: 0.6963\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5294 - loss: 0.6914 - val_accuracy: 0.5031 - val_loss: 0.6946\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5421 - loss: 0.6897 - val_accuracy: 0.5153 - val_loss: 0.6933\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5214 - loss: 0.6947 - val_accuracy: 0.5031 - val_loss: 0.6979\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5031 - loss: 0.6921 - val_accuracy: 0.4969 - val_loss: 0.7008\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5294 - loss: 0.6892 - val_accuracy: 0.5153 - val_loss: 0.6988\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5404 - loss: 0.6896 - val_accuracy: 0.5153 - val_loss: 0.6955\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5294 - loss: 0.6904 - val_accuracy: 0.4908 - val_loss: 0.6975\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5481 - loss: 0.6870 - val_accuracy: 0.4785 - val_loss: 0.6950\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5500 - loss: 0.6865 - val_accuracy: 0.5276 - val_loss: 0.6961\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5240 - loss: 0.6995 - val_accuracy: 0.4969 - val_loss: 0.6955\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5535 - loss: 0.6881 - val_accuracy: 0.4663 - val_loss: 0.6983\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5118 - loss: 0.6943 - val_accuracy: 0.5123 - val_loss: 0.6938\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5244 - loss: 0.6927 - val_accuracy: 0.4877 - val_loss: 0.6942\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5227 - loss: 0.6920 - val_accuracy: 0.5247 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 0.6912 - val_accuracy: 0.4568 - val_loss: 0.6939\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5231 - loss: 0.6917 - val_accuracy: 0.5309 - val_loss: 0.6941\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5252 - loss: 0.6920 - val_accuracy: 0.4630 - val_loss: 0.6952\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5250 - loss: 0.6908 - val_accuracy: 0.5000 - val_loss: 0.6964\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5320 - loss: 0.6899 - val_accuracy: 0.5000 - val_loss: 0.6983\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5207 - loss: 0.6934 - val_accuracy: 0.4938 - val_loss: 0.6958\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5010 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5264 - loss: 0.6909 - val_accuracy: 0.5000 - val_loss: 0.6964\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5239 - loss: 0.6904 - val_accuracy: 0.4877 - val_loss: 0.6988\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5275 - loss: 0.6907 - val_accuracy: 0.4444 - val_loss: 0.6949\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5444 - loss: 0.6890 - val_accuracy: 0.5247 - val_loss: 0.6975\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5379 - loss: 0.6907 - val_accuracy: 0.5123 - val_loss: 0.6992\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5499 - loss: 0.6878 - val_accuracy: 0.4877 - val_loss: 0.7034\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 85ms/step - accuracy: 0.5037 - loss: 0.6934 - val_accuracy: 0.4938 - val_loss: 0.6939\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5267 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6983\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5257 - loss: 0.6913 - val_accuracy: 0.5000 - val_loss: 0.6982\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5263 - loss: 0.6912 - val_accuracy: 0.5000 - val_loss: 0.6970\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5285 - loss: 0.6907 - val_accuracy: 0.5000 - val_loss: 0.6975\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5266 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6992\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5254 - loss: 0.6910 - val_accuracy: 0.4938 - val_loss: 0.6943\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5260 - loss: 0.6914 - val_accuracy: 0.5062 - val_loss: 0.6938\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5281 - loss: 0.6900 - val_accuracy: 0.5000 - val_loss: 0.6963\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5289 - loss: 0.6897 - val_accuracy: 0.5000 - val_loss: 0.7004\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5192 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6986\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5305 - loss: 0.6896 - val_accuracy: 0.4815 - val_loss: 0.6967\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5330 - loss: 0.6887 - val_accuracy: 0.4753 - val_loss: 0.7035\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5388 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.7015\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5386 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.6970\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5325 - loss: 0.6902 - val_accuracy: 0.5000 - val_loss: 0.6991\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5474 - loss: 0.6885 - val_accuracy: 0.4630 - val_loss: 0.7019\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5441 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.7069\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5393 - loss: 0.6897 - val_accuracy: 0.5000 - val_loss: 0.7061\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5406 - loss: 0.6887 - val_accuracy: 0.5000 - val_loss: 0.7060\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5411 - loss: 0.6876 - val_accuracy: 0.4877 - val_loss: 0.6997\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5467 - loss: 0.6875 - val_accuracy: 0.4877 - val_loss: 0.6998\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5406 - loss: 0.6919 - val_accuracy: 0.5000 - val_loss: 0.7073\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - accuracy: 0.5254 - loss: 0.6935 - val_accuracy: 0.4969 - val_loss: 0.6956\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5228 - loss: 0.6930 - val_accuracy: 0.4969 - val_loss: 0.6929\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5269 - loss: 0.6913 - val_accuracy: 0.4783 - val_loss: 0.6931\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5255 - loss: 0.6939 - val_accuracy: 0.4720 - val_loss: 0.6946\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4869 - loss: 0.6936 - val_accuracy: 0.5155 - val_loss: 0.6939\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5267 - loss: 0.6919 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4896 - loss: 0.6945 - val_accuracy: 0.4720 - val_loss: 0.6941\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5270 - loss: 0.6920 - val_accuracy: 0.4720 - val_loss: 0.6972\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5088 - loss: 0.6937 - val_accuracy: 0.5217 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5255 - loss: 0.6917 - val_accuracy: 0.4969 - val_loss: 0.6931\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5255 - loss: 0.6910 - val_accuracy: 0.5031 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5295 - loss: 0.6929 - val_accuracy: 0.5093 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4967 - loss: 0.6920 - val_accuracy: 0.4783 - val_loss: 0.6944\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5261 - loss: 0.6913 - val_accuracy: 0.4410 - val_loss: 0.6945\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5260 - loss: 0.6905 - val_accuracy: 0.4596 - val_loss: 0.6951\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5437 - loss: 0.6902 - val_accuracy: 0.4658 - val_loss: 0.6950\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5250 - loss: 0.6915 - val_accuracy: 0.5031 - val_loss: 0.6946\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.4691 - loss: 0.6960 - val_accuracy: 0.5031 - val_loss: 0.6949\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5105 - loss: 0.6931 - val_accuracy: 0.5031 - val_loss: 0.6948\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5250 - loss: 0.6917 - val_accuracy: 0.5031 - val_loss: 0.6986\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5236 - loss: 0.6913 - val_accuracy: 0.5031 - val_loss: 0.6985\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5242 - loss: 0.6911 - val_accuracy: 0.4596 - val_loss: 0.6940\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5250 - loss: 0.6912 - val_accuracy: 0.4907 - val_loss: 0.6934\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5082 - loss: 0.6926 - val_accuracy: 0.4658 - val_loss: 0.6941\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5241 - loss: 0.6915 - val_accuracy: 0.4845 - val_loss: 0.6935\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5336 - loss: 0.6909 - val_accuracy: 0.5031 - val_loss: 0.6944\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5251 - loss: 0.6902 - val_accuracy: 0.5217 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5361 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6969\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5449 - loss: 0.6894 - val_accuracy: 0.4783 - val_loss: 0.6933\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5156 - loss: 0.6929 - val_accuracy: 0.4845 - val_loss: 0.6952\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5267 - loss: 0.6910 - val_accuracy: 0.4907 - val_loss: 0.6978\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5275 - loss: 0.6902 - val_accuracy: 0.5031 - val_loss: 0.6985\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5252 - loss: 0.6910 - val_accuracy: 0.4783 - val_loss: 0.6958\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5242 - loss: 0.6913 - val_accuracy: 0.5404 - val_loss: 0.6925\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5264 - loss: 0.6905 - val_accuracy: 0.4472 - val_loss: 0.6956\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5307 - loss: 0.6896 - val_accuracy: 0.4969 - val_loss: 0.6970\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5301 - loss: 0.6890 - val_accuracy: 0.4969 - val_loss: 0.6947\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5428 - loss: 0.6906 - val_accuracy: 0.5031 - val_loss: 0.7010\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5252 - loss: 0.6927 - val_accuracy: 0.5031 - val_loss: 0.7012\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4838 - loss: 0.6942 - val_accuracy: 0.5031 - val_loss: 0.6937\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5259 - loss: 0.6908 - val_accuracy: 0.5031 - val_loss: 0.6991\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5277 - loss: 0.6899 - val_accuracy: 0.4720 - val_loss: 0.7033\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5268 - loss: 0.6906 - val_accuracy: 0.4969 - val_loss: 0.6999\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5238 - loss: 0.6907 - val_accuracy: 0.4783 - val_loss: 0.6989\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5244 - loss: 0.6903 - val_accuracy: 0.5031 - val_loss: 0.6961\n",
            "Epoch 29/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5253 - loss: 0.6893 - val_accuracy: 0.5031 - val_loss: 0.6958\n",
            "Epoch 30/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5343 - loss: 0.6886 - val_accuracy: 0.4720 - val_loss: 0.6977\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.4975 - loss: 0.6951 - val_accuracy: 0.5063 - val_loss: 0.6924\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5216 - loss: 0.6927 - val_accuracy: 0.4938 - val_loss: 0.6931\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5234 - loss: 0.6919 - val_accuracy: 0.4750 - val_loss: 0.6935\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5264 - loss: 0.6927 - val_accuracy: 0.4875 - val_loss: 0.6933\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5069 - loss: 0.6920 - val_accuracy: 0.4875 - val_loss: 0.6937\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5037 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5223 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6937\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5256 - loss: 0.6913 - val_accuracy: 0.4938 - val_loss: 0.6941\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5296 - loss: 0.6909 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4995 - loss: 0.6914 - val_accuracy: 0.4875 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5281 - loss: 0.6908 - val_accuracy: 0.5312 - val_loss: 0.6929\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5263 - loss: 0.6922 - val_accuracy: 0.5188 - val_loss: 0.6940\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5419 - loss: 0.6902 - val_accuracy: 0.5375 - val_loss: 0.6929\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5444 - loss: 0.6897 - val_accuracy: 0.5063 - val_loss: 0.6938\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5283 - loss: 0.6923 - val_accuracy: 0.5375 - val_loss: 0.6909\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5410 - loss: 0.6904 - val_accuracy: 0.5375 - val_loss: 0.6923\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5436 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6988\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5430 - loss: 0.6904 - val_accuracy: 0.4750 - val_loss: 0.6942\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5414 - loss: 0.6889 - val_accuracy: 0.5188 - val_loss: 0.6947\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5310 - loss: 0.6917 - val_accuracy: 0.4938 - val_loss: 0.6946\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5285 - loss: 0.6912 - val_accuracy: 0.5375 - val_loss: 0.6935\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5291 - loss: 0.6898 - val_accuracy: 0.5125 - val_loss: 0.6936\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5424 - loss: 0.6904 - val_accuracy: 0.4750 - val_loss: 0.6951\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5292 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6940\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5285 - loss: 0.6903 - val_accuracy: 0.4938 - val_loss: 0.6964\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5295 - loss: 0.6901 - val_accuracy: 0.5063 - val_loss: 0.6959\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5280 - loss: 0.6907 - val_accuracy: 0.5375 - val_loss: 0.6918\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5277 - loss: 0.6906 - val_accuracy: 0.4938 - val_loss: 0.6944\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5283 - loss: 0.6901 - val_accuracy: 0.4938 - val_loss: 0.6919\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5331 - loss: 0.6904 - val_accuracy: 0.5188 - val_loss: 0.6959\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.5145 - loss: 0.6932 - val_accuracy: 0.4625 - val_loss: 0.6940\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5228 - loss: 0.6925 - val_accuracy: 0.4938 - val_loss: 0.6942\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5254 - loss: 0.6915 - val_accuracy: 0.4812 - val_loss: 0.6944\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5240 - loss: 0.6908 - val_accuracy: 0.5125 - val_loss: 0.6953\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5468 - loss: 0.6900 - val_accuracy: 0.4938 - val_loss: 0.6949\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5243 - loss: 0.6953 - val_accuracy: 0.5063 - val_loss: 0.6967\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5234 - loss: 0.6914 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5249 - loss: 0.6908 - val_accuracy: 0.5063 - val_loss: 0.6944\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5303 - loss: 0.6899 - val_accuracy: 0.4625 - val_loss: 0.6936\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5456 - loss: 0.6879 - val_accuracy: 0.4625 - val_loss: 0.6940\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4966 - loss: 0.6974 - val_accuracy: 0.4938 - val_loss: 0.6941\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5248 - loss: 0.6904 - val_accuracy: 0.4750 - val_loss: 0.6940\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5397 - loss: 0.6896 - val_accuracy: 0.4750 - val_loss: 0.6994\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5310 - loss: 0.6907 - val_accuracy: 0.4938 - val_loss: 0.6945\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5508 - loss: 0.6868 - val_accuracy: 0.4688 - val_loss: 0.6994\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5515 - loss: 0.6861 - val_accuracy: 0.4938 - val_loss: 0.6957\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4991 - loss: 0.6920 - val_accuracy: 0.5063 - val_loss: 0.6962\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5453 - loss: 0.6860 - val_accuracy: 0.5125 - val_loss: 0.6940\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5670 - loss: 0.6848 - val_accuracy: 0.5000 - val_loss: 0.6976\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5521 - loss: 0.6838 - val_accuracy: 0.5000 - val_loss: 0.6954\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5411 - loss: 0.6871 - val_accuracy: 0.5437 - val_loss: 0.6932\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5479 - loss: 0.6839 - val_accuracy: 0.4938 - val_loss: 0.6953\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.5089 - loss: 0.6936 - val_accuracy: 0.4843 - val_loss: 0.6939\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5261 - loss: 0.6926 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5273 - loss: 0.6912 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6964\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6920 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5266 - loss: 0.6913 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5275 - loss: 0.6914 - val_accuracy: 0.4969 - val_loss: 0.6938\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6917 - val_accuracy: 0.4906 - val_loss: 0.6947\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5273 - loss: 0.6910 - val_accuracy: 0.4843 - val_loss: 0.6937\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5247 - loss: 0.6912 - val_accuracy: 0.4465 - val_loss: 0.6932\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5286 - loss: 0.6913 - val_accuracy: 0.4906 - val_loss: 0.6935\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4891 - loss: 0.6925 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5212 - loss: 0.6913 - val_accuracy: 0.4906 - val_loss: 0.6937\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5270 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5306 - loss: 0.6902 - val_accuracy: 0.4906 - val_loss: 0.6944\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5310 - loss: 0.6900 - val_accuracy: 0.4969 - val_loss: 0.6930\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5041 - loss: 0.6922 - val_accuracy: 0.5220 - val_loss: 0.6963\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5244 - loss: 0.6916 - val_accuracy: 0.5094 - val_loss: 0.6960\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5279 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.7038\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5276 - loss: 0.6917 - val_accuracy: 0.5346 - val_loss: 0.6967\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5293 - loss: 0.6917 - val_accuracy: 0.4906 - val_loss: 0.6975\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6922 - val_accuracy: 0.4906 - val_loss: 0.6964\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5270 - loss: 0.6918 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6952\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5285 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.7014\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5266 - loss: 0.6919 - val_accuracy: 0.4906 - val_loss: 0.6993\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5266 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6959\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5279 - loss: 0.6948 - val_accuracy: 0.4906 - val_loss: 0.6956\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5282 - loss: 0.6916 - val_accuracy: 0.4906 - val_loss: 0.6972\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5283 - loss: 0.6914 - val_accuracy: 0.4906 - val_loss: 0.7005\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.5198 - loss: 0.6937 - val_accuracy: 0.4906 - val_loss: 0.6946\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5261 - loss: 0.6917 - val_accuracy: 0.4906 - val_loss: 0.6939\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5276 - loss: 0.6912 - val_accuracy: 0.4906 - val_loss: 0.6943\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5546 - loss: 0.6906 - val_accuracy: 0.4906 - val_loss: 0.6950\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5400 - loss: 0.6894 - val_accuracy: 0.4843 - val_loss: 0.6958\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5490 - loss: 0.6895 - val_accuracy: 0.4906 - val_loss: 0.6967\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5256 - loss: 0.6944 - val_accuracy: 0.4403 - val_loss: 0.6945\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5270 - loss: 0.6912 - val_accuracy: 0.4906 - val_loss: 0.6941\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5268 - loss: 0.6900 - val_accuracy: 0.4906 - val_loss: 0.6948\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5277 - loss: 0.6901 - val_accuracy: 0.4906 - val_loss: 0.6957\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5276 - loss: 0.6909 - val_accuracy: 0.5094 - val_loss: 0.6958\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5267 - loss: 0.6902 - val_accuracy: 0.4906 - val_loss: 0.6953\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5475 - loss: 0.6883 - val_accuracy: 0.4906 - val_loss: 0.6961\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5261 - loss: 0.6941 - val_accuracy: 0.4906 - val_loss: 0.6962\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5068 - loss: 0.6906 - val_accuracy: 0.4906 - val_loss: 0.6964\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6923 - val_accuracy: 0.4906 - val_loss: 0.6986\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5287 - loss: 0.6921 - val_accuracy: 0.4906 - val_loss: 0.7098\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5154 - loss: 0.6942 - val_accuracy: 0.4937 - val_loss: 0.6933\n",
            "Epoch 2/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5278 - loss: 0.6929 - val_accuracy: 0.5253 - val_loss: 0.6932\n",
            "Epoch 3/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5271 - loss: 0.6936 - val_accuracy: 0.4684 - val_loss: 0.6945\n",
            "Epoch 4/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5299 - loss: 0.6921 - val_accuracy: 0.4810 - val_loss: 0.6952\n",
            "Epoch 5/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5263 - loss: 0.6915 - val_accuracy: 0.5127 - val_loss: 0.6936\n",
            "Epoch 6/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5270 - loss: 0.6937 - val_accuracy: 0.5063 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5261 - loss: 0.6922 - val_accuracy: 0.5253 - val_loss: 0.6913\n",
            "Epoch 8/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5286 - loss: 0.6911 - val_accuracy: 0.4810 - val_loss: 0.6954\n",
            "Epoch 9/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5075 - loss: 0.6924 - val_accuracy: 0.4937 - val_loss: 0.6931\n",
            "Epoch 10/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5163 - loss: 0.6916 - val_accuracy: 0.5127 - val_loss: 0.6936\n",
            "Epoch 11/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 0.6899 - val_accuracy: 0.5063 - val_loss: 0.6943\n",
            "Epoch 12/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5063 - loss: 0.6928 - val_accuracy: 0.5253 - val_loss: 0.6969\n",
            "Epoch 13/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5033 - loss: 0.6910 - val_accuracy: 0.5380 - val_loss: 0.6938\n",
            "Epoch 14/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5293 - loss: 0.6968 - val_accuracy: 0.4810 - val_loss: 0.6964\n",
            "Epoch 15/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5366 - loss: 0.6898 - val_accuracy: 0.5063 - val_loss: 0.6918\n",
            "Epoch 16/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5405 - loss: 0.6900 - val_accuracy: 0.5127 - val_loss: 0.6914\n",
            "Epoch 17/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5263 - loss: 0.6940 - val_accuracy: 0.5063 - val_loss: 0.6940\n",
            "Epoch 18/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5285 - loss: 0.6914 - val_accuracy: 0.4684 - val_loss: 0.6941\n",
            "Epoch 19/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5300 - loss: 0.6908 - val_accuracy: 0.5253 - val_loss: 0.6906\n",
            "Epoch 20/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5313 - loss: 0.6903 - val_accuracy: 0.4937 - val_loss: 0.6935\n",
            "Epoch 21/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5283 - loss: 0.6905 - val_accuracy: 0.4937 - val_loss: 0.6933\n",
            "Epoch 22/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5242 - loss: 0.6925 - val_accuracy: 0.5063 - val_loss: 0.6937\n",
            "Epoch 23/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5262 - loss: 0.6908 - val_accuracy: 0.5253 - val_loss: 0.6948\n",
            "Epoch 24/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5271 - loss: 0.6916 - val_accuracy: 0.5063 - val_loss: 0.6941\n",
            "Epoch 25/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5256 - loss: 0.6908 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 26/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5256 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 27/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5288 - loss: 0.6911 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 28/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5215 - loss: 0.6896 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 29/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4869 - loss: 0.6931 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 30/30\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5207 - loss: 0.6950 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.5112 - loss: 0.6941 - val_accuracy: 0.5190 - val_loss: 0.6941\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 3/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5261 - loss: 0.6913 - val_accuracy: 0.5127 - val_loss: 0.6928\n",
            "Epoch 4/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5278 - loss: 0.6899 - val_accuracy: 0.5063 - val_loss: 0.6937\n",
            "Epoch 5/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5432 - loss: 0.6892 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 6/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5426 - loss: 0.6890 - val_accuracy: 0.5316 - val_loss: 0.6925\n",
            "Epoch 7/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5129 - loss: 0.6943 - val_accuracy: 0.4810 - val_loss: 0.6952\n",
            "Epoch 8/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5262 - loss: 0.6943 - val_accuracy: 0.4494 - val_loss: 0.6942\n",
            "Epoch 9/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5240 - loss: 0.6907 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 10/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5370 - loss: 0.6889 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 11/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5417 - loss: 0.6910 - val_accuracy: 0.5063 - val_loss: 0.6932\n",
            "Epoch 12/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5532 - loss: 0.6874 - val_accuracy: 0.5063 - val_loss: 0.6942\n",
            "Epoch 13/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5275 - loss: 0.6962 - val_accuracy: 0.5316 - val_loss: 0.6919\n",
            "Epoch 14/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5303 - loss: 0.6921 - val_accuracy: 0.5190 - val_loss: 0.6933\n",
            "Epoch 15/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5274 - loss: 0.6907 - val_accuracy: 0.5063 - val_loss: 0.6938\n",
            "Epoch 16/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5311 - loss: 0.6902 - val_accuracy: 0.4873 - val_loss: 0.6932\n",
            "Epoch 17/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5286 - loss: 0.6895 - val_accuracy: 0.5127 - val_loss: 0.6937\n",
            "Epoch 18/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5502 - loss: 0.6903 - val_accuracy: 0.5190 - val_loss: 0.6931\n",
            "Epoch 19/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5230 - loss: 0.6927 - val_accuracy: 0.5063 - val_loss: 0.6928\n",
            "Epoch 20/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5304 - loss: 0.6909 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5266 - loss: 0.6928 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 22/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5258 - loss: 0.6910 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 23/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5272 - loss: 0.6906 - val_accuracy: 0.5063 - val_loss: 0.6929\n",
            "Epoch 24/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5272 - loss: 0.6903 - val_accuracy: 0.5063 - val_loss: 0.6931\n",
            "Epoch 25/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5247 - loss: 0.6903 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 26/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5322 - loss: 0.6894 - val_accuracy: 0.5063 - val_loss: 0.6933\n",
            "Epoch 27/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5243 - loss: 0.6905 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 28/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5284 - loss: 0.6935 - val_accuracy: 0.5063 - val_loss: 0.6934\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.4894 - loss: 0.6947 - val_accuracy: 0.4968 - val_loss: 0.6928\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5236 - loss: 0.6924 - val_accuracy: 0.4904 - val_loss: 0.6938\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5240 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.6958\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5226 - loss: 0.6918 - val_accuracy: 0.4841 - val_loss: 0.6944\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5159 - loss: 0.6932 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6925 - val_accuracy: 0.4904 - val_loss: 0.6964\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5252 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6934\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6920 - val_accuracy: 0.4968 - val_loss: 0.6939\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5239 - loss: 0.6912 - val_accuracy: 0.4904 - val_loss: 0.6972\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5227 - loss: 0.6913 - val_accuracy: 0.5032 - val_loss: 0.6936\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5241 - loss: 0.6919 - val_accuracy: 0.4841 - val_loss: 0.6932\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4874 - loss: 0.6933 - val_accuracy: 0.4904 - val_loss: 0.6938\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5227 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6928\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5252 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6936\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5233 - loss: 0.6912 - val_accuracy: 0.4904 - val_loss: 0.6941\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5226 - loss: 0.6914 - val_accuracy: 0.4586 - val_loss: 0.6936\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5246 - loss: 0.6909 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5246 - loss: 0.6914 - val_accuracy: 0.4968 - val_loss: 0.6949\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5250 - loss: 0.6917 - val_accuracy: 0.5159 - val_loss: 0.6940\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5240 - loss: 0.6927 - val_accuracy: 0.5159 - val_loss: 0.6934\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5227 - loss: 0.6913 - val_accuracy: 0.4904 - val_loss: 0.6951\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5224 - loss: 0.6910 - val_accuracy: 0.4904 - val_loss: 0.6939\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5235 - loss: 0.6911 - val_accuracy: 0.4904 - val_loss: 0.6943\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.5283 - loss: 0.6905 - val_accuracy: 0.4904 - val_loss: 0.6933\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5253 - loss: 0.6908 - val_accuracy: 0.4904 - val_loss: 0.6923\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5303 - loss: 0.6910 - val_accuracy: 0.4968 - val_loss: 0.6970\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.5447 - loss: 0.6881 - val_accuracy: 0.5032 - val_loss: 0.6939\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5231 - loss: 0.6941 - val_accuracy: 0.4586 - val_loss: 0.6942\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5164 - loss: 0.6922 - val_accuracy: 0.4904 - val_loss: 0.6943\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5227 - loss: 0.6912 - val_accuracy: 0.4904 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5262 - loss: 0.6932 - val_accuracy: 0.4904 - val_loss: 0.6940\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5257 - loss: 0.6920 - val_accuracy: 0.4777 - val_loss: 0.6946\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5245 - loss: 0.6910 - val_accuracy: 0.4650 - val_loss: 0.6933\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5279 - loss: 0.6896 - val_accuracy: 0.4904 - val_loss: 0.6950\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5287 - loss: 0.6907 - val_accuracy: 0.4713 - val_loss: 0.6946\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5287 - loss: 0.6910 - val_accuracy: 0.4904 - val_loss: 0.6945\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4849 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6955\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5255 - loss: 0.6914 - val_accuracy: 0.4904 - val_loss: 0.6965\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5259 - loss: 0.6902 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5297 - loss: 0.6902 - val_accuracy: 0.5096 - val_loss: 0.6965\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5382 - loss: 0.6895 - val_accuracy: 0.4904 - val_loss: 0.7145\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5407 - loss: 0.6920 - val_accuracy: 0.4904 - val_loss: 0.7052\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5508 - loss: 0.6876 - val_accuracy: 0.4904 - val_loss: 0.6935\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5248 - loss: 0.6950 - val_accuracy: 0.5096 - val_loss: 0.6932\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5253 - loss: 0.6920 - val_accuracy: 0.4841 - val_loss: 0.6931\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5270 - loss: 0.6916 - val_accuracy: 0.5032 - val_loss: 0.6933\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.5281 - loss: 0.6912 - val_accuracy: 0.4904 - val_loss: 0.6942\n",
            "Epoch 18/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4980 - loss: 0.6923 - val_accuracy: 0.4904 - val_loss: 0.6957\n",
            "Epoch 19/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5294 - loss: 0.6901 - val_accuracy: 0.4904 - val_loss: 0.6966\n",
            "Epoch 20/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5276 - loss: 0.6898 - val_accuracy: 0.4904 - val_loss: 0.6963\n",
            "Epoch 21/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5256 - loss: 0.6898 - val_accuracy: 0.4904 - val_loss: 0.7007\n",
            "Epoch 22/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5423 - loss: 0.6895 - val_accuracy: 0.4904 - val_loss: 0.6967\n",
            "Epoch 23/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5260 - loss: 0.6930 - val_accuracy: 0.4904 - val_loss: 0.7010\n",
            "Epoch 24/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4903 - loss: 0.6929 - val_accuracy: 0.4904 - val_loss: 0.6984\n",
            "Epoch 25/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5319 - loss: 0.6905 - val_accuracy: 0.4904 - val_loss: 0.6971\n",
            "Epoch 26/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5407 - loss: 0.6886 - val_accuracy: 0.4904 - val_loss: 0.6968\n",
            "Epoch 27/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5465 - loss: 0.6883 - val_accuracy: 0.4904 - val_loss: 0.6988\n",
            "Epoch 28/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5305 - loss: 0.6916 - val_accuracy: 0.4904 - val_loss: 0.7006\n",
            "Epoch 29/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5302 - loss: 0.6896 - val_accuracy: 0.4904 - val_loss: 0.6999\n",
            "Epoch 30/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5308 - loss: 0.6891 - val_accuracy: 0.4904 - val_loss: 0.7006\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.5156 - loss: 0.6949 - val_accuracy: 0.4808 - val_loss: 0.6929\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5282 - loss: 0.6928 - val_accuracy: 0.5256 - val_loss: 0.6931\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.5285 - loss: 0.6910 - val_accuracy: 0.5385 - val_loss: 0.6922\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5404 - loss: 0.6907 - val_accuracy: 0.4872 - val_loss: 0.6934\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5288 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5196 - loss: 0.6912 - val_accuracy: 0.4936 - val_loss: 0.6936\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5270 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6959\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5292 - loss: 0.6920 - val_accuracy: 0.5128 - val_loss: 0.6930\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5288 - loss: 0.6905 - val_accuracy: 0.5449 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5298 - loss: 0.6907 - val_accuracy: 0.5385 - val_loss: 0.6947\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5281 - loss: 0.6904 - val_accuracy: 0.4744 - val_loss: 0.6960\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5301 - loss: 0.6897 - val_accuracy: 0.5000 - val_loss: 0.6961\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5291 - loss: 0.6912 - val_accuracy: 0.5128 - val_loss: 0.6930\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5286 - loss: 0.6923 - val_accuracy: 0.5192 - val_loss: 0.6933\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5294 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6956\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5283 - loss: 0.6908 - val_accuracy: 0.4936 - val_loss: 0.6941\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5293 - loss: 0.6911 - val_accuracy: 0.4615 - val_loss: 0.6933\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5312 - loss: 0.6907 - val_accuracy: 0.4872 - val_loss: 0.6947\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.4834 - loss: 0.6942 - val_accuracy: 0.4936 - val_loss: 0.6938\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5286 - loss: 0.6921 - val_accuracy: 0.5256 - val_loss: 0.6918\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5278 - loss: 0.6908 - val_accuracy: 0.5256 - val_loss: 0.6928\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5287 - loss: 0.6908 - val_accuracy: 0.4872 - val_loss: 0.6940\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5296 - loss: 0.6917 - val_accuracy: 0.5064 - val_loss: 0.6926\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5287 - loss: 0.6903 - val_accuracy: 0.5064 - val_loss: 0.6934\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5268 - loss: 0.6899 - val_accuracy: 0.5192 - val_loss: 0.6927\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5383 - loss: 0.6897 - val_accuracy: 0.5128 - val_loss: 0.6921\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5357 - loss: 0.6903 - val_accuracy: 0.4872 - val_loss: 0.6934\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5470 - loss: 0.6887 - val_accuracy: 0.4872 - val_loss: 0.6953\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5450 - loss: 0.6889 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5456 - loss: 0.6886 - val_accuracy: 0.4872 - val_loss: 0.6956\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5449 - loss: 0.6880 - val_accuracy: 0.4872 - val_loss: 0.6933\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5372 - loss: 0.6877 - val_accuracy: 0.4679 - val_loss: 0.6932\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5317 - loss: 0.6906 - val_accuracy: 0.5128 - val_loss: 0.6928\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5296 - loss: 0.6905 - val_accuracy: 0.4551 - val_loss: 0.6931\n",
            "Epoch 17/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5306 - loss: 0.6895 - val_accuracy: 0.4872 - val_loss: 0.6967\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.5116 - loss: 0.6933 - val_accuracy: 0.4839 - val_loss: 0.6934\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.5284 - loss: 0.6924 - val_accuracy: 0.4581 - val_loss: 0.6932\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5285 - loss: 0.6943 - val_accuracy: 0.5097 - val_loss: 0.6931\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5289 - loss: 0.6926 - val_accuracy: 0.4581 - val_loss: 0.6931\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5287 - loss: 0.6914 - val_accuracy: 0.5290 - val_loss: 0.6936\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5284 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6940\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5306 - loss: 0.6910 - val_accuracy: 0.5161 - val_loss: 0.6936\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5300 - loss: 0.6903 - val_accuracy: 0.5226 - val_loss: 0.6929\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5195 - loss: 0.6900 - val_accuracy: 0.5355 - val_loss: 0.6921\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5453 - loss: 0.6898 - val_accuracy: 0.4839 - val_loss: 0.6995\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5455 - loss: 0.6880 - val_accuracy: 0.5161 - val_loss: 0.6936\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5273 - loss: 0.6917 - val_accuracy: 0.5290 - val_loss: 0.6917\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5561 - loss: 0.6901 - val_accuracy: 0.5032 - val_loss: 0.6945\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5384 - loss: 0.6890 - val_accuracy: 0.5226 - val_loss: 0.6952\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5389 - loss: 0.6895 - val_accuracy: 0.4968 - val_loss: 0.6912\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5307 - loss: 0.6949 - val_accuracy: 0.5097 - val_loss: 0.6934\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5305 - loss: 0.6904 - val_accuracy: 0.5097 - val_loss: 0.6974\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5084 - loss: 0.6932 - val_accuracy: 0.5032 - val_loss: 0.6966\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.4784 - loss: 0.6945 - val_accuracy: 0.4839 - val_loss: 0.6951\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5334 - loss: 0.6902 - val_accuracy: 0.4903 - val_loss: 0.6952\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5424 - loss: 0.6902 - val_accuracy: 0.4839 - val_loss: 0.6949\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5441 - loss: 0.6879 - val_accuracy: 0.5677 - val_loss: 0.6957\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5377 - loss: 0.6857 - val_accuracy: 0.5097 - val_loss: 0.6966\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5286 - loss: 0.6939 - val_accuracy: 0.4645 - val_loss: 0.6936\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5471 - loss: 0.6889 - val_accuracy: 0.4968 - val_loss: 0.6981\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5543 - loss: 0.6874 - val_accuracy: 0.5419 - val_loss: 0.6970\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5377 - loss: 0.6949 - val_accuracy: 0.5032 - val_loss: 0.6972\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4907 - loss: 0.6909 - val_accuracy: 0.4839 - val_loss: 0.7029\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5380 - loss: 0.6891 - val_accuracy: 0.4903 - val_loss: 0.7095\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5440 - loss: 0.6882 - val_accuracy: 0.4903 - val_loss: 0.7015\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.5084 - loss: 0.6939 - val_accuracy: 0.4903 - val_loss: 0.6930\n",
            "Epoch 2/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5319 - loss: 0.6915 - val_accuracy: 0.4839 - val_loss: 0.6936\n",
            "Epoch 3/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.5321 - loss: 0.6910 - val_accuracy: 0.4839 - val_loss: 0.6952\n",
            "Epoch 4/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.5296 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6983\n",
            "Epoch 5/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5286 - loss: 0.6901 - val_accuracy: 0.5290 - val_loss: 0.6933\n",
            "Epoch 6/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5455 - loss: 0.6891 - val_accuracy: 0.4839 - val_loss: 0.6939\n",
            "Epoch 7/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.5337 - loss: 0.6910 - val_accuracy: 0.4968 - val_loss: 0.6962\n",
            "Epoch 8/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.5335 - loss: 0.6908 - val_accuracy: 0.4839 - val_loss: 0.6985\n",
            "Epoch 9/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4950 - loss: 0.6959 - val_accuracy: 0.4710 - val_loss: 0.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5310 - loss: 0.6897 - val_accuracy: 0.4839 - val_loss: 0.6960\n",
            "Epoch 11/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5333 - loss: 0.6886 - val_accuracy: 0.4903 - val_loss: 0.6956\n",
            "Epoch 12/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5382 - loss: 0.6894 - val_accuracy: 0.4839 - val_loss: 0.6971\n",
            "Epoch 13/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5442 - loss: 0.6882 - val_accuracy: 0.4839 - val_loss: 0.6994\n",
            "Epoch 14/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5224 - loss: 0.6903 - val_accuracy: 0.4839 - val_loss: 0.7004\n",
            "Epoch 15/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5407 - loss: 0.6878 - val_accuracy: 0.4968 - val_loss: 0.6945\n",
            "Epoch 16/30\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5407 - loss: 0.6879 - val_accuracy: 0.4839 - val_loss: 0.6948\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model                   <Sequential name=sequential_91, built=True>\n",
              "window_size                                                      20\n",
              "batch_size                                                      128\n",
              "train_accuracy                                             0.566347\n",
              "val_accuracy                                               0.533742\n",
              "X_test            [[[0.02255599219806541, -1.1090867518093193, -...\n",
              "y_test            [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "final_accuracy                                             0.548469\n",
              "Name: 3, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <td>&lt;Sequential name=sequential_91, built=True&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>window_size</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <td>128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_accuracy</th>\n",
              "      <td>0.566347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val_accuracy</th>\n",
              "      <td>0.533742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>X_test</th>\n",
              "      <td>[[[0.02255599219806541, -1.1090867518093193, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y_test</th>\n",
              "      <td>[1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>final_accuracy</th>\n",
              "      <td>0.548469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "hA1CK9w9bNBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model creation and training functiion"
      ],
      "metadata": {
        "id": "BnsjB8_-cFPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import xgboost as xgb\n",
        "\n",
        "def xgboost_model_training(df):\n",
        "\n",
        "  X = df.drop(columns=[\"target\"])\n",
        "  y = df[\"target\"]\n",
        "\n",
        "  # Split the data:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
        "\n",
        "  model = xgb.XGBClassifier(\n",
        "      objective='binary:logistic',   # Use this objective if you have binary classes (e.g., up/down).\n",
        "      eval_metric='logloss',         # Evaluation metric can be logloss, error, etc.\n",
        "      use_label_encoder=False,       # Prevents deprecation warnings in newer versions of XGBoost.\n",
        "      random_state=42\n",
        "  )\n",
        "\n",
        "  # Parameter grid for the grid search\n",
        "  param_grid = {\n",
        "      'max_depth': [3, 5, 7],\n",
        "      'learning_rate': [0.01, 0.1, 0.2],\n",
        "      'n_estimators': [100, 200, 300],\n",
        "      'subsample': [0.8, 1.0]\n",
        "  }\n",
        "\n",
        "  grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  # Retrieve the best model after grid search\n",
        "  best_model = grid_search.best_estimator_\n",
        "  return best_model, X_test, y_test\n"
      ],
      "metadata": {
        "id": "oDaNatjvbOkB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "XpJdV3TfcCZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_xgboost_model(best_model, X_test, y_test):\n",
        "  # Make predictions on the test set\n",
        "  y_pred = best_model.predict(X_test)\n",
        "\n",
        "  # Evaluate using accuracy and other metrics.\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print(\"Test Accuracy:\", acc)\n",
        "\n",
        "  # Detailed classification report\n",
        "  print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "  # Confusion matrix to see the distribution of predictions.\n",
        "  conf_mat = confusion_matrix(y_test, y_pred)\n",
        "  print(\"Confusion Matrix:\\n\", conf_mat)"
      ],
      "metadata": {
        "id": "XM03ALGccD28"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results"
      ],
      "metadata": {
        "id": "BEz5VGe4cz0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for df_name, df in dfs.items():\n",
        "  print(f\"{df_name}\")\n",
        "  print(50*\"-\")\n",
        "  df[\"month\"] = df.index.month\n",
        "  best_model, X_test, y_test = xgboost_model_training(df)\n",
        "  evaluate_xgboost_model(best_model, X_test, y_test)\n",
        "  print(50*\"-\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyalJusWcrIV",
        "outputId": "b2331903-4190-497c-f2c5-ace567e16aaf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scaled\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:41:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5145631067961165\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.92      0.67       220\n",
            "         1.0       0.36      0.05      0.09       192\n",
            "\n",
            "    accuracy                           0.51       412\n",
            "   macro avg       0.44      0.49      0.38       412\n",
            "weighted avg       0.45      0.51      0.40       412\n",
            "\n",
            "Confusion Matrix:\n",
            " [[202  18]\n",
            " [182  10]]\n",
            "--------------------------------------------------\n",
            "\n",
            "normalized\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:44:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5145631067961165\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.90      0.66       220\n",
            "         1.0       0.39      0.07      0.12       192\n",
            "\n",
            "    accuracy                           0.51       412\n",
            "   macro avg       0.46      0.49      0.39       412\n",
            "weighted avg       0.46      0.51      0.41       412\n",
            "\n",
            "Confusion Matrix:\n",
            " [[198  22]\n",
            " [178  14]]\n",
            "--------------------------------------------------\n",
            "\n",
            "log_transformed\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:46:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5194174757281553\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.93      0.67       220\n",
            "         1.0       0.38      0.05      0.09       192\n",
            "\n",
            "    accuracy                           0.52       412\n",
            "   macro avg       0.46      0.49      0.38       412\n",
            "weighted avg       0.46      0.52      0.40       412\n",
            "\n",
            "Confusion Matrix:\n",
            " [[204  16]\n",
            " [182  10]]\n",
            "--------------------------------------------------\n",
            "\n",
            "log_normalized\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:48:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.5194174757281553\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.53      0.93      0.67       220\n",
            "         1.0       0.38      0.05      0.09       192\n",
            "\n",
            "    accuracy                           0.52       412\n",
            "   macro avg       0.46      0.49      0.38       412\n",
            "weighted avg       0.46      0.52      0.40       412\n",
            "\n",
            "Confusion Matrix:\n",
            " [[204  16]\n",
            " [182  10]]\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    }
  ]
}